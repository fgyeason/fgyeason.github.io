<!DOCTYPE html>



  


<html class="theme-next muse use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">


  
  
    
    
  <script src="/lib/pace/pace.min.js?v=1.0.2"></script>
  <link href="/lib/pace/pace-theme-minimal.min.css?v=1.0.2" rel="stylesheet">


 <script>     
    (function(){
        if(''){
            if (prompt('请输入文章密码') !== ''){
                alert('密码错误！');
                history.back();
            }
        }
    })();
</script>







<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="机器学习,深度学习," />





  <link rel="alternate" href="/atom.xml" title="Frank's Blog" type="application/atom+xml" />






<meta name="keywords" content="机器学习,深度学习">
<meta property="og:type" content="article">
<meta property="og:title" content="机器学习基础（一）">
<meta property="og:url" content="http://frankblog.site/2018/05/18/机器学习基础/index.html">
<meta property="og:site_name" content="Frank&#39;s Blog">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="http://p4rlzrioq.bkt.clouddn.com/machine-learning-algorithms.jpg">
<meta property="og:image" content="http://p4rlzrioq.bkt.clouddn.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF.png">
<meta property="og:image" content="http://p4rlzrioq.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E6%B5%81%E7%A8%8B.jpg">
<meta property="og:image" content="http://p4rlzrioq.bkt.clouddn.com/%E8%87%AA%E5%8A%A9%E6%B3%95.png">
<meta property="og:image" content="http://p4rlzrioq.bkt.clouddn.com/hash%E7%BC%96%E7%A0%81.jpg">
<meta property="og:image" content="http://p4rlzrioq.bkt.clouddn.com/%E5%BD%92%E4%B8%80%E5%8C%96.svg">
<meta property="og:image" content="http://p4rlzrioq.bkt.clouddn.com/%E7%BC%A9%E6%94%BE.svg">
<meta property="og:image" content="http://p4rlzrioq.bkt.clouddn.com/%E6%A0%87%E5%87%86%E5%8C%96.svg">
<meta property="og:image" content="http://p4rlzrioq.bkt.clouddn.com/%E6%AF%94%E8%B5%9B%E5%9C%BA%E6%99%AF1.jpg">
<meta property="og:image" content="http://p4rlzrioq.bkt.clouddn.com/%E6%AF%94%E8%B5%9B%E5%9C%BA%E6%99%AF2.jpg">
<meta property="og:image" content="http://p4rlzrioq.bkt.clouddn.com/pca%E9%99%8D%E7%BB%B4%E5%A4%84%E7%90%86.png">
<meta property="og:image" content="http://p4rlzrioq.bkt.clouddn.com/L1,L2%E6%AD%A3%E5%88%99%E5%8C%96.png">
<meta property="og:image" content="http://p4rlzrioq.bkt.clouddn.com/gini%E7%B3%BB%E6%95%B01.jpg">
<meta property="og:image" content="http://p4rlzrioq.bkt.clouddn.com/%E5%9F%BA%E5%B0%BC%E7%B3%BB%E6%95%B02.jpg">
<meta property="og:image" content="http://p4rlzrioq.bkt.clouddn.com/%E5%9F%BA%E5%B0%BC%E7%B3%BB%E6%95%B03.jpg">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/40658-24f62052d3f57559.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/700">
<meta property="og:image" content="http://p4rlzrioq.bkt.clouddn.com/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D.jpg">
<meta property="og:image" content="http://p4rlzrioq.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E6%A0%87%E5%87%86%E5%8C%96%E4%BC%98%E5%8A%BF.png">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/145616-0a7a7fd1ff77dcd9.png">
<meta property="og:image" content="http://p4rlzrioq.bkt.clouddn.com/%E5%87%86%E7%A1%AE%E7%8E%87%EF%BC%88Accuracy%EF%BC%89.svg">
<meta property="og:image" content="http://p4rlzrioq.bkt.clouddn.com/%E6%9F%A5%E5%87%86%E7%8E%87%EF%BC%88Precision%EF%BC%89.svg">
<meta property="og:image" content="http://p4rlzrioq.bkt.clouddn.com/%E6%9F%A5%E5%85%A8%E7%8E%87%EF%BC%88Recall%EF%BC%89.svg">
<meta property="og:image" content="https://upload.wikimedia.org/wikipedia/commons/2/26/Precisionrecall.svg">
<meta property="og:image" content="http://p4rlzrioq.bkt.clouddn.com/F1%20Score.svg">
<meta property="og:image" content="http://p4rlzrioq.bkt.clouddn.com/F-beta%20Score.svg">
<meta property="og:image" content="https://habrastorage.org/files/267/36b/ff1/26736bff158a4d82893ff85b2022cc5b.gif">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/145616-ce8221a29d9c01ef.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/700">
<meta property="og:image" content="http://p4rlzrioq.bkt.clouddn.com/sklearn%20%E4%B8%AD%E6%96%87.png">
<meta property="og:image" content="http://p4rlzrioq.bkt.clouddn.com/%E5%81%8F%E5%B7%AE%E6%96%B9%E5%B7%AE0.png">
<meta property="og:image" content="http://p4rlzrioq.bkt.clouddn.com/%E5%81%8F%E5%B7%AE%E6%96%B9%E5%B7%AE.png">
<meta property="og:image" content="http://p4rlzrioq.bkt.clouddn.com/%E5%81%8F%E5%B7%AE%E6%96%B9%E5%B7%AE1.png">
<meta property="og:image" content="http://p4rlzrioq.bkt.clouddn.com/%E5%81%8F%E5%B7%AE%E6%96%B9%E5%B7%AE0.png">
<meta property="og:image" content="http://p4rlzrioq.bkt.clouddn.com/%E5%87%86%E4%B8%8E%E7%A1%AE.jpeg">
<meta property="og:image" content="http://p4rlzrioq.bkt.clouddn.com/overfitting.jpg">
<meta property="og:image" content="http://p4rlzrioq.bkt.clouddn.com/machine%20learning%20funny.jpg">
<meta property="og:updated_time" content="2018-06-12T08:39:30.282Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="机器学习基础（一）">
<meta name="twitter:image" content="http://p4rlzrioq.bkt.clouddn.com/machine-learning-algorithms.jpg">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":true},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://frankblog.site/2018/05/18/机器学习基础/"/>





  <title>机器学习基础（一） | Frank's Blog</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">
  
  
    
  
  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>
    
    <a href="https://github.com/fgyeason" class="github-corner" aria-label="View source on Github"><svg width="80" height="80" viewBox="0 0 250 250" style="fill:#151513; color:#fff; position: absolute; top: 0; border: 0; right: 0;" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a><style>.github-corner:hover .octo-arm{animation:octocat-wave 560ms ease-in-out}@keyframes octocat-wave{0%,100%{transform:rotate(0)}20%,60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}@media (max-width:500px){.github-corner:hover .octo-arm{animation:none}.github-corner .octo-arm{animation:octocat-wave 560ms ease-in-out}}</style>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Frank's Blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">Enjoy everything fun and challenging</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            关于
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-books">
          <a href="/books/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-book"></i> <br />
            
            书籍
          </a>
        </li>
      
        
        <li class="menu-item menu-item-films">
          <a href="/films/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-film"></i> <br />
            
            电影
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off"
             placeholder="搜索..." spellcheck="false"
             type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>
<script src="https://cdn.bootcss.com/aplayer/1.6.0/APlayer.min.js"></script>


 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://frankblog.site/2018/05/18/机器学习基础/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="FGY">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/风景.jpeg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Frank's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">机器学习基础（一）</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
              
                <span class="post-meta-item-text">发表于</span>
              

              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-05-18T12:57:16+08:00">
                2018-05-18
              </time>
            

            
              <span class="post-meta-divider">|</span>
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-check-o"></i>
              </span>
              
                <span class="post-meta-item-text">更新于&#58;</span>
              
              <time title="更新于" itemprop="dateModified" datetime="2018-06-12T16:39:30+08:00">
                2018-06-12
              </time>
            
          </span>


          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习</span>
                  </a>
                </span>

                
                
              
            </span>
          





          
            
          

        
          


          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  9,580 字  
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  34 分钟  
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <script src="\assets\js\APlayer.min.js"> </script><p><img src="http://p4rlzrioq.bkt.clouddn.com/machine-learning-algorithms.jpg" alt=""></p>
<a id="more"></a>
<blockquote class="blockquote-center"><font size="5">从IT时代走向DT时代</font></blockquote>

<hr>
<h1 id="机器学习应用"><a href="#机器学习应用" class="headerlink" title="机器学习应用"></a>机器学习应用</h1><h2 id="1、计算机视觉"><a href="#1、计算机视觉" class="headerlink" title="1、计算机视觉"></a>1、计算机视觉</h2><p>典型的应用包括：<strong>人脸识别、车牌识别、扫描文字识别、图片内容识别、图片搜索</strong>等等。</p>
<h2 id="2、自然语言处理"><a href="#2、自然语言处理" class="headerlink" title="2、自然语言处理"></a>2、自然语言处理</h2><p>典型的应用包括：<strong>搜索引擎智能匹配、文本内容理解、文本情绪判断，语音识别、输入法、机器翻译</strong>等等。</p>
<h2 id="3、社会网络分析"><a href="#3、社会网络分析" class="headerlink" title="3、社会网络分析"></a>3、社会网络分析</h2><p>典型的应用包括：<strong>用户画像、网络关联分析、欺诈作弊发现、热点发现</strong>等等。</p>
<h2 id="4、推荐系统"><a href="#4、推荐系统" class="headerlink" title="4、推荐系统"></a>4、推荐系统</h2><p>典型的应用包括：<strong>虾米音乐的“歌曲推荐”，某宝的“猜你喜欢”</strong>等等。<br><img src="http://p4rlzrioq.bkt.clouddn.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF.png" alt=""></p>
<h2 id="数据挖掘流程"><a href="#数据挖掘流程" class="headerlink" title="数据挖掘流程"></a>数据挖掘流程</h2><p><img src="http://p4rlzrioq.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E6%B5%81%E7%A8%8B.jpg" alt=""></p>
<h1 id="数据采集"><a href="#数据采集" class="headerlink" title="数据采集"></a>数据采集</h1><h2 id="数据分类"><a href="#数据分类" class="headerlink" title="数据分类"></a>数据分类</h2><p>正例(positive example)<br>反例(negative example)<br>训练集(training set)<br>验证集(validation set)：用作超参数验证<br>测试集(test set)<br>类别不平衡数据集（class-imbalanced data set）</p>
<h2 id="采样方式"><a href="#采样方式" class="headerlink" title="采样方式"></a>采样方式</h2><h3 id="1、分层采样-stratified-sampling"><a href="#1、分层采样-stratified-sampling" class="headerlink" title="1、分层采样(stratified sampling)"></a>1、分层采样(stratified sampling)</h3><p>保留类别比例的采样方式通常称为分层采样</p>
<h3 id="2、留出法（hold-out）"><a href="#2、留出法（hold-out）" class="headerlink" title="2、留出法（hold-out）"></a>2、留出法（hold-out）</h3><p>直接将数据集D划分为两个互斥的集合，其中一个集合作为训练集S，另一个作为测试集T，在S上训练出模型后，用T来评估其测试误差，作为对泛化误差的估计。</p>
<h3 id="3、k折交叉验证（k-fold-cross-validation）"><a href="#3、k折交叉验证（k-fold-cross-validation）" class="headerlink" title="3、k折交叉验证（k-fold cross validation）"></a>3、k折交叉验证（k-fold cross validation）</h3><p>交叉验证先将数据集D划分为k个大小相似的互斥子集，每个子集从数据集中分层采样得到，然后，每次用k-1个子集的并集作为训练集，余下的一个子集作为测试集，这样就可以获得k组训练/测试集，最终返回k个测试结果的均值。</p>
<h3 id="4、自助法-bootstrapping"><a href="#4、自助法-bootstrapping" class="headerlink" title="4、自助法(bootstrapping)"></a>4、自助法(bootstrapping)</h3><p>对数据集D有放回的随机采样m次后，一个样本不在样本集D1出现的概率：</p>
<p><img src="http://p4rlzrioq.bkt.clouddn.com/%E8%87%AA%E5%8A%A9%E6%B3%95.png" alt=""></p>
<p>当n足够大时，大约有36.8%的样本不会被采到，用没采到的部分做测试集，也是包外估计（out-of-bag-estimate）。由于我们的训练集有重复数据，这会改变数据的分布，因而训练结果会有估计偏差，因此，此种方法不是很常用，除非数据量真的很少，比如小于20个。</p>
<h1 id="数据清洗"><a href="#数据清洗" class="headerlink" title="数据清洗"></a>数据清洗</h1><h2 id="1、缺失值处理"><a href="#1、缺失值处理" class="headerlink" title="1、缺失值处理"></a>1、缺失值处理</h2><p>1.直接删除——适合缺失值数量较小，并且是随机出现的，删除它们对整体数据影响不大的情况。<br>2.使用一个全局常量填充—-譬如将缺失值用“Unknown”等填充，但是效果不一定好，因为算法可能会把它识别为一个新的类别，一般很少用<br>3.使用均值或中位数代替——优点：不会减少样本信息，处理简单。缺点：当缺失数据不是随机数据时会产生偏差.对于正常分布的数据可以使用均值代替，如果数据是倾斜的，使用中位数可能更好。<br>4.插补法<br>    1）随机插补法——从总体中随机抽取某个样本代替缺失样本<br>    2）多重插补法——通过变量之间的关系对缺失数据进行预测，利用蒙特卡洛方法生成多个完整的数据集，在对这些数据集进行分析，最后对分析结果进行汇总处理<br>    3）热平台插补——指在非缺失数据集中找到一个与缺失值所在样本相似的样本（匹配样本），利用其中的观测值对缺失值进行插补。<br>优点：简单易行，准去率较高<br>缺点：变量数量较多时，通常很难找到与需要插补样本完全相同的样本。但我们可以按照某些变量将数据分层，在层中对缺失值实用均值插补<br>    4)拉格朗日差值法和牛顿插值法<br>5.建模法<br>可以用回归、使用贝叶斯形式化方法的基于推理的工具或决策树归纳确定。例如，利用数据集中其他数据的属性，可以构造一棵判定树，来预测缺失值的值。</p>
<p><strong>使用sklearn进行插补：</strong><br>其实sklearn里也有一个工具<a href="http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.Imputer.html#sklearn.preprocessing.Imputer" target="_blank" rel="noopener">Imputer</a>可以对缺失值进行插补。Imputer类可以对缺失值进行均值插补、中位数插补或者某行/列出现的频率最高的值进行插补，也可以对不同的缺失值进行编码。<strong>并且支持稀疏矩阵。</strong></p>
<p>在稀疏矩阵中，缺失值被编码为0存储为矩阵中，这种格式是适合于缺失值比非缺失值多得多的情况。此外，Imputer类也可以用于Pipeline中。</p>
<blockquote>
<p>Imputor类的参数：_class _<code>sklearn.preprocessing.``Imputer</code>(_missing_values=’NaN’_, _strategy=’mean’_, _axis=0_, _verbose=0_, _copy=True_)</p>
<p><strong>missing_values</strong> : int或”NaN”,默认NaN（String类型）<br><strong>strategy</strong> : string, 默认为mean，可选则mean、median、most_frequent<br><strong>axis</strong> :int, 默认为0（axis = 0，对列进行插值；axis= 1，对行进行插值）<br><strong>verbose</strong> : int, 默认为0<br><strong>copy</strong> : boolean, 默认为True<br>　　True：会创建一个X的副本<br>　　False：在任何合适的地方都会进行插值。<br>　　但是以下四种情况，计算设置的copy = Fasle，也会创建一个副本：<br>　　1.X不是浮点型数组<br>　　2.X是稀疏矩阵，而且miss_value = 0<br>　　3.axis= 0，X被编码为CSR矩阵<br>　　4.axis= 1，X被编码为CSC矩阵</p>
</blockquote>
<p>p.s.：LightGBM和XGBoost都能将NaN作为数据的一部分进行学习，所以不需要处理缺失值。</p>
<h2 id="2、异常点处理"><a href="#2、异常点处理" class="headerlink" title="2、异常点处理"></a>2、异常点处理</h2><p>1.简单的统计分析<br>　　拿到数据后可以对数据进行一个简单的描述性统计分析，譬如最大最小值可以用来判断这个变量的取值是否超过了合理的范围，如客户的年龄为-20岁或200岁，显然是不合常理的，为异常值。<br>2.3∂原则<br>　　如果数据服从正态分布，在3∂原则下，异常值为一组测定值中与平均值的偏差超过3倍标准差的值。如果数据服从正态分布，距离平均值3∂之外的值出现的概率为P(|x-u| &gt; 3∂) &lt;= 0.003，属于极个别的小概率事件。如果数据不服从正态分布，也可以用远离平均值的多少倍标准差来描述。</p>
<p>3.箱型图分析<br>　　箱型图提供了识别异常值的一个标准：如果一个值小于QL01.5IQR或大于OU-1.5IQR的值，则被称为异常值。QL为下四分位数，表示全部观察值中有四分之一的数据取值比它小；QU为上四分位数，表示全部观察值中有四分之一的数据取值比它大；IQR为四分位数间距，是上四分位数QU与下四分位数QL的差值，包含了全部观察值的一半。箱型图判断异常值的方法以四分位数和四分位距为基础，四分位数具有鲁棒性：25%的数据可以变得任意远并且不会干扰四分位数，所以异常值不能对这个标准施加影响。因此箱型图识别异常值比较客观，在识别异常值时有一定的优越性。</p>
<p>4.基于模型检测<br>　　首先建立一个数据模型，异常是那些同模型不能完美拟合的对象；如果模型是簇的集合，则异常是不显著属于任何簇的对象；在使用回归模型时，异常是相对远离预测值的对象</p>
<p>优缺点：1.有坚实的统计学理论基础，当存在充分的数据和所用的检验类型的知识时，这些检验可能非常有效；2.对于多元数据，可用的选择少一些，并且对于高维数据，这些检测可能性很差。</p>
<p>5.基于距离<br>　　通常可以在对象之间定义邻近性度量，异常对象是那些远离其他对象的对象</p>
<p>优缺点：1.简单；2.缺点：基于邻近度的方法需要O(m2)时间，大数据集不适用；3.该方法对参数的选择也是敏感的；4.不能处理具有不同密度区域的数据集，因为它使用全局阈值，不能考虑这种密度的变化。</p>
<p>6.基于密度<br>　　当一个点的局部密度显著低于它的大部分近邻时才将其分类为离群点。适合非均匀分布的数据。</p>
<p>优缺点：1.给出了对象是离群点的定量度量，并且即使数据具有不同的区域也能够很好的处理；2.与基于距离的方法一样，这些方法必然具有O(m2)的时间复杂度。对于低维数据使用特定的数据结构可以达到O(mlogm)；3.参数选择困难。虽然算法通过观察不同的k值，取得最大离群点得分来处理该问题，但是，仍然需要选择这些值的上下界。</p>
<p>7.基于聚类：<br>　　基于聚类的离群点：一个对象是基于聚类的离群点，如果该对象不强属于任何簇。离群点对初始聚类的影响：如果通过聚类检测离群点，则由于离群点影响聚类，存在一个问题：结构是否有效。为了处理该问题，可以使用如下方法：对象聚类，删除离群点，对象再次聚类（这个不能保证产生最优结果）。</p>
<p>优缺点：1.基于线性和接近线性复杂度（k均值）的聚类技术来发现离群点可能是高度有效的；2.簇的定义通常是离群点的补，因此可能同时发现簇和离群点；3.产生的离群点集和它们的得分可能非常依赖所用的簇的个数和数据中离群点的存在性；4.聚类算法产生的簇的质量对该算法产生的离群点的质量影响非常大。</p>
<p><strong>处理方法：</strong></p>
<p>1.删除异常值——明显看出是异常且数量较少可以直接删除<br>2.不处理—-如果算法对异常值不敏感则可以不处理，但如果算法对异常值敏感，则最好不要用，如基于距离计算的一些算法，包括kmeans，knn之类的。<br>3.平均值替代——损失信息小，简单高效。<br>4.视为缺失值——可以按照处理缺失值的方法来处理<br>5.标准化——如果你的数据有离群点，对数据进行均差和方差的标准化效果并不好。这种情况你可以使用<code>sklearn</code>中的<code>robust_scale</code>和 <code>RobustScaler</code> 作为替代。</p>
<h2 id="3、去重处理"><a href="#3、去重处理" class="headerlink" title="3、去重处理"></a>3、去重处理</h2><h3 id="dataframe格式"><a href="#dataframe格式" class="headerlink" title="dataframe格式"></a>dataframe格式</h3><p>1、DataFrame的duplicated方法返回一个布尔型Series，表示各行是否是重复行<br>2、drop_duplicates方法用于返回一个移除了重复行的DataFrame<br>3、data.drop_duplicates([‘v1’]) #只判断某列</p>
<h3 id="list格式"><a href="#list格式" class="headerlink" title="list格式"></a>list格式</h3><p>1、使用set()<br>2、{}.fromkeys().keys()<br>3、set()+sort()<br>4、排序后比较相邻2个元素的数据，重复的删除</p>
<h2 id="4、噪音处理"><a href="#4、噪音处理" class="headerlink" title="4、噪音处理"></a>4、<strong>噪音处理</strong></h2><p> 噪音，是被测量变量的随机误差或方差。</p>
<h3 id="噪音与离群点"><a href="#噪音与离群点" class="headerlink" title="噪音与离群点"></a>噪音与离群点</h3><blockquote>
<p>离群点： 你正在从口袋的零钱包里面穷举里面的钱，你发现了3个一角，1个五毛，和一张100元的毛爷爷向你微笑。这个100元就是个离群点，因为并不应该常出现在口袋里..</p>
<p>噪声： 你晚上去三里屯喝的酩酊大醉，很需要买点东西清醒清醒，这时候你开始翻口袋的零钱包，嘛，你发现了3个一角，1个五毛，和一张100元的毛爷爷向你微笑。但是你突然眼晕，把那三个一角看成了三个1元…这样错误的判断使得数据集中出现了噪声。</p>
</blockquote>
<h3 id="噪音处理方法"><a href="#噪音处理方法" class="headerlink" title="噪音处理方法"></a>噪音处理方法</h3><p><strong>1.分箱法</strong><br>分箱方法通过考察数据的“近邻”（即，周围的值）来光滑有序数据值。这些有序的值被分布到一些“桶”或箱中。由于分箱方法考察近邻的值，因此它进行局部光滑。</p>
<ul>
<li>用箱均值光滑：箱中每一个值被箱中的平均值替换。</li>
<li>用箱中位数平滑：箱中的每一个值被箱中的中位数替换。</li>
<li>用箱边界平滑：箱中的最大和最小值同样被视为边界。箱中的每一个值被最近的边界值替换。</li>
</ul>
<p>一般而言，宽度越大，光滑效果越明显。箱也可以是等宽的，其中每个箱值的区间范围是个常量。分箱也可以作为一种离散化技术使用.</p>
<p><strong>2.  回归法</strong><br>　　可以用一个函数拟合数据来光滑数据。线性回归涉及找出拟合两个属性（或变量）的“最佳”直线，使得一个属性能够预测另一个。多线性回归是线性回归的扩展，它涉及多于两个属性，并且数据拟合到一个多维面。使用回归，找出适合数据的数学方程式，能够帮助消除噪声。</p>
<h2 id="5、其他实用小技巧"><a href="#5、其他实用小技巧" class="headerlink" title="5、其他实用小技巧"></a>5、其他实用小技巧</h2><p>1.<strong>去掉文件中多余的空行</strong><br>空行主要指的是（\n,\r,\r\n,\n\r等），在python中有个strip()的方法，该方法可以去掉字符串两端多余的“空白”，此处的空白主要包括空格，制表符(\t)，换行符。不过亲测以后发现，strip()可以匹配掉\n,\r\n,\n\r等，但是过滤不掉单独的\r。为了万无一失，我还是喜欢用麻烦的办法。</p>
<p>2.<strong>如何判断文件的编码格式</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">import chardet</span><br><span class="line">if chardet.detect(data)[&apos;encoding&apos;] != &apos;utf-8&apos;</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">批量处理编码格式转换的代码已上传到github上</span><br></pre></td></tr></table></figure>
<h1 id="数据转换"><a href="#数据转换" class="headerlink" title="数据转换"></a>数据转换</h1><h2 id="1、离散型"><a href="#1、离散型" class="headerlink" title="1、离散型"></a>1、离散型</h2><p>1、<strong>one-hot 编码</strong><br>编码后得到哑变量。统计这个特征上有多少类，就设置几维的向量，pd.get_dummies()可以进行one-hot编码。</p>
<blockquote>
<p>sklearn.preprocessing.OneHotEncoder(_n_values=’auto’_, _categorical_features=’all’_, _dtype=<class 'float'="">_, _sparse=True_, _handle_unknown=’error’_)</class></p>
<p><strong>n_values</strong> : ‘auto’, int or array of ints 每个特征的数量</p>
<blockquote>
<p>auto : 从训练数据的范围中得到<br>     int : 所有特征的最大值（number）<br>     array : 每个特征的最大值（number）</p>
</blockquote>
<p><strong>categorical_features: “all” or array of indices or mask</strong> :确定哪些特征是类别特征</p>
<blockquote>
<p>all (默认): 所有特征都是类别特征，意味着所有特征都要进行OneHot编码<br>    array of indices: 类别特征的数组索引<br>    mask: n_features 长度的数组，切dtype = bool<br>非类别型特征通常会放到矩阵的右边</p>
</blockquote>
<p><strong>dtype</strong> : number type, default=np.float<br>输出数据的类型<br><strong>sparse</strong> : boolean, default=True<br>设置True会返回稀疏矩阵，否则返回数组<br><strong>handle_unknown</strong> : str, ‘error’ or ‘ignore’<br>当一个不明类别特征出现在变换中时，报错还是忽略</p>
</blockquote>
<p>２、<strong>Hash编码成词向量</strong>：<br><img src="http://p4rlzrioq.bkt.clouddn.com/hash%E7%BC%96%E7%A0%81.jpg" alt=""></p>
<h2 id="2、文本型"><a href="#2、文本型" class="headerlink" title="2、文本型"></a>2、文本型</h2><p>１. <strong>词袋</strong>：文本数据预处理后，去掉停用词，剩下的词组成的list，在词库中的映射稀疏向量。Python中用CountVectorizer处理词袋．<br>２. 把词袋中的词扩充到<strong>n-gram</strong>：n-gram代表n个词的组合。比如“我喜欢你”、“你喜欢我”这两句话如果用词袋表示的话，分词后包含相同的三个词，组成一样的向量：“我 喜欢 你”。显然两句话不是同一个意思，用n-gram可以解决这个问题。如果用2-gram，那么“我喜欢你”的向量中会加上“我喜欢”和“喜欢你”，“你喜欢我”的向量中会加上“你喜欢”和“喜欢我”。这样就区分开来了。<br>３. 使用<strong>TF-IDF</strong>特征：TF-IDF是一种统计方法，用以评估一字词对于一个文件集或一个语料库中的其中一份文件的重要程度。字词的重要性随着它在文件中出现的次数成正比增加，但同时会随着它在语料库中出现的频率成反比下降。TF(t) = (词t在当前文中出现次数) / (t在全部文档中出现次数)，IDF(t) = ln(总文档数/ 含t的文档数)，TF-IDF权重 = TF(t) * IDF(t)。自然语言处理中经常会用到。</p>
<h2 id="3、数值型"><a href="#3、数值型" class="headerlink" title="3、数值型"></a>3、数值型</h2><h3 id="归一化（Normalization）"><a href="#归一化（Normalization）" class="headerlink" title="归一化（Normalization）"></a>归一化（Normalization）</h3><p><img src="http://p4rlzrioq.bkt.clouddn.com/%E5%BD%92%E4%B8%80%E5%8C%96.svg" alt="link"><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">X_train = np.array([[1., -1., 2.], [2., 0., 0.], [0., 1., -1.]])</span><br><span class="line">min_max_scaler = preprocessing.MinMaxScaler()</span><br><span class="line">X_train_minmax = min_max_scaler.fit_transform(X_train)</span><br><span class="line">#将上述得到的scale参数应用至测试数据</span><br><span class="line">X_test = np.array([[ -3., -1., 4.]]) </span><br><span class="line">X_test_minmax = min_max_scaler.transform(X_test)</span><br></pre></td></tr></table></figure></p>
<h3 id="区间缩放（scaling）"><a href="#区间缩放（scaling）" class="headerlink" title="区间缩放（scaling）"></a>区间缩放（scaling）</h3><p><img src="http://p4rlzrioq.bkt.clouddn.com/%E7%BC%A9%E6%94%BE.svg" alt="link"></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">X_train = np.array([[ 1., -1.,  2.],</span><br><span class="line">                    [ 2.,  0.,  0.],</span><br><span class="line">                    [ 0.,  1., -1.]])</span><br><span class="line">max_abs_scaler = preprocessing.MaxAbsScaler() </span><br><span class="line">X_train_maxabs = max_abs_scaler.fit_transform(X_train)</span><br><span class="line">X_test_maxabs = max_abs_scaler.transform(X_test)</span><br><span class="line">X_test_maxabs = max_abs_scaler.transform(X_test)</span><br></pre></td></tr></table></figure>
<h3 id="标准化（Standardization）"><a href="#标准化（Standardization）" class="headerlink" title="标准化（Standardization）"></a>标准化（Standardization）</h3><h4 id="适用情况"><a href="#适用情况" class="headerlink" title="适用情况"></a>适用情况</h4><p>看模型是否具有伸缩不变性。<br> 不是所有的模型都一定需要标准化，有些模型对量纲不同的数据比较敏感，譬如SVM等。当各个维度进行不均匀伸缩后，最优解与原来不等价，这样的模型，除非原始数据的分布范围本来就不叫接近，否则<strong>必须</strong>进行标准化，以免模型参数被分布范围较大或较小的数据主导。<br>但是如果模型在各个维度进行不均匀伸缩后，最优解与原来等价，例如logistic regression等，对于这样的模型，是否标准化理论上不会改变最优解。但是，由于实际求解往往使用迭代算法，如果目标函数的形状太“扁”，迭代算法可能收敛得很慢甚至不收敛。<br>所以对于具有伸缩不变性的模型，<strong>最好</strong>也进行数据标准化。</p>
<p><img src="http://p4rlzrioq.bkt.clouddn.com/%E6%A0%87%E5%87%86%E5%8C%96.svg" alt="link"><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">from sklearn import preprocessing  </span><br><span class="line">import numpy as np </span><br><span class="line">X = np.array([[1., -1., 2.], [2., 0., 0.], [0., 1., -1.]])  </span><br><span class="line">X_scaled = preprocessing.scale(X)</span><br></pre></td></tr></table></figure></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">scaler = preprocessing.StandardScaler().fit(X) </span><br><span class="line">#测试将该scaler用于输入数据，变换之后得到的结果同上</span><br><span class="line">scaler.transform(X)</span><br></pre></td></tr></table></figure>
<h3 id="二值化"><a href="#二值化" class="headerlink" title="二值化"></a><strong>二值化</strong></h3><p><strong>1.特征二值化</strong><br>特征二值化是把数值特征转化成布尔值的过程。这个方法对符合多变量伯努利分布的输入数据进行预测概率参数很有效。详细可以见这个例子<a href="http://scikit-learn.org/stable/modules/generated/sklearn.neural_network.BernoulliRBM.html#sklearn.neural_network.BernoulliRBM" title="sklearn.neural_network.BernoulliRBM" target="_blank" rel="noopener">sklearn.neural_network.BernoulliRBM</a>.</p>
<p>对于 <a href="http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.Normalizer.html#sklearn.preprocessing.Normalizer" title="sklearn.preprocessing.Normalizer" target="_blank" rel="noopener">Normalizer</a>，<a href="http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.Binarizer.html#sklearn.preprocessing.Binarizer" title="sklearn.preprocessing.Binarizer" target="_blank" rel="noopener">Binarizer</a>工具类通常是在Pipeline阶段（<a href="http://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html#sklearn.pipeline.Pipeline" title="sklearn.pipeline.Pipeline" target="_blank" rel="noopener">sklearn.pipeline.Pipeline</a>）的前期过程会用到。</p>
<h2 id="4、比赛实际场景"><a href="#4、比赛实际场景" class="headerlink" title="4、比赛实际场景"></a>4、比赛实际场景</h2><p><img src="http://p4rlzrioq.bkt.clouddn.com/%E6%AF%94%E8%B5%9B%E5%9C%BA%E6%99%AF1.jpg" alt="link"><br><img src="http://p4rlzrioq.bkt.clouddn.com/%E6%AF%94%E8%B5%9B%E5%9C%BA%E6%99%AF2.jpg" alt="link"><br>可见，选手需要进行制定规则、数据清洗、各个种类的特征处理等，对特征的研究是非常细化的。</p>
<h1 id="特征衍生"><a href="#特征衍生" class="headerlink" title="特征衍生"></a>特征衍生</h1><h2 id="组合特征"><a href="#组合特征" class="headerlink" title="组合特征"></a>组合特征</h2><p>1. 拼接型：简单的组合特征。例如挖掘用户对某种类型的喜爱，对用户和类型做拼接。正负权重，代表喜欢或不喜欢某种类型。 </p>
<ul>
<li>user_id&amp;&amp;category: 10001&amp;&amp;女裙 10002&amp;&amp;男士牛仔 </li>
<li>user_id&amp;&amp;style: 10001&amp;&amp;蕾丝 10002&amp;&amp;全棉　　<br>2. 模型特征组合： </li>
<li>用GBDT产出特征组合路径 </li>
<li>组合特征和原始特征一起放进LR训练</li>
</ul>
<h2 id="生成多项式特征"><a href="#生成多项式特征" class="headerlink" title="生成多项式特征"></a>生成多项式特征</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">X = np.arange(9).reshape(3, 3)</span><br><span class="line">#只需要特征的交叉项，可以设置interaction_only=True</span><br><span class="line">poly = PolynomialFeatures(degree=3, interaction_only=True)</span><br><span class="line">poly.fit_transform(X)</span><br></pre></td></tr></table></figure>
<p>此方法经常用于核方法中</p>
<h2 id="自定义特征"><a href="#自定义特征" class="headerlink" title="自定义特征"></a>自定义特征</h2><p>1.想用对数据取对数，可以自己用 <a href="http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.FunctionTransformer.html#sklearn.preprocessing.FunctionTransformer" title="sklearn.preprocessing.FunctionTransformer" target="_blank" rel="noopener">FunctionTransformer</a>自定义一个转化器,并且可以在Pipeline中使用`</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.preprocessing import FunctionTransformer </span><br><span class="line">transformer = FunctionTransformer(np.log1p)#括号内的就是自定义函数</span><br><span class="line">X = np.array([[0, 1], [2, 3]]) </span><br><span class="line">transformer.transform(X)</span><br></pre></td></tr></table></figure>
<p>2.如果你在做一个分类任务时，发现第一主成分与这个不相关，你可以用<a href="http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.FunctionTransformer.html#sklearn.preprocessing.FunctionTransformer" title="sklearn.preprocessing.FunctionTransformer" target="_blank" rel="noopener">FunctionTransformer</a>把第一列除去，剩下的列用PCA</p>
<h1 id="特征选择"><a href="#特征选择" class="headerlink" title="特征选择"></a>特征选择</h1><p><strong>特征选择</strong>，就是从多个特征中，挑选出一些对结果预测最有用的特征。因为原始的特征中可能会有冗余和噪声。 </p>
<h2 id="1-过滤型"><a href="#1-过滤型" class="headerlink" title="1 过滤型"></a>1 过滤型</h2><ul>
<li>方法：  评估单个特征和结果值之间的相关程度， 排序留下Top相关的特征部分。 </li>
<li>评价方式：Pearson相关系数， 互信息， 距离相关度。 </li>
<li>缺点：只评估了单个特征对结果的影响，没有考虑到特征之间的关联作用， 可能把有用的关联特征误踢掉。因此工业界使用比较少。 </li>
<li>python包：SelectKBest指定过滤个数、SelectPercentile指定过滤百分比。</li>
</ul>
<h2 id="2-包裹型"><a href="#2-包裹型" class="headerlink" title="2 包裹型"></a>2 包裹型</h2><ul>
<li>方法：把特征选择看做一个特征子集搜索问题， 筛选各种特征子集， 用模型评估效果。 </li>
<li>典型算法：“递归特征删除算法”。 </li>
<li>应用在逻辑回归的过程：用全量特征跑一个模型；根据线性模型的系数(体现相关性)，删掉5-10%的弱特征，观察准确率/auc的变化；逐步进行， 直至准确率/auc出现大的下滑停止。 </li>
<li>python包：RFE </li>
</ul>
<h2 id="3-嵌入型"><a href="#3-嵌入型" class="headerlink" title="3 嵌入型"></a>3 嵌入型</h2><ul>
<li>方法：根据模型来分析特征的重要性，最常见的方式为用正则化方式来做特征选择。 </li>
<li>举例：最早在电商用LR做CTR预估， 在3-5亿维的系数特征上用L1正则化的LR模型。上一篇介绍了L1正则化有截断作用，剩余2-3千万的feature， 意味着其他的feature重要度不够。 </li>
<li>python包：feature_selection.SelectFromModel选出权重不为0的特征。</li>
</ul>
<h1 id="特征降维"><a href="#特征降维" class="headerlink" title="特征降维"></a>特征降维</h1><pre><code>       在数据处理中，经常会遇到特征维度比样本数量多得多的情况，如果拿到实际工程中去跑，效果不一定好。
    一是因为冗余的特征会带来一些噪音，影响计算的结果；
    二是因为无关的特征会加大计算量，耗费时间和资源。所以我们通常会对数据重新变换一下，再跑模型。数据变换的目的不仅仅是降维，还可以消除特征之间的相关性，并发现一些潜在的特征变量。
</code></pre><h2 id="PCA-过程"><a href="#PCA-过程" class="headerlink" title="PCA 过程"></a>PCA 过程</h2><p>1.去掉数据的类别特征（label），将去掉后的d维数据作为样本<br>2.计算d维的均值向量（即所有数据的每一维向量的均值）<br>3.计算所有数据的散布矩阵（或者协方差矩阵）<br>4.计算特征值（e1,e2,…,ed）以及相应的特征向量（lambda1,lambda2,…,lambda d）<br>5.按照特征值的大小对特征向量降序排序，选择前k个最大的特征向量，组成d<em>k维的矩阵W（其中每一列代表一个特征向量）<br>6.运用d</em>K的特征向量矩阵W将样本数据变换成新的子空间。（用数学式子表达就是<img src="http://p4rlzrioq.bkt.clouddn.com/pca%E9%99%8D%E7%BB%B4%E5%A4%84%E7%90%86.png" alt="">，其中x是d<em>1维的向量，代表一个样本，y是K</em>1维的在新的子空间里的向量）</p>
<p>python里有已经写好的模块，可以直接拿来用，但是我觉得不管什么模块，都要懂得它的原理是什么。matplotlib有<a href="https://www.clear.rice.edu/comp130/12spring/pca/pca_docs.shtml" target="_blank" rel="noopener">matplotlib.mlab.PCA()</a>，sklearn也有专门一个模块<a href="http://scikit-learn.org/stable/modules/decomposition.html#decompositions" target="_blank" rel="noopener">Dimensionality reduction</a>专门讲PCA，包括传统的PCA，也就是我上文写的，以及增量PCA，核PCA等等，除了PCA以外，还有ZCA白化等等，在图像处理中也经常会用到。</p>
<p>　　推荐一个博客，动态展示了PCA的过程：<a href="http://setosa.io/ev/principal-component-analysis/" target="_blank" rel="noopener">http://setosa.io/ev/principal-component-analysis/</a>  写的也很清楚，可以看一下；再推荐一个维基百科的，讲的真的是详细啊<a href="https://en.wikipedia.org/wiki/Principal_component_analysis" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Principal_component_analysis</a></p>
<h1 id="线性回归模型"><a href="#线性回归模型" class="headerlink" title="线性回归模型"></a>线性回归模型</h1><h2 id="线性回归的正则化"><a href="#线性回归的正则化" class="headerlink" title="线性回归的正则化"></a>线性回归的正则化</h2><h3 id="Lasso回归"><a href="#Lasso回归" class="headerlink" title="Lasso回归"></a>Lasso回归</h3><ul>
<li>线性回归的L1正则化通常称为Lasso回归，α来调节损失函数的均方差项和正则化项的权重。</li>
<li>Lasso回归可以使得一些特征的系数变小，甚至还是一些绝对值较小的系数直接变为0，故具有特征选择的功能，增强了模型的泛化能力。</li>
</ul>
<h3 id="岭回归"><a href="#岭回归" class="headerlink" title="岭回归"></a>岭回归</h3><ul>
<li>线性回归的L2正则化通常称为Ridge回归。</li>
<li>Ridge回归在不抛弃任何一个特征的情况下，缩小了回归系数，使得模型相对而言比较的稳定，但和Lasso回归比，这会使得模型的特征留的特别多，模型解释性差。</li>
<li>Ridge回归的求解比较简单，一般用最小二乘法。</li>
</ul>
<p><strong>L1正则化产生稀疏的权值, 具有特征选择的作用；L2正则化产生平滑的权值</strong>。</p>
<p><img src="http://p4rlzrioq.bkt.clouddn.com/L1,L2%E6%AD%A3%E5%88%99%E5%8C%96.png" alt=""></p>
<h2 id="最小二乘法的局限性"><a href="#最小二乘法的局限性" class="headerlink" title="最小二乘法的局限性"></a>最小二乘法的局限性</h2><ol>
<li>最小二乘法需要计算XTX的逆矩阵，有可能它的逆矩阵不存在，这样就没有办法直接用最小二乘法了</li>
<li>当样本特征n非常的大的时候，计算XTX的逆矩阵是一个非常耗时的工作（nxn的矩阵求逆），当然，我们可以通过对样本数据进行整理，去掉冗余特征。让XTX的行列式不为0，然后继续使用最小二乘法。</li>
<li>如果拟合函数不是线性的，这时无法使用最小二乘法，需要通过一些技巧转化为线性才能使用</li>
<li>当样本量m很少，小于特征数n的时候，这时拟合方程是欠定的，常用的优化方法都无法去拟合数据。当样本量m等于特征数n的时候，用方程组求解就可以了。当m大于n时，拟合方程是超定的，也就是我们常用与最小二乘法的场景了。</li>
</ol>
<h1 id="决策树"><a href="#决策树" class="headerlink" title="决策树"></a>决策树</h1><h2 id="决策树构建中的分裂准则"><a href="#决策树构建中的分裂准则" class="headerlink" title="决策树构建中的分裂准则"></a>决策树构建中的分裂准则</h2><p>决策树可以通过一系列规则递归地分割特征空间</p>
<h3 id="信息增益（information-gain）"><a href="#信息增益（information-gain）" class="headerlink" title="信息增益（information gain）"></a><strong>信息增益（information gain）</strong></h3><p>属性划分减少的信息熵，信息熵是度量样本集合纯度的一种指标，假设第k类样本所占比例为pk，则数据集D的信息熵为：Ent(D)=-∑pklogpk，Ent(D)越小，D的纯度越高。 Gain(D,a)=Ent(D)-∑(Dv/D*Ent(Dv))，Dv是某个属性a的某个可能取值的样本集合</p>
<h3 id="增益率（gain-ratio）"><a href="#增益率（gain-ratio）" class="headerlink" title="增益率（gain ratio）"></a><strong>增益率（gain ratio）</strong></h3><p>信息增益准则对可取值数目较多的属性有偏好，为减少这种偏好的不利影响，使用增益率选择最优划分属性，增益率定义为:Gain_ratio(D,a)=Gain(D,a)/IV(a), IV(a)=-∑(Dv/D*log(Dv/D))，IV(a)称为为a的固有值。属性可能取值数目越多，IV(a)的值越大，增益率即增益/固有值。</p>
<h3 id="基尼指数-Gini-index"><a href="#基尼指数-Gini-index" class="headerlink" title="基尼指数(Gini index)"></a><strong>基尼指数(Gini index)</strong></h3><p>基尼指数是另外一种数据的不纯度的度量方法，其定义如下：</p>
<p><img src="http://p4rlzrioq.bkt.clouddn.com/gini%E7%B3%BB%E6%95%B01.jpg" alt="">　　</p>
<p>其中的m仍然表示数据集D中类别C的个数，Pi表示D中任意一个记录属于Ci的概率，计算时Pi=(D中属于Ci类的集合的记录个数/|D|)。如果所有的记录都属于同一个类中，则P1=1，Gini(D)=0，此时不纯度最低。<br>在CART(Classification and Regression Tree)算法中利用基尼指数构造二叉决策树，对每个属性都会枚举其属性的非空真子集，以属性R分裂后的基尼系数为：</p>
<p><img src="http://p4rlzrioq.bkt.clouddn.com/%E5%9F%BA%E5%B0%BC%E7%B3%BB%E6%95%B02.jpg" alt=""></p>
<p>D1为D的一个非空真子集，D2为D1在D的补集，即D1+D2=D，对于属性R来说，有多个真子集，即GiniR(D)有多个值，但我们选取最小的那么值作为R的基尼指数。最后：</p>
<p><img src="http://p4rlzrioq.bkt.clouddn.com/%E5%9F%BA%E5%B0%BC%E7%B3%BB%E6%95%B03.jpg" alt=""></p>
<p>对于二类分类，基尼系数和熵之半的曲线如下：</p>
<p><img src="https://upload-images.jianshu.io/upload_images/40658-24f62052d3f57559.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/700" alt="link"></p>
<p>从上图可以看出，基尼系数和熵之半的曲线非常接近，仅仅在45度角附近误差稍大。因此，基尼系数可以做为熵模型的一个近似替代</p>
<h2 id="常用决策树模型"><a href="#常用决策树模型" class="headerlink" title="常用决策树模型"></a>常用决策树模型</h2><h3 id="决策树模型总结"><a href="#决策树模型总结" class="headerlink" title="决策树模型总结"></a>决策树模型总结</h3><div class="table-container">
<table>
<thead>
<tr>
<th>算法</th>
<th>支持模型</th>
<th>树结构</th>
<th>特征选择</th>
<th>连续值处理</th>
<th>缺失值处理</th>
<th>剪枝</th>
</tr>
</thead>
<tbody>
<tr>
<td>ID3</td>
<td>分类</td>
<td>多叉树</td>
<td>信息增益</td>
<td>不支持</td>
<td>不支持</td>
<td>不支持</td>
</tr>
<tr>
<td>C4.5</td>
<td>分类</td>
<td>多叉树</td>
<td>信息增益比</td>
<td>支持</td>
<td>支持</td>
<td>支持</td>
</tr>
<tr>
<td>CART</td>
<td>分类，回归</td>
<td>二叉树</td>
<td>基尼系数，均方差</td>
<td>支持</td>
<td>支持</td>
<td>支持</td>
</tr>
</tbody>
</table>
</div>
<h3 id="CART决策树属性分裂方法"><a href="#CART决策树属性分裂方法" class="headerlink" title="CART决策树属性分裂方法"></a>CART决策树属性分裂方法</h3><ol>
<li>m个样本的连续特征A有m个，从小到大排列为a1,a2,…,ama1,a2,…,am,则CART算法取相邻两样本值的中位数，一共取得m-1个划分点。</li>
<li>对于这m-1个点，分别计算以该点作为二元分类点时的基尼系数。选择基尼系数最小的点作为该连续特征的二元离散分类点。</li>
</ol>
<h2 id="决策树优化方法"><a href="#决策树优化方法" class="headerlink" title="决策树优化方法"></a>决策树优化方法</h2><h3 id="后剪枝（postpruning）"><a href="#后剪枝（postpruning）" class="headerlink" title="后剪枝（postpruning）"></a>后剪枝（postpruning）</h3><p>先从训练集生成一颗完整的决策树，然后自底向上地对非叶节点进行考察，若将该结点子树替换成叶节点能提升泛化性能，则进行替换，后剪枝训练时间开销大。</p>
<h3 id="预剪枝（prepruning）"><a href="#预剪枝（prepruning）" class="headerlink" title="预剪枝（prepruning）"></a>预剪枝（prepruning）</h3><p>在决策树生成过程中，对每个结点在划分前先进行估计，若当前结点的划分不能带来决策树泛化性能的提升，则停止划分并将当前结点标记为叶节点，预剪枝基于贪心存在欠拟合的风险。</p>
<h3 id="抑制单颗决策树的复杂度的方法"><a href="#抑制单颗决策树的复杂度的方法" class="headerlink" title="抑制单颗决策树的复杂度的方法"></a>抑制单颗决策树的复杂度的方法</h3><ol>
<li>限制树的最大深度</li>
<li>限制叶子节点的最少样本数量</li>
<li>限制节点分裂时的最少样本数量</li>
<li>吸收 bagging 的思想对训练样本采样，在学习单颗决策树时只使用一部分训练样本</li>
<li>借鉴随机森林的思路在学习单颗决策树时只采样一部分特征，在目标函数中添加正则项惩罚复杂的树结。</li>
</ol>
<h2 id="决策树算法的优点"><a href="#决策树算法的优点" class="headerlink" title="决策树算法的优点"></a>决策树算法的优点</h2><ol>
<li>基本不需要预处理，不需要提前归一化，处理缺失值。</li>
<li>使用决策树预测的代价是O(log2m)。 m为样本数。</li>
<li>既可以处理离散值也可以处理连续值。很多算法只是4.专注于离散值或者连续值。</li>
<li>可以处理多维度输出的分类问题。</li>
<li>相比于神经网络之类的黑盒分类模型，决策树在逻辑上可以得到很好的解释</li>
<li>可以交叉验证的剪枝来选择模型，从而提高泛化能力。</li>
<li>对于异常点的容错能力好，健壮性高。</li>
</ol>
<h2 id="决策树算法的缺陷"><a href="#决策树算法的缺陷" class="headerlink" title="决策树算法的缺陷"></a>决策树算法的缺陷</h2><ol>
<li>决策树算法非常容易过拟合，导致泛化能力不强。可以通过设置节点最少样本数量和限制决策树深度来改进。</li>
<li>决策树会因为样本发生一点点的改动，就会导致树结构的剧烈改变。这个可以通过集成学习之类的方法解决。</li>
<li>寻找最优的决策树是一个NP难的问题，我们一般是通过启发式方法，容易陷入局部最优。可以通过集成学习之类的方法来改善。</li>
<li>有些比较复杂的关系，决策树很难学习，比如异或。这个就没有办法了，一般这种关系可以换神经网络分类方法来解决。</li>
<li>如果某些特征的样本比例过大，生成决策树容易偏向于这些特征。这个可以通过调节样本权重来改善。</li>
</ol>
<h1 id="梯度"><a href="#梯度" class="headerlink" title="梯度"></a>梯度</h1><p>在最小化损失函数时，可以通过梯度下降法来一步步的迭代求解，得到最小化的损失函数，和模型参数值。反过来，如果我们需要求解损失函数的最大值，这时就需要用梯度上升法来迭代了。</p>
<h2 id="梯度下降法的超参数"><a href="#梯度下降法的超参数" class="headerlink" title="梯度下降法的超参数"></a>梯度下降法的超参数</h2><ul>
<li>步长（step size）<br>学习速率（learning rate）乘以偏导数的值，即梯度下降中的步长。<br><img src="http://p4rlzrioq.bkt.clouddn.com/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D.jpg" alt=""></li>
</ul>
<h2 id="梯度下降的算法调优"><a href="#梯度下降的算法调优" class="headerlink" title="梯度下降的算法调优"></a>梯度下降的算法调优</h2><ol>
<li><p>算法的步长选择。在前面的算法描述中，我提到取步长为1，但是实际上取值取决于数据样本，可以多取一些值，从大到小，分别运行算法，看看迭代效果，如果损失函数在变小，说明取值有效，否则要增大步长。前面说了。步长太大，会导致迭代过快，甚至有可能错过最优解。步长太小，迭代速度太慢，很长时间算法都不能结束。所以算法的步长需要多次运行后才能得到一个较为优的值。</p>
</li>
<li><p>算法参数的初始值选择。 初始值不同，获得的最小值也有可能不同，因此梯度下降求得的只是局部最小值；当然如果损失函数是凸函数则一定是最优解。由于有局部最优解的风险，需要多次用不同初始值运行算法，关键损失函数的最小值，选择损失函数最小化的初值。</p>
</li>
<li><p>标准化。由于样本不同特征的取值范围不一样，可能导致迭代很慢，为了减少特征取值的影响，可以对特征数据标准化，这样特征的新期望为0，新方差为1，迭代次数可以大大加快。<br><img src="http://p4rlzrioq.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E6%A0%87%E5%87%86%E5%8C%96%E4%BC%98%E5%8A%BF.png" alt=""></p>
</li>
</ol>
<h2 id="梯度下降方法总结"><a href="#梯度下降方法总结" class="headerlink" title="梯度下降方法总结"></a>梯度下降方法总结</h2><h3 id="批梯度下降-batch-gradient-descent-BGD"><a href="#批梯度下降-batch-gradient-descent-BGD" class="headerlink" title="批梯度下降(batch gradient descent/BGD)"></a>批梯度下降(batch gradient descent/BGD)</h3><p>求梯度的时候就用了所有m个样本的梯度数据。</p>
<h3 id="随机梯度下降（stochastic-gradient-descent-SGD）"><a href="#随机梯度下降（stochastic-gradient-descent-SGD）" class="headerlink" title="随机梯度下降（stochastic gradient descent/SGD）"></a>随机梯度下降（stochastic gradient descent/SGD）</h3><p>随机梯度下降法由于每次仅仅采用一个样本来迭代。优点是速度快以及可以跳出局部最优解，缺点是导致迭代方向变化很大，不能很快的收敛到局部最优解。</p>
<h3 id="小批量随机梯度下降（mini-batch-stochastic-gradient-descent）"><a href="#小批量随机梯度下降（mini-batch-stochastic-gradient-descent）" class="headerlink" title="小批量随机梯度下降（mini-batch stochastic gradient descent）"></a>小批量随机梯度下降（mini-batch stochastic gradient descent）</h3><p>小批量梯度下降法是批量梯度下降法和随机梯度下降法的折衷，也就是对于m个样本，我们采用x个样子来迭代，1&lt;x&lt;m。一般可以取x=10，当然根据样本的数据，可以调整这个x的值。</p>
<h2 id="梯度下降法与最小二乘法"><a href="#梯度下降法与最小二乘法" class="headerlink" title="梯度下降法与最小二乘法"></a>梯度下降法与最小二乘法</h2><ul>
<li>梯度下降法和最小二乘法相比，梯度下降法需要选择步长，而最小二乘法不需要。</li>
<li>梯度下降法是迭代求解，最小二乘法是计算解析解。如果样本量不算很大，且存在解析解，最小二乘法比起梯度下降法要有优势，计算速度很快。但是如果样本量很大，用最小二乘法由于需要求一个超级大的逆矩阵，这时就很难或者很慢才能求解解析解了，使用迭代的梯度下降法比较有优势。</li>
</ul>
<h1 id="分类模型指标"><a href="#分类模型指标" class="headerlink" title="分类模型指标"></a>分类模型指标</h1><h2 id="混淆矩阵（confusion-matrix）"><a href="#混淆矩阵（confusion-matrix）" class="headerlink" title="混淆矩阵（confusion matrix）"></a>混淆矩阵（confusion matrix）</h2><p><img src="https://upload-images.jianshu.io/upload_images/145616-0a7a7fd1ff77dcd9.png" alt="link"></p>
<h2 id="准确率（Accuracy）"><a href="#准确率（Accuracy）" class="headerlink" title="准确率（Accuracy）"></a>准确率（Accuracy）</h2><p><strong>准确率</strong>是预测和标签一致的样本在所有样本中所占的比例</p>
<p><img src="http://p4rlzrioq.bkt.clouddn.com/%E5%87%86%E7%A1%AE%E7%8E%87%EF%BC%88Accuracy%EF%BC%89.svg" alt="link"></p>
<h2 id="精确率（Precision）"><a href="#精确率（Precision）" class="headerlink" title="精确率（Precision）"></a>精确率（Precision）</h2><p><strong>精确率</strong>是你预测为正类的数据中，有多少确实是正类</p>
<p><img src="http://p4rlzrioq.bkt.clouddn.com/%E6%9F%A5%E5%87%86%E7%8E%87%EF%BC%88Precision%EF%BC%89.svg" alt="link"></p>
<h2 id="查全率（Recall）"><a href="#查全率（Recall）" class="headerlink" title="查全率（Recall）"></a>查全率（Recall）</h2><p><strong>查全率</strong>是所有正类的数据中，你预测为正类的数据占比</p>
<p><img src="http://p4rlzrioq.bkt.clouddn.com/%E6%9F%A5%E5%85%A8%E7%8E%87%EF%BC%88Recall%EF%BC%89.svg" alt="link"></p>
<p><img src="https://upload.wikimedia.org/wikipedia/commons/2/26/Precisionrecall.svg" alt="link"></p>
<p>不同的问题，判别标准不同。对于推荐系统，更侧重于查准率；对于医学诊断系统，更侧重于查全率。查准率和查全率是一个矛盾体，往往差准率高的情况查重率比较低。</p>
<h2 id="F1-Score"><a href="#F1-Score" class="headerlink" title="F1 Score"></a>F1 Score</h2><p>有时也用一个F1值来综合评估精确率和召回率，它是精确率和召回率的调和均值。</p>
<p><img src="http://p4rlzrioq.bkt.clouddn.com/F1%20Score.svg" alt="link"></p>
<h2 id="F-beta-Score"><a href="#F-beta-Score" class="headerlink" title="F-beta Score"></a>F-beta Score</h2><p>有时候我们对精确率和召回率并不是一视同仁，比如有时候我们更加重视精确率。我们用一个参数β来度量两者之间的关系。如果β&gt;1, 召回率有更大影响，如果β&lt;1,精确率有更大影响。</p>
<p><img src="http://p4rlzrioq.bkt.clouddn.com/F-beta%20Score.svg" alt="link"></p>
<h2 id="ROC-（receiver-operating-characteristic-curve）"><a href="#ROC-（receiver-operating-characteristic-curve）" class="headerlink" title="ROC （receiver operating characteristic curve）"></a>ROC （receiver operating characteristic curve）</h2><p>绘制方法：首先根据分类器的预测对样例进行排序，排在前面的是分类器被认为最可能为正例的样本。按照真例y方向走一个单位，遇到假例x方向走一个单位。<br>ROC曲线的横坐标为false positive rate（FPR），纵坐标为true positive rate（TPR）。<br>ROC曲线有个很好的特性：当测试集中的正负样本的分布变化的时候，ROC曲线能够保持不变。</p>
<p><img src="https://habrastorage.org/files/267/36b/ff1/26736bff158a4d82893ff85b2022cc5b.gif" alt=""></p>
<h2 id="AUC（Area-Under-the-Curve）"><a href="#AUC（Area-Under-the-Curve）" class="headerlink" title="AUC（Area Under the Curve）"></a>AUC（Area Under the Curve）</h2><p>ROC曲线下的面积，AUC的取值范围一般在0.5和1之间。AUC越大代表分类器效果更好。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/145616-ce8221a29d9c01ef.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/700" alt="link"></p>
<p>理想目标：TPR=1，FPR=0，即图中(0,1)点，故ROC曲线越靠拢(0,1)点，越偏离45度对角线越好，Sensitivity、Specificity越大效果越好。</p>
<h1 id="模型选择与评估"><a href="#模型选择与评估" class="headerlink" title="模型选择与评估"></a>模型选择与评估</h1><h2 id="算法选择"><a href="#算法选择" class="headerlink" title="算法选择"></a>算法选择</h2><p><img src="http://p4rlzrioq.bkt.clouddn.com/sklearn%20%E4%B8%AD%E6%96%87.png" alt=""></p>
<h2 id="偏差和方差"><a href="#偏差和方差" class="headerlink" title="偏差和方差"></a>偏差和方差</h2><p>偏差-方差分解（bias-variance decomposition）是解释学习算法泛化性能的一种重要工具。令：<br>x为测试样本<br>yD：x在数据集中的标记<br>y：x的真实标记<br>f(x;D):训练集D上学得的模型f在x上的预测输出<br>f(x)=E[f(x;D)] :期望预测<br>使用样本数相同的不同训练集产生的方差（variance）为：<br><img src="http://p4rlzrioq.bkt.clouddn.com/%E5%81%8F%E5%B7%AE%E6%96%B9%E5%B7%AE0.png" alt=""><br>方差描述的是预测值作为随机变量的离散程度。度量了同样大小的训练集的变动所导致的学习性能的变化，即刻画了数据扰动所造成的影响。<br>期望输出与真实标记的差别称为<strong>偏差（bias）</strong>,偏差度量了学习算法的期望预测与真实结果的偏离程度，即刻画了学习算法本身的拟合能力。偏差公式如下：<br><img src="http://p4rlzrioq.bkt.clouddn.com/%E5%81%8F%E5%B7%AE%E6%96%B9%E5%B7%AE.png" alt=""><br><strong>噪声</strong>为：（表示若不为0，就是标记错了）<br><img src="http://p4rlzrioq.bkt.clouddn.com/%E5%81%8F%E5%B7%AE%E6%96%B9%E5%B7%AE1.png" alt=""><br>噪声表达了在当前任务上任何学习算法所能达到的期望泛化误差的下界，即刻画了学习问题本身的难度。<br><strong>算法的期望泛化误差</strong>为：<br><a href="http://p4rlzrioq.bkt.clouddn.com/%E5%81%8F%E5%B7%AE%E6%96%B9%E5%B7%AE0.png" target="_blank" rel="noopener"><img src="http://p4rlzrioq.bkt.clouddn.com/%E5%81%8F%E5%B7%AE%E6%96%B9%E5%B7%AE0.png" alt=""></a><br>即泛化误差可分解为偏差、方差与噪声之和。</p>
<p><img src="http://p4rlzrioq.bkt.clouddn.com/%E5%87%86%E4%B8%8E%E7%A1%AE.jpeg" alt="link"></p>
<ul>
<li>有一些算法天生是高方差的算法。如KNN、决策树。非参数学习通常是高方差算法，对数据较为敏感，因为不对数据进行任何假设。</li>
<li>有一些算法天生就是高偏差算法。如线性回归。参数学习通常是高偏差算法，因为对数据具有极强的假设。</li>
<li>机器学习的主要挑战来自于方差，解决高方差的通常手段有：<ul>
<li>1.降低模型复杂度</li>
<li>2.减少数据维度；降噪</li>
<li>3.增加样本数</li>
<li>4.使用验证集</li>
<li>5.模型正则化</li>
</ul>
</li>
</ul>
<h2 id="泛化能力、欠拟合和过拟合"><a href="#泛化能力、欠拟合和过拟合" class="headerlink" title="泛化能力、欠拟合和过拟合"></a>泛化能力、欠拟合和过拟合</h2><p><img src="http://p4rlzrioq.bkt.clouddn.com/overfitting.jpg" alt=""></p>
<p>此图献给奋战在一线的调参侠们！</p>
<p><img src="http://p4rlzrioq.bkt.clouddn.com/machine%20learning%20funny.jpg" alt="link"></p>

      
    </div>
    
    
    

    

    <div>
      
        <div>
    
        <div style="text-align:center;color: #ccc;font-size:14px;">-------------本文结束<i class="fa fa-paw"></i>感谢您的阅读-------------</div>
    
</div>
      
    </div>

    
      <div>
        <div style="padding: 10px 0; margin: 20px auto; width: 90%; text-align: center;">
  <div>Donate comment here</div>
  <button id="rewardButton" disable="enable" onclick="var qr = document.getElementById('QR'); if (qr.style.display === 'none') {qr.style.display='block';} else {qr.style.display='none'}">
    <span>打赏</span>
  </button>
  <div id="QR" style="display: none;">

    
      <div id="wechat" style="display: inline-block">
        <img id="wechat_qr" src="/images/wechatpay.png" alt="FGY 微信支付"/>
        <p>微信支付</p>
      </div>
    

    
      <div id="alipay" style="display: inline-block">
        <img id="alipay_qr" src="/images/alipay.jpg" alt="FGY 支付宝"/>
        <p>支付宝</p>
      </div>
    

    

  </div>
</div>

      </div>
    

    
      <div>
        <ul class="post-copyright">
  <li class="post-copyright-author">
    <strong>本文作者：</strong>
    FGY
  </li>
  <li class="post-copyright-link">
    <strong>本文链接：</strong>
    <a href="http://frankblog.site/2018/05/18/机器学习基础/" title="机器学习基础（一）">http://frankblog.site/2018/05/18/机器学习基础/</a>
  </li>
  <li class="post-copyright-license">
    <strong>版权声明： </strong>
    本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/3.0/" rel="external nofollow" target="_blank">CC BY-NC-SA 3.0</a> 许可协议。转载请注明出处！
  </li>
</ul>

      </div>
    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/机器学习/" rel="tag"><i class="fa fa-tag"></i> 机器学习</a>
          
            <a href="/tags/深度学习/" rel="tag"><i class="fa fa-tag"></i> 深度学习</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2018/04/08/git学习/" rel="next" title="Git学习">
                <i class="fa fa-chevron-left"></i> Git学习
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2018/05/30/机器学习基础（二）/" rel="prev" title="机器学习基础（二）">
                机器学习基础（二） <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>
  <aside id="sidebar" class="sidebar">
    
      <div id="sidebar-dimmer"></div>
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="/images/风景.jpeg"
                alt="FGY" />
            
              <p class="site-author-name" itemprop="name">FGY</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">
            

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">24</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">10</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">31</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>

            

          </nav>


          
            <div class="feed-link motion-element">
              <a href="/atom.xml" rel="alternate">
                <i class="fa fa-rss"></i>
                RSS
              </a>
            </div>
          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/fgyeason" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i>GitHub</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="https://www.kaggle.com/fgy0303" target="_blank" title="Kaggle">
                      
                        <i class="fa fa-fw fa-database"></i>Kaggle</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="https://music.163.com/#/playlist?id=2130685222" target="_blank" title="云音乐">
                      
                        <i class="fa fa-fw fa-music"></i>云音乐</a>
                  </span>
                
            </div>
          

          
          

          

          
            <div class="links-of-blogroll motion-element links-of-blogroll-inline">
              <div class="links-of-blogroll-title">
                <i class="fa  fa-fw fa-link"></i>
                Links
              </div>
              <ul class="links-of-blogroll-list">
                
                  <li class="links-of-blogroll-item">
                    <a href="http://xgboost.apachecn.org/cn/latest/" title="XGBoost" target="_blank">XGBoost</a>
                  </li>
                
                  <li class="links-of-blogroll-item">
                    <a href="https://www.lfd.uci.edu/~gohlke/pythonlibs/#wordcloud" title="Py_whl" target="_blank">Py_whl</a>
                  </li>
                
                  <li class="links-of-blogroll-item">
                    <a href="https://www.coursera.org/" title="Coursera" target="_blank">Coursera</a>
                  </li>
                
                  <li class="links-of-blogroll-item">
                    <a href="https://juejin.im" title="掘金" target="_blank">掘金</a>
                  </li>
                
                  <li class="links-of-blogroll-item">
                    <a href="https://uqer.io/data/browse/0/?page=1" title="量化" target="_blank">量化</a>
                  </li>
                
                  <li class="links-of-blogroll-item">
                    <a href="https://www.jiqizhixin.com/" title="机器之心" target="_blank">机器之心</a>
                  </li>
                
                  <li class="links-of-blogroll-item">
                    <a href="http://tool.chinaz.com/" title="站长工具" target="_blank">站长工具</a>
                  </li>
                
              </ul>
            </div>
          
          

          
        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#机器学习应用"><span class="nav-number">1.</span> <span class="nav-text">机器学习应用</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#1、计算机视觉"><span class="nav-number">1.1.</span> <span class="nav-text">1、计算机视觉</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2、自然语言处理"><span class="nav-number">1.2.</span> <span class="nav-text">2、自然语言处理</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3、社会网络分析"><span class="nav-number">1.3.</span> <span class="nav-text">3、社会网络分析</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4、推荐系统"><span class="nav-number">1.4.</span> <span class="nav-text">4、推荐系统</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#数据挖掘流程"><span class="nav-number">1.5.</span> <span class="nav-text">数据挖掘流程</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#数据采集"><span class="nav-number">2.</span> <span class="nav-text">数据采集</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#数据分类"><span class="nav-number">2.1.</span> <span class="nav-text">数据分类</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#采样方式"><span class="nav-number">2.2.</span> <span class="nav-text">采样方式</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1、分层采样-stratified-sampling"><span class="nav-number">2.2.1.</span> <span class="nav-text">1、分层采样(stratified sampling)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2、留出法（hold-out）"><span class="nav-number">2.2.2.</span> <span class="nav-text">2、留出法（hold-out）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3、k折交叉验证（k-fold-cross-validation）"><span class="nav-number">2.2.3.</span> <span class="nav-text">3、k折交叉验证（k-fold cross validation）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4、自助法-bootstrapping"><span class="nav-number">2.2.4.</span> <span class="nav-text">4、自助法(bootstrapping)</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#数据清洗"><span class="nav-number">3.</span> <span class="nav-text">数据清洗</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#1、缺失值处理"><span class="nav-number">3.1.</span> <span class="nav-text">1、缺失值处理</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2、异常点处理"><span class="nav-number">3.2.</span> <span class="nav-text">2、异常点处理</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3、去重处理"><span class="nav-number">3.3.</span> <span class="nav-text">3、去重处理</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#dataframe格式"><span class="nav-number">3.3.1.</span> <span class="nav-text">dataframe格式</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#list格式"><span class="nav-number">3.3.2.</span> <span class="nav-text">list格式</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4、噪音处理"><span class="nav-number">3.4.</span> <span class="nav-text">4、噪音处理</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#噪音与离群点"><span class="nav-number">3.4.1.</span> <span class="nav-text">噪音与离群点</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#噪音处理方法"><span class="nav-number">3.4.2.</span> <span class="nav-text">噪音处理方法</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#5、其他实用小技巧"><span class="nav-number">3.5.</span> <span class="nav-text">5、其他实用小技巧</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#数据转换"><span class="nav-number">4.</span> <span class="nav-text">数据转换</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#1、离散型"><span class="nav-number">4.1.</span> <span class="nav-text">1、离散型</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2、文本型"><span class="nav-number">4.2.</span> <span class="nav-text">2、文本型</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3、数值型"><span class="nav-number">4.3.</span> <span class="nav-text">3、数值型</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#归一化（Normalization）"><span class="nav-number">4.3.1.</span> <span class="nav-text">归一化（Normalization）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#区间缩放（scaling）"><span class="nav-number">4.3.2.</span> <span class="nav-text">区间缩放（scaling）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#标准化（Standardization）"><span class="nav-number">4.3.3.</span> <span class="nav-text">标准化（Standardization）</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#适用情况"><span class="nav-number">4.3.3.1.</span> <span class="nav-text">适用情况</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#二值化"><span class="nav-number">4.3.4.</span> <span class="nav-text">二值化</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4、比赛实际场景"><span class="nav-number">4.4.</span> <span class="nav-text">4、比赛实际场景</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#特征衍生"><span class="nav-number">5.</span> <span class="nav-text">特征衍生</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#组合特征"><span class="nav-number">5.1.</span> <span class="nav-text">组合特征</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#生成多项式特征"><span class="nav-number">5.2.</span> <span class="nav-text">生成多项式特征</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#自定义特征"><span class="nav-number">5.3.</span> <span class="nav-text">自定义特征</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#特征选择"><span class="nav-number">6.</span> <span class="nav-text">特征选择</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-过滤型"><span class="nav-number">6.1.</span> <span class="nav-text">1 过滤型</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-包裹型"><span class="nav-number">6.2.</span> <span class="nav-text">2 包裹型</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-嵌入型"><span class="nav-number">6.3.</span> <span class="nav-text">3 嵌入型</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#特征降维"><span class="nav-number">7.</span> <span class="nav-text">特征降维</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#PCA-过程"><span class="nav-number">7.1.</span> <span class="nav-text">PCA 过程</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#线性回归模型"><span class="nav-number">8.</span> <span class="nav-text">线性回归模型</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#线性回归的正则化"><span class="nav-number">8.1.</span> <span class="nav-text">线性回归的正则化</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Lasso回归"><span class="nav-number">8.1.1.</span> <span class="nav-text">Lasso回归</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#岭回归"><span class="nav-number">8.1.2.</span> <span class="nav-text">岭回归</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#最小二乘法的局限性"><span class="nav-number">8.2.</span> <span class="nav-text">最小二乘法的局限性</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#决策树"><span class="nav-number">9.</span> <span class="nav-text">决策树</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#决策树构建中的分裂准则"><span class="nav-number">9.1.</span> <span class="nav-text">决策树构建中的分裂准则</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#信息增益（information-gain）"><span class="nav-number">9.1.1.</span> <span class="nav-text">信息增益（information gain）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#增益率（gain-ratio）"><span class="nav-number">9.1.2.</span> <span class="nav-text">增益率（gain ratio）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#基尼指数-Gini-index"><span class="nav-number">9.1.3.</span> <span class="nav-text">基尼指数(Gini index)</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#常用决策树模型"><span class="nav-number">9.2.</span> <span class="nav-text">常用决策树模型</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#决策树模型总结"><span class="nav-number">9.2.1.</span> <span class="nav-text">决策树模型总结</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#CART决策树属性分裂方法"><span class="nav-number">9.2.2.</span> <span class="nav-text">CART决策树属性分裂方法</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#决策树优化方法"><span class="nav-number">9.3.</span> <span class="nav-text">决策树优化方法</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#后剪枝（postpruning）"><span class="nav-number">9.3.1.</span> <span class="nav-text">后剪枝（postpruning）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#预剪枝（prepruning）"><span class="nav-number">9.3.2.</span> <span class="nav-text">预剪枝（prepruning）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#抑制单颗决策树的复杂度的方法"><span class="nav-number">9.3.3.</span> <span class="nav-text">抑制单颗决策树的复杂度的方法</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#决策树算法的优点"><span class="nav-number">9.4.</span> <span class="nav-text">决策树算法的优点</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#决策树算法的缺陷"><span class="nav-number">9.5.</span> <span class="nav-text">决策树算法的缺陷</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#梯度"><span class="nav-number">10.</span> <span class="nav-text">梯度</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#梯度下降法的超参数"><span class="nav-number">10.1.</span> <span class="nav-text">梯度下降法的超参数</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#梯度下降的算法调优"><span class="nav-number">10.2.</span> <span class="nav-text">梯度下降的算法调优</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#梯度下降方法总结"><span class="nav-number">10.3.</span> <span class="nav-text">梯度下降方法总结</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#批梯度下降-batch-gradient-descent-BGD"><span class="nav-number">10.3.1.</span> <span class="nav-text">批梯度下降(batch gradient descent/BGD)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#随机梯度下降（stochastic-gradient-descent-SGD）"><span class="nav-number">10.3.2.</span> <span class="nav-text">随机梯度下降（stochastic gradient descent/SGD）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#小批量随机梯度下降（mini-batch-stochastic-gradient-descent）"><span class="nav-number">10.3.3.</span> <span class="nav-text">小批量随机梯度下降（mini-batch stochastic gradient descent）</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#梯度下降法与最小二乘法"><span class="nav-number">10.4.</span> <span class="nav-text">梯度下降法与最小二乘法</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#分类模型指标"><span class="nav-number">11.</span> <span class="nav-text">分类模型指标</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#混淆矩阵（confusion-matrix）"><span class="nav-number">11.1.</span> <span class="nav-text">混淆矩阵（confusion matrix）</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#准确率（Accuracy）"><span class="nav-number">11.2.</span> <span class="nav-text">准确率（Accuracy）</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#精确率（Precision）"><span class="nav-number">11.3.</span> <span class="nav-text">精确率（Precision）</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#查全率（Recall）"><span class="nav-number">11.4.</span> <span class="nav-text">查全率（Recall）</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#F1-Score"><span class="nav-number">11.5.</span> <span class="nav-text">F1 Score</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#F-beta-Score"><span class="nav-number">11.6.</span> <span class="nav-text">F-beta Score</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#ROC-（receiver-operating-characteristic-curve）"><span class="nav-number">11.7.</span> <span class="nav-text">ROC （receiver operating characteristic curve）</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#AUC（Area-Under-the-Curve）"><span class="nav-number">11.8.</span> <span class="nav-text">AUC（Area Under the Curve）</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#模型选择与评估"><span class="nav-number">12.</span> <span class="nav-text">模型选择与评估</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#算法选择"><span class="nav-number">12.1.</span> <span class="nav-text">算法选择</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#偏差和方差"><span class="nav-number">12.2.</span> <span class="nav-text">偏差和方差</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#泛化能力、欠拟合和过拟合"><span class="nav-number">12.3.</span> <span class="nav-text">泛化能力、欠拟合和过拟合</span></a></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

<iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width=330 height=450 src="//music.163.com/outchain/player?type=0&id=2130685222&auto=1&height=430"></iframe>

      

    </div>
  </aside>




        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js">
</script>

<div class="copyright">&copy; <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">FGY</span>

  
</div>



  <div class="powered-by">
  <i class="fa fa-user-md"></i><span id="busuanzi_container_site_uv">
    本站访客数: <span id="busuanzi_value_site_uv"></span>人
  </span>
  </div>
<span>|</span>
  <div class="powered-by">
  <i class="fa fa-user-md"></i><span id="busuanzi_container_site_uv">
    访问量: <span id="busuanzi_value_site_pv"></span>次
  </span>
  </div>


<!--  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Muse</a> v5.1.4</div>



-->
<!--
<div class="theme-info">
  <div class="powered-by"></div>
  <span class="post-count">博客全站共81.2k字</span>
</div>
-->




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    
      <div id="needsharebutton-float">
        <span class="btn">
          <i class="fa fa-share-alt" aria-hidden="true"></i>
        </span>
      </div>
    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  


  











  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  

  
  
    <script type="text/javascript" src="/lib/canvas-nest/canvas-nest.min.js"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  

  
  
  
  <link rel="stylesheet" href="/lib/needsharebutton/needsharebutton.css">

  
  
  <script src="/lib/needsharebutton/needsharebutton.js"></script>

  <script>
    
    
      flOptions = {};
      
          flOptions.iconStyle = "box";
      
          flOptions.boxForm = "horizontal";
      
          flOptions.position = "middleRight";
      
          flOptions.networks = "Weibo,Wechat,Douban,QQZone,Twitter,Facebook";
      
      new needShareButton('#needsharebutton-float', flOptions);
    
  </script>

  

  
  


  

  

<!-- -->
  
</body>
</html>

<!-- 页面点击小红心 -->
<script type="text/javascript" src="/js/src/love.js"></script>
