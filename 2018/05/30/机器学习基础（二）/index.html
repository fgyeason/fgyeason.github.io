<!DOCTYPE html>



  


<html class="theme-next muse use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">


  
  
    
    
  <script src="/lib/pace/pace.min.js?v=1.0.2"></script>
  <link href="/lib/pace/pace-theme-minimal.min.css?v=1.0.2" rel="stylesheet">


 <script>     
    (function(){
        if(''){
            if (prompt('请输入文章密码') !== ''){
                alert('密码错误！');
                history.back();
            }
        }
    })();
</script>







<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="机器学习,深度学习," />





  <link rel="alternate" href="/atom.xml" title="Frank's Blog" type="application/atom+xml" />






<meta name="keywords" content="机器学习,深度学习">
<meta property="og:type" content="article">
<meta property="og:title" content="机器学习基础（二）">
<meta property="og:url" content="http://frankblog.site/2018/05/30/机器学习基础（二）/index.html">
<meta property="og:site_name" content="Frank&#39;s Blog">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="http://p4rlzrioq.bkt.clouddn.com/ai%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0.jpg">
<meta property="og:image" content="http://p4rlzrioq.bkt.clouddn.com/%E4%B8%89%E9%98%B6%E5%BC%A0%E9%87%8F.jpg">
<meta property="og:image" content="http://p4rlzrioq.bkt.clouddn.com/%E6%96%B0%E8%A7%86%E8%A7%92%E7%9C%8B%E5%BE%85%E7%9F%A9%E9%98%B5%E8%BF%90%E7%AE%97.png">
<meta property="og:image" content="http://p4rlzrioq.bkt.clouddn.com/%E6%96%B0%E8%A7%86%E8%A7%92%E7%9C%8B%E5%BE%85%E7%9F%A9%E9%98%B5%E8%BF%90%E7%AE%971.png">
<meta property="og:image" content="http://p4rlzrioq.bkt.clouddn.com/%E6%96%B0%E8%A7%86%E8%A7%92%E7%9C%8B%E5%BE%85%E7%9F%A9%E9%98%B5%E8%BF%90%E7%AE%972.png">
<meta property="og:image" content="http://p4rlzrioq.bkt.clouddn.com/%E6%96%B0%E8%A7%86%E8%A7%92%E7%9C%8B%E5%BE%85%E7%9F%A9%E9%98%B5%E8%BF%90%E7%AE%973.png">
<meta property="og:image" content="http://p4rlzrioq.bkt.clouddn.com/%E6%96%B0%E8%A7%86%E8%A7%92%E7%9C%8B%E5%BE%85%E7%9F%A9%E9%98%B5%E8%BF%90%E7%AE%974.png">
<meta property="og:image" content="http://p4rlzrioq.bkt.clouddn.com/%E6%96%B0%E8%A7%86%E8%A7%92%E7%9C%8B%E5%BE%85%E7%9F%A9%E9%98%B5%E8%BF%90%E7%AE%975.png">
<meta property="og:image" content="http://p4rlzrioq.bkt.clouddn.com/%E7%9F%A9%E9%98%B5%E5%88%86%E5%AD%90%E5%88%86%E6%AF%8D%E5%B8%83%E5%B1%80%E8%BF%90%E7%AE%97.png">
<meta property="og:image" content="http://p4rlzrioq.bkt.clouddn.com/%E7%9F%A9%E9%98%B5%E6%B1%82%E5%AF%BC%E9%9C%80%E8%A6%81%E6%B3%A8%E6%84%8F%E7%9A%84%E8%A7%84%E5%88%99.png">
<meta property="og:image" content="http://p4rlzrioq.bkt.clouddn.com/%E7%9F%A9%E9%98%B5%E6%B1%82%E5%AF%BC%E9%9C%80%E8%A6%81%E6%B3%A8%E6%84%8F%E7%9A%84%E8%A7%84%E5%88%991.png">
<meta property="og:image" content="http://p4rlzrioq.bkt.clouddn.com/%E7%9F%A9%E9%98%B5%E6%B1%82%E5%AF%BC%E9%9C%80%E8%A6%81%E6%B3%A8%E6%84%8F%E7%9A%84%E8%A7%84%E5%88%992.png">
<meta property="og:image" content="http://p4rlzrioq.bkt.clouddn.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%B8%B8%E8%A7%81%E6%B1%82%E5%AF%BC%E6%96%B9%E5%BC%8F.png">
<meta property="og:image" content="http://p4rlzrioq.bkt.clouddn.com/%E7%89%B9%E5%BE%81%E5%88%86%E8%A7%A3.jpg">
<meta property="og:image" content="http://p4rlzrioq.bkt.clouddn.com/%E7%89%B9%E5%BE%81%E5%88%86%E8%A7%A31.jpg">
<meta property="og:image" content="http://p4rlzrioq.bkt.clouddn.com/PCA.jpg">
<meta property="og:image" content="http://p4rlzrioq.bkt.clouddn.com/PCA1.jpg">
<meta property="og:image" content="http://p4rlzrioq.bkt.clouddn.com/PCA2.jpg">
<meta property="og:image" content="http://p4rlzrioq.bkt.clouddn.com/PCA3.jpg">
<meta property="og:image" content="http://p4rlzrioq.bkt.clouddn.com/%E5%A5%87%E5%BC%82%E5%80%BC%E5%88%86%E8%A7%A30.jpg">
<meta property="og:image" content="http://p4rlzrioq.bkt.clouddn.com/%E5%A5%87%E5%BC%82%E5%80%BC%E5%88%86%E8%A7%A3.jpg">
<meta property="og:image" content="http://p4rlzrioq.bkt.clouddn.com/%E6%98%8E%E5%BC%8F%E8%B7%9D%E7%A6%BB.png">
<meta property="og:image" content="http://p4rlzrioq.bkt.clouddn.com/%E4%BD%99%E5%BC%A6%E7%9B%B8%E4%BC%BC%E5%BA%A6.png">
<meta property="og:image" content="http://p4rlzrioq.bkt.clouddn.com/%E7%9A%AE%E5%B0%94%E9%80%8A%E7%9B%B8%E5%85%B3%E7%B3%BB%E6%95%B0.png">
<meta property="og:image" content="http://p4rlzrioq.bkt.clouddn.com/%E7%9A%AE%E5%B0%94%E9%80%8A%E7%B3%BB%E6%95%B0.png">
<meta property="og:image" content="http://p4rlzrioq.bkt.clouddn.com/%E6%B1%89%E6%98%8E%E8%B7%9D%E7%A6%BB.png">
<meta property="og:image" content="http://p4rlzrioq.bkt.clouddn.com/Jaccard%20%E7%9B%B8%E4%BC%BC%E6%80%A7%E7%B3%BB%E6%95%B0.png">
<meta property="og:image" content="http://p4rlzrioq.bkt.clouddn.com/%E5%8D%8F%E6%96%B9%E5%B7%AE.png">
<meta property="og:image" content="http://p4rlzrioq.bkt.clouddn.com/%E5%8D%8F%E6%96%B9%E5%B7%AE1.png">
<meta property="og:image" content="http://p4rlzrioq.bkt.clouddn.com/%E5%8D%8F%E6%96%B9%E5%B7%AE2.png">
<meta property="og:image" content="http://p4rlzrioq.bkt.clouddn.com/Pearson%E7%9B%B8%E5%85%B3%E7%B3%BB%E6%95%B0.png">
<meta property="og:image" content="http://p4rlzrioq.bkt.clouddn.com/%E5%8D%8F%E6%96%B9%E5%B7%AE%E7%9F%A9%E9%98%B5.png">
<meta property="og:image" content="http://p4rlzrioq.bkt.clouddn.com/%E7%8B%AC%E7%AB%8B%E4%B8%8E%E4%B8%8D%E7%9B%B8%E5%85%B3.png">
<meta property="og:image" content="http://p4rlzrioq.bkt.clouddn.com/488px-Normal_Distribution_PDF.svg.png">
<meta property="og:image" content="http://p4rlzrioq.bkt.clouddn.com/%E6%AD%A3%E6%80%81%E5%88%86%E5%B8%83.png">
<meta property="og:image" content="http://p4rlzrioq.bkt.clouddn.com/%E6%8C%87%E6%95%B0%E5%88%86%E5%B8%83.jpg">
<meta property="og:image" content="http://p4rlzrioq.bkt.clouddn.com/%E5%B8%B8%E8%A7%81%E5%88%86%E5%B8%83.jpg">
<meta property="og:image" content="https://wikimedia.org/api/rest_v1/media/math/render/svg/d0070da6cb78cda75d9ff9521f85702c97862673">
<meta property="og:image" content="http://p4rlzrioq.bkt.clouddn.com/%E6%B3%B0%E5%8B%92%E5%B1%95%E5%BC%80.jpg">
<meta property="og:image" content="http://p4rlzrioq.bkt.clouddn.com/%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E6%95%B0.jpg">
<meta property="og:image" content="http://p4rlzrioq.bkt.clouddn.com/%E4%BF%A1%E6%81%AF%E7%86%B5.png">
<meta property="og:image" content="http://p4rlzrioq.bkt.clouddn.com/%E4%BF%A1%E6%81%AF%E7%86%B51.png">
<meta property="og:image" content="http://p4rlzrioq.bkt.clouddn.com/%E4%BF%A1%E6%81%AF%E7%86%B52.png">
<meta property="og:image" content="http://p4rlzrioq.bkt.clouddn.com/%E4%BF%A1%E6%81%AF%E7%86%B52.png">
<meta property="og:image" content="http://p4rlzrioq.bkt.clouddn.com/%E7%9B%B8%E5%AF%B9%E7%86%B51.png">
<meta property="og:image" content="http://p4rlzrioq.bkt.clouddn.com/%E7%9B%B8%E5%AF%B9%E7%86%B52.png">
<meta property="og:image" content="http://p4rlzrioq.bkt.clouddn.com/%E7%9B%B8%E5%AF%B9%E7%86%B53.png">
<meta property="og:image" content="http://p4rlzrioq.bkt.clouddn.com/%E7%9B%B8%E5%AF%B9%E7%86%B54.png">
<meta property="og:image" content="http://p4rlzrioq.bkt.clouddn.com/%E4%BA%92%E4%BF%A1%E6%81%AF.png">
<meta property="og:image" content="http://p4rlzrioq.bkt.clouddn.com/%E4%BA%92%E4%BF%A1%E6%81%AF1.png">
<meta property="og:image" content="http://p4rlzrioq.bkt.clouddn.com/%E4%B8%8A%E6%BA%A2%E5%92%8C%E4%B8%8B%E6%BA%A2.jpg">
<meta property="og:image" content="http://p4rlzrioq.bkt.clouddn.com/%E5%87%B8%E9%9B%86.jpg">
<meta property="og:image" content="http://oddpnmpll.bkt.clouddn.com/2016-10-05-01%3A23%3A27.jpg">
<meta property="og:image" content="http://p4rlzrioq.bkt.clouddn.com/%E5%87%B8%E5%87%BD%E6%95%B0%E7%9A%84%E4%B8%80%E9%98%B6%E6%9D%A1%E4%BB%B6.png">
<meta property="og:image" content="http://oddpnmpll.bkt.clouddn.com/2016-10-05-01%3A27%3A53.jpg">
<meta property="og:image" content="http://p4rlzrioq.bkt.clouddn.com/%E5%87%B8%E5%87%BD%E6%95%B0%E7%9A%84%E4%BA%8C%E9%98%B6%E6%9D%A1%E4%BB%B6.png">
<meta property="og:image" content="http://p4rlzrioq.bkt.clouddn.com/%E5%87%B8%E4%BC%98%E5%8C%96%E9%97%AE%E9%A2%98.jpg">
<meta property="og:image" content="http://p4rlzrioq.bkt.clouddn.com/%E7%89%9B%E9%A1%BF%E6%B3%95.jpg">
<meta property="og:image" content="http://p4rlzrioq.bkt.clouddn.com/%E7%89%9B%E9%A1%BF%E6%B3%95%E7%9A%84%E8%BF%AD%E4%BB%A3%E7%A4%BA%E6%84%8F%E5%9B%BE%E5%A6%82%E4%B8%8B.jpg">
<meta property="og:image" content="http://p4rlzrioq.bkt.clouddn.com/%E9%AB%98%E7%BB%B4%E6%83%85%E5%86%B5%E7%9A%84%E7%89%9B%E9%A1%BF%E8%BF%AD%E4%BB%A3%E5%85%AC%E5%BC%8F.jpg">
<meta property="og:image" content="http://p4rlzrioq.bkt.clouddn.com/%E7%89%9B%E9%A1%BF%E6%B3%953.jpg">
<meta property="og:image" content="http://p4rlzrioq.bkt.clouddn.com/Hessen%E7%9F%A9%E9%98%B5.jpg">
<meta property="og:updated_time" content="2018-06-09T02:34:16.203Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="机器学习基础（二）">
<meta name="twitter:image" content="http://p4rlzrioq.bkt.clouddn.com/ai%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0.jpg">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":true},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://frankblog.site/2018/05/30/机器学习基础（二）/"/>





  <title>机器学习基础（二） | Frank's Blog</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">
  
  
    
  
  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>
    
    <a href="https://github.com/fgyeason" class="github-corner" aria-label="View source on Github"><svg width="80" height="80" viewBox="0 0 250 250" style="fill:#151513; color:#fff; position: absolute; top: 0; border: 0; right: 0;" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a><style>.github-corner:hover .octo-arm{animation:octocat-wave 560ms ease-in-out}@keyframes octocat-wave{0%,100%{transform:rotate(0)}20%,60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}@media (max-width:500px){.github-corner:hover .octo-arm{animation:none}.github-corner .octo-arm{animation:octocat-wave 560ms ease-in-out}}</style>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Frank's Blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">Enjoy everything fun and challenging</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            关于
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-books">
          <a href="/books/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-book"></i> <br />
            
            书籍
          </a>
        </li>
      
        
        <li class="menu-item menu-item-films">
          <a href="/films/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-film"></i> <br />
            
            电影
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off"
             placeholder="搜索..." spellcheck="false"
             type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>
<script src="https://cdn.bootcss.com/aplayer/1.6.0/APlayer.min.js"></script>


 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://frankblog.site/2018/05/30/机器学习基础（二）/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="FGY">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/风景.jpeg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Frank's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">机器学习基础（二）</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
              
                <span class="post-meta-item-text">发表于</span>
              

              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-05-30T14:05:51+08:00">
                2018-05-30
              </time>
            

            
              <span class="post-meta-divider">|</span>
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-check-o"></i>
              </span>
              
                <span class="post-meta-item-text">更新于&#58;</span>
              
              <time title="更新于" itemprop="dateModified" datetime="2018-06-09T10:34:16+08:00">
                2018-06-09
              </time>
            
          </span>


          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习</span>
                  </a>
                </span>

                
                
              
            </span>
          





          
            
          

        
          


          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  12,325 字  
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  46 分钟  
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <script src="\assets\js\APlayer.min.js"> </script><p><img src="http://p4rlzrioq.bkt.clouddn.com/ai%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0.jpg" alt=""></p>
<a id="more"></a>
<blockquote class="blockquote-center"><font size="5">从IT时代走向DT时代</font></blockquote>

<hr>
<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script>

<h1 id="线性代数"><a href="#线性代数" class="headerlink" title="线性代数"></a>线性代数</h1><h2 id="1-数据类型比较"><a href="#1-数据类型比较" class="headerlink" title="1.数据类型比较"></a>1.数据类型比较</h2><p>Scalar: 标量，可以看成一个数<br>Vector: 向量，可以看成一个一维数组<br>Matrix: 矩阵，可以看成二维数组<br>Tensor: 张量，三维或三维以上的数组的统称，维度不定</p>
<p>几何代数中定义的张量是基于向量和矩阵的推广，通俗一点理解的话，我们可以将标量视为零阶张量，矢量视为一阶张量，那么矩阵就是二阶张量。<br>例如，可以将任意一张彩色图片表示成一个三阶张量，三个维度分别是图片的高度、宽度和色彩数据。将这张图用张量表示出来，就是最下方的那张表格：<br><img src="http://p4rlzrioq.bkt.clouddn.com/%E4%B8%89%E9%98%B6%E5%BC%A0%E9%87%8F.jpg" alt=""></p>
<ul>
<li><p>当然我们还可以将这一定义继续扩展，即：我们可以用四阶张量表示一个包含多张图片的数据集，这四个维度分别是：图片在数据集中的编号，图片高度、宽度，以及色彩数据。</p>
</li>
<li><p>张量在深度学习中是一个很重要的概念，因为它是一个深度学习框架中的一个核心组件，后续的所有运算和优化算法几乎都是基于张量进行的。</p>
</li>
</ul>
<h2 id="2-线性代数概念"><a href="#2-线性代数概念" class="headerlink" title="2.线性代数概念"></a>2.线性代数概念</h2><p><strong>  逆矩阵</strong>：对于n阶矩阵A，如果有一个n阶矩阵B，使 AB = BA = E， 则说矩阵A是可逆的，并把矩阵B称为A的逆矩阵。当 |A| =0 时，A称为奇异矩阵。可逆矩阵一定是非奇异矩阵，因为矩阵可逆的充分必要条件是 |A|不为0。</p>
<p><strong> 矩阵的秩</strong>：矩阵A的行阶梯形中非零行的行数，就是矩阵A的秩。 对于n阶矩阵A，由于A的n阶子式只有一个|A|，故当 |A|不为0时R(A)=n，当|A|=0时R(A)&lt;n。因此，可逆矩阵的秩 = 矩阵的阶数，不可逆矩阵的秩 &lt; 矩阵的阶数。那么秩有什么实际意义吗？答案是肯定的。在做矩阵SVD分解的时候用于降噪，如果矩阵秩远小于样本维数（即矩阵列数），那么这些样本相当于只生活在外围空间中的一个低维子空间，这样就能实施降维操作。再者，如果把矩阵看成线性映射，那么秩就是象空间的的维数。</p>
<p><strong> 线性方程组的解</strong>：矩阵在数学上的基本的应用就是解线性方程组，这也是贯穿整个课本的样例。一个复杂的线性方程组可以表示为Ax=b，其中x，b是向量。通过求A的秩可以判定方程组的解：无解的充分必要条件是R(A) &lt; R(A,b)；有唯一解的充分必要条件是R(A) = R(A,b) = n；有无限多解的充分必要条件是R(A) = R(A,b) &lt; n。</p>
<p><strong>   向量空间的基</strong>：设V是一个向量空间，V上有r个向量a1,a2…ar，并且满足 a1,a2…ar线性无关，并且V中的任一向量都可以由a1,a2…ar线性表示，那么向量组a1,a2…ar就称为向量空间V的一个基，r是向量空间的维数，并称V为r维向量空间。可以这么理解，把向量空间看做是向量组，那么基就是一个极大线性无关组，可以用来表示其他向量的最小组合，维数就是向量组的秩。</p>
<p><strong>  特征值与特征向量</strong>：对于n阶矩阵A，如果数 λ 和 n 维非零列向量 x 使关系式 Ax=λ x 成立，那么 λ 称为矩阵A的特征值，向量 x 就是A的对应于λ 的特征向量。那么如何理解特征值与特征向量呢？</p>
<p> 我们知道，矩阵乘法对应了一个变换，是把任意一个向量变成另一个方向或长度都大多不同的新向量。在这个变换的过程中，原向量主要发生旋转、伸缩的变化。如果矩阵对某一个向量或某些向量只发生伸缩变换，不对这些向量产生旋转的效果，那么这些向量就称为这个矩阵的特征向量，伸缩的比例就是特征值。实际上，这段话既讲了矩阵变换特征值及特征向量的几何意义（图形变换）也讲了其物理含义。物理的含义就是运动的图景：特征向量在一个矩阵的作用下作伸缩运动，伸缩的幅度由特征值确定。特征值大于1，所有属于此特征值的特征向量身形暴长；特征值大于0小于1，特征向量身形猛缩；特征值小于0，特征向量缩过了界，反方向到0点那边去了。</p>
<p> <strong>相似矩阵</strong>：设A，B都是n阶矩阵，若有可逆矩阵P，使P-1 AP=B,则B是A的相似矩阵。</p>
<p> <strong>对角阵</strong>：是一个主对角线之外的元素皆为 0 的矩阵。对角线上的元素可以为 0 或其他值。</p>
<p> <strong>二次型</strong>：含有n个变量的二次齐次函数叫做二次型。只含平方项叫做二次型的标准型。用矩阵表示二次型就是f = xT Ax，A为对称矩阵。</p>
<h2 id="3-新视角看待矩阵运算"><a href="#3-新视角看待矩阵运算" class="headerlink" title="3.新视角看待矩阵运算"></a>3.新视角看待矩阵运算</h2><h3 id="1-矩阵"><a href="#1-矩阵" class="headerlink" title="1 矩阵"></a>1 矩阵</h3><p>矩阵<img src="http://p4rlzrioq.bkt.clouddn.com/%E6%96%B0%E8%A7%86%E8%A7%92%E7%9C%8B%E5%BE%85%E7%9F%A9%E9%98%B5%E8%BF%90%E7%AE%97.png" alt="">构成行视图的方程组为 2x-y=1;x+y=5，表示的是二维平面的两条直线，方程组的解就是两条直线的交点。</p>
<p><img src="http://p4rlzrioq.bkt.clouddn.com/%E6%96%B0%E8%A7%86%E8%A7%92%E7%9C%8B%E5%BE%85%E7%9F%A9%E9%98%B5%E8%BF%90%E7%AE%971.png" alt=""> </p>
<p>如果用列视图表达，就是<img src="http://p4rlzrioq.bkt.clouddn.com/%E6%96%B0%E8%A7%86%E8%A7%92%E7%9C%8B%E5%BE%85%E7%9F%A9%E9%98%B5%E8%BF%90%E7%AE%972.png" alt="">，表示了两个向量之间的关系，如下图，有向量a（2,1）和向量b（-1,1）,2a+3b=（1,5）。</p>
<p><img src="http://p4rlzrioq.bkt.clouddn.com/%E6%96%B0%E8%A7%86%E8%A7%92%E7%9C%8B%E5%BE%85%E7%9F%A9%E9%98%B5%E8%BF%90%E7%AE%973.png" alt=""></p>
<p>这里我们来探究一下“维度”。数学中的维度和物理研究的维度不可一概而论。数学的维度表示的是独立参数的数目，物理学的维度指的是独立的时空坐标的数目。根据爱因斯坦的理论，我们生活的空间是四维空间，包含了三维的空间+时间。</p>
<h3 id="2-线性相关和线性无关"><a href="#2-线性相关和线性无关" class="headerlink" title="2 线性相关和线性无关"></a>2 线性相关和线性无关</h3><p>我们先看线性相关和线性无关的定义。在向量空间V的一组向量A，如果存在不全为零的数 k1, k2, ···,km , 使<img src="http://p4rlzrioq.bkt.clouddn.com/%E6%96%B0%E8%A7%86%E8%A7%92%E7%9C%8B%E5%BE%85%E7%9F%A9%E9%98%B5%E8%BF%90%E7%AE%974.png" alt="">则称向量组A是线性相关的，否则数 k1, k2, ···,km全为0时，称它是线性无关。线性无关可以这么理解，如果是二维空间，这组向量的任意两个向量不共线；如果是三维空间，则任意三个向量不共面，如果共面了就可以用另外两个表示第三个向量了不是么。</p>
<h3 id="3-向量空间的基"><a href="#3-向量空间的基" class="headerlink" title="3 向量空间的基"></a>3 向量空间的基</h3><p>基：向量空间V的一组向量若满足(1)线性无关，(2)V中任一向量可由此向量线性表出，则称该组向量V中的一个基（亦称基底）。</p>
<h3 id="4-四个基本的子空间"><a href="#4-四个基本的子空间" class="headerlink" title="4 四个基本的子空间"></a>4 四个基本的子空间</h3><p>列空间：是包含所有列的线性组合。列向量是m维的，所以C(A)在Rm里。维数上，A的主列就是列空间的一组基，dim(C(A))=Rank(A)=r，维数就是秩的大小。</p>
<p>   零空间：n维向量，是Ax=0的所有解的集合，所以N(A)在Rn里。零空间有可能不存在。维数上，一组基就是一组特殊解，r是主变量的个数，n-r是自由变量的个数，零空间的维数等于n-r。</p>
<p>   行空间：是包含所有行的线性组合。A的行的所有线性组合，即A转置的列的线性组合（因为我们不习惯处理行向量），C(AT)在Rn里。维数上，有一个重要的性质：行空间和列空间维数相同，都等于秩的大小。</p>
<p>   左零空间：和列空间垂直的空间，交于一个零点，维数为m-r。</p>
<p>   可以画出四个子空间如下，行空间和零空间在Rn里，他们的维数加起来等于n，列空间和左零空间在Rm里，他们的维数加起来等于m。</p>
<p><img src="http://p4rlzrioq.bkt.clouddn.com/%E6%96%B0%E8%A7%86%E8%A7%92%E7%9C%8B%E5%BE%85%E7%9F%A9%E9%98%B5%E8%BF%90%E7%AE%975.png" alt=""></p>
<h2 id="4-矩阵导数"><a href="#4-矩阵导数" class="headerlink" title="4.矩阵导数"></a>4.矩阵导数</h2><ul>
<li>分子、分母布局：<br>分子布局：分子为列向量，或者分母为行向量；<br>分母布局：分母为列向量，或者分子为行向量；</li>
<li>运算规则：<br><img src="http://p4rlzrioq.bkt.clouddn.com/%E7%9F%A9%E9%98%B5%E5%88%86%E5%AD%90%E5%88%86%E6%AF%8D%E5%B8%83%E5%B1%80%E8%BF%90%E7%AE%97.png" alt=""></li>
<li>需要注意的规则：<br>以下公式默认在分子布局下的结果<br><img src="http://p4rlzrioq.bkt.clouddn.com/%E7%9F%A9%E9%98%B5%E6%B1%82%E5%AF%BC%E9%9C%80%E8%A6%81%E6%B3%A8%E6%84%8F%E7%9A%84%E8%A7%84%E5%88%99.png" alt="">；<img src="http://p4rlzrioq.bkt.clouddn.com/%E7%9F%A9%E9%98%B5%E6%B1%82%E5%AF%BC%E9%9C%80%E8%A6%81%E6%B3%A8%E6%84%8F%E7%9A%84%E8%A7%84%E5%88%991.png" alt="">；<img src="http://p4rlzrioq.bkt.clouddn.com/%E7%9F%A9%E9%98%B5%E6%B1%82%E5%AF%BC%E9%9C%80%E8%A6%81%E6%B3%A8%E6%84%8F%E7%9A%84%E8%A7%84%E5%88%992.png" alt=""></li>
<li>常用公式<br><img src="http://p4rlzrioq.bkt.clouddn.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%B8%B8%E8%A7%81%E6%B1%82%E5%AF%BC%E6%96%B9%E5%BC%8F.png" alt=""></li>
</ul>
<h2 id="5-特征分解"><a href="#5-特征分解" class="headerlink" title="5.特征分解"></a>5.特征分解</h2><h3 id="1-特征分解"><a href="#1-特征分解" class="headerlink" title="1 特征分解"></a>1 特征分解</h3><ul>
<li>特征分解的性质：对于Ax=λ x,如果所有的特征值都不相同，则相应的所有的特征向量线性无关，此时X可以被对角化为<img src="http://p4rlzrioq.bkt.clouddn.com/%E7%89%B9%E5%BE%81%E5%88%86%E8%A7%A3.jpg" alt="">。</li>
</ul>
<ul>
<li>对称矩阵的特征分解：如果一个对称矩阵的特征值不同，则其相应的所有的特征向量正交。</li>
<li>二次型：用于判定一个矩阵是正定矩阵、半正定矩阵、负定矩阵还是不定矩阵。如果矩阵的特征值都大于0，就是正定矩阵。下图中是两个二次型图形的例子，左边是凸函数，右边是非凸函数。之后会详细讲凸函数的优化问题。</li>
<li><img src="http://p4rlzrioq.bkt.clouddn.com/%E7%89%B9%E5%BE%81%E5%88%86%E8%A7%A31.jpg" alt=""></li>
</ul>
<h3 id="2-PCA"><a href="#2-PCA" class="headerlink" title="2 PCA"></a>2 PCA</h3><p>PCA是特征分解的一个有效应用。在进行图像的特征提取的过程中，提取的特征维数太多经常会导致特征匹配时过于复杂，消耗系统资源，不得不采用特征降维的方法。所谓特征降维，即采用一个低纬度的特征来表示高纬度。特征降维一般有两类方法：特征选择和特征抽取。特征选择即从高纬度的特征中选择其中的一个子集来作为新的特征；而特征抽取是指将高纬度的特征经过某个函数映射至低纬度作为新的特征。常用的特征抽取方法就是PCA（Principal Component Analysis）。降维过程举例：比如有矩阵X，希望把它由两行降成一行。</p>
<p>矩阵X：<img src="http://p4rlzrioq.bkt.clouddn.com/PCA.jpg" alt=""></p>
<p>1.计算协方差矩阵<img src="http://p4rlzrioq.bkt.clouddn.com/PCA1.jpg" alt=""></p>
<p>2.计算Cx的特征值为：λ1=2，λ2=2/5。特征值对应的特征向量为<img src="http://p4rlzrioq.bkt.clouddn.com/PCA2.jpg" alt=""></p>
<p>3.降维：特征向量的转置*X。<img src="http://p4rlzrioq.bkt.clouddn.com/PCA3.jpg" alt="">得到一行的矩阵。</p>
<h2 id="6-奇异值分解（Singular-Value-Decomposition，SVD）"><a href="#6-奇异值分解（Singular-Value-Decomposition，SVD）" class="headerlink" title="6.奇异值分解（Singular Value Decomposition，SVD）"></a>6.<strong>奇异值分解（Singular Value Decomposition，SVD）</strong></h2><p>  PCA的实现一般有两种方式，分别是特征值分解和SVD分解。SVD奇异值分解可以将一个复杂的矩阵用几个更小的子矩阵表示，每个子矩阵代表了原矩阵的重要特性。 SVD奇异值分解：任何秩为r的矩阵，都可以特征分解为以下公式：</p>
<p><img src="http://p4rlzrioq.bkt.clouddn.com/%E5%A5%87%E5%BC%82%E5%80%BC%E5%88%86%E8%A7%A30.jpg" alt=""> </p>
<p>其中U和V是正交矩阵。公式表示了SVD与子空间的关系。公式(13)便于分析，但并不计算有效；公式(14)计算有效，但有时候不方便分析；公式(15)方便展开，用于低秩矩阵的计算。另外SVD还提供了计算四个子空间正交基的一种快速方法。</p>
<p>SVD应用之一图像压缩：给定一幅图像，256<em>512像素，考虑用低秩矩阵近似的方式，存储奇异向量，若保留一个奇异向量k=1，压缩比大致是 (256</em>512) / (256+512) = 170。但是k太小图像的质量也损失较大，实际中k不会这么小，下面四个图分别是原图、k=1、k=10、k=80 时图片的表现。</p>
<p><img src="http://p4rlzrioq.bkt.clouddn.com/%E5%A5%87%E5%BC%82%E5%80%BC%E5%88%86%E8%A7%A3.jpg" alt=""></p>
<h2 id="7-常见距离"><a href="#7-常见距离" class="headerlink" title="7.常见距离"></a>7.常见距离</h2><p>上面大致说过， 在机器学习里，我们的运算一般都是基于向量的，一条用户具有100个特征，那么他对应的就是一个100维的向量，通过计算两个用户对应向量之间的距离值大小，有时候能反映出这两个用户的相似程度。这在后面的KNN算法和K-means算法中很明显。</p>
<p>设有两个n维变量\(A=\left[ x_{11}, x_{12},…,x_{1n} \right]\)和\(A=\left[ x_{11}, x_{12},…,x_{1n} \right]\)，则一些常用的距离公式定义如下：</p>
<h3 id="1-闵可夫斯基距离"><a href="#1-闵可夫斯基距离" class="headerlink" title="1.闵可夫斯基距离"></a>1.<strong>闵可夫斯基距离</strong></h3><ul>
<li>从严格意义上讲，闵可夫斯基距离不是一种距离，而是一组距离的定义：</li>
</ul>
<p>$$d_{12} =\sqrt[p]{\sum_{k=1}^{n}{\left( x_{1k} -x_{2k} \right) ^{p} } } $$</p>
<ul>
<li>实际上，当p=1时，就是<strong>曼哈顿距离</strong>；当p=2时，就是<strong>欧式距离</strong>。当p=无穷时，就是<strong>切比雪夫距离</strong></li>
</ul>
<p><img src="http://p4rlzrioq.bkt.clouddn.com/%E6%98%8E%E5%BC%8F%E8%B7%9D%E7%A6%BB.png" alt=""></p>
<ul>
<li>切比雪夫距离Python实现如下：</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> *</span><br><span class="line">vector1 = mat([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>])</span><br><span class="line">vector2 = mat([<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>])</span><br><span class="line"><span class="keyword">print</span> sqrt(abs(vector1-vector2).max)</span><br></pre></td></tr></table></figure>
<h3 id="2-向量内积"><a href="#2-向量内积" class="headerlink" title="2. 向量内积"></a>2. 向量内积</h3><p>向量内积的结果是没有界限的，一种解决办法是除以长度之后再求内积，这就是应用十分广泛的<strong>余弦相似度</strong>（Cosine similarity）：</p>
<p><img src="http://p4rlzrioq.bkt.clouddn.com/%E4%BD%99%E5%BC%A6%E7%9B%B8%E4%BC%BC%E5%BA%A6.png" alt=""></p>
<p>余弦相似度与向量的幅值无关，只与向量的方向相关，在文档相似度（<a href="http://www.ruanyifeng.com/blog/2013/03/cosine_similarity.html" target="_blank" rel="noopener">TF-IDF</a>）和图片相似性（<a href="http://www.ruanyifeng.com/blog/2013/03/similar_image_search_part_ii.html" target="_blank" rel="noopener">histogram</a>）计算上都有它的身影。需要注意一点的是，余弦相似度受到向量的平移影响，上式如果将 x 平移到 x+1, 余弦值就会改变。怎样才能实现平移不变性？这就是下面要说的<strong>皮尔逊相关系数</strong>（Pearson correlation），有时候也直接叫<strong>相关系数</strong>:</p>
<p><img src="http://p4rlzrioq.bkt.clouddn.com/%E7%9A%AE%E5%B0%94%E9%80%8A%E7%9B%B8%E5%85%B3%E7%B3%BB%E6%95%B0.png" alt=""></p>
<p>皮尔逊相关系数具有平移不变性和尺度不变性，计算出了两个向量（维度）的相关性。不过，一般我们在谈论相关系数的时候，将 x 与 y 对应位置的两个数值看作一个样本点，皮尔逊系数用来表示这些样本点分布的相关性。</p>
<p><img src="http://p4rlzrioq.bkt.clouddn.com/%E7%9A%AE%E5%B0%94%E9%80%8A%E7%B3%BB%E6%95%B0.png" alt=""></p>
<p>由于皮尔逊系数具有的良好性质，在各个领域都应用广泛，例如，在推荐系统根据为某一用户查找喜好相似的用户,进而提供推荐，优点是可以不受每个用户评分标准不同和观看影片数量不一样的影响。</p>
<h3 id="3-分类数据点间的距离"><a href="#3-分类数据点间的距离" class="headerlink" title="3. 分类数据点间的距离"></a>3. 分类数据点间的距离</h3><p><strong>汉明距离</strong>（Hamming distance）是指，两个等长字符串s1与s2之间的汉明距离定义为将其中一个变为另外一个所需要作的最小替换次数。举个维基百科上的例子：</p>
<p><img src="http://p4rlzrioq.bkt.clouddn.com/%E6%B1%89%E6%98%8E%E8%B7%9D%E7%A6%BB.png" alt=""></p>
<p>还可以用简单的<strong><em>匹配系数</em></strong>来表示两点之间的相似度——匹配字符数/总字符数。</p>
<p>在一些情况下，某些特定的值相等并不能代表什么。举个例子，用 1 表示用户看过该电影，用 0 表示用户没有看过，那么用户看电影的的信息就可用 0,1 表示成一个序列。考虑到电影基数非常庞大，用户看过的电影只占其中非常小的一部分，如果两个用户都没有看过某一部电影（两个都是 0），并不能说明两者相似。反而言之，如果两个用户都看过某一部电影（序列中都是 1），则说明用户有很大的相似度。在这个例子中，序列中等于 1 所占的权重应该远远大于 0 的权重，这就引出下面要说的<strong>杰卡德相似系数</strong>（Jaccard similarity）。</p>
<p>在上面的例子中，用 M11 表示两个用户都看过的电影数目，M10 表示用户 A 看过，用户 B 没看过的电影数目，M01 表示用户 A 没看过，用户 B 看过的电影数目，M00 表示两个用户都没有看过的电影数目。Jaccard 相似性系数可以表示为：</p>
<p><img src="http://p4rlzrioq.bkt.clouddn.com/Jaccard%20%E7%9B%B8%E4%BC%BC%E6%80%A7%E7%B3%BB%E6%95%B0.png" alt=""></p>
<hr>
<h1 id="概率论和统计"><a href="#概率论和统计" class="headerlink" title="概率论和统计"></a>概率论和统计</h1><h2 id="1-统计量"><a href="#1-统计量" class="headerlink" title="1.统计量"></a>1.统计量</h2><h3 id="协方差"><a href="#协方差" class="headerlink" title="协方差"></a>协方差</h3><p><img src="http://p4rlzrioq.bkt.clouddn.com/%E5%8D%8F%E6%96%B9%E5%B7%AE.png" alt=""><br><img src="http://p4rlzrioq.bkt.clouddn.com/%E5%8D%8F%E6%96%B9%E5%B7%AE1.png" alt=""><br><img src="http://p4rlzrioq.bkt.clouddn.com/%E5%8D%8F%E6%96%B9%E5%B7%AE2.png" alt=""></p>
<h3 id="Pearson相关系数"><a href="#Pearson相关系数" class="headerlink" title="Pearson相关系数"></a><strong>Pearson相关系数</strong></h3><p><img src="http://p4rlzrioq.bkt.clouddn.com/Pearson%E7%9B%B8%E5%85%B3%E7%B3%BB%E6%95%B0.png" alt=""></p>
<h3 id="协方差矩阵"><a href="#协方差矩阵" class="headerlink" title="协方差矩阵"></a><strong>协方差矩阵</strong></h3><p><img src="http://p4rlzrioq.bkt.clouddn.com/%E5%8D%8F%E6%96%B9%E5%B7%AE%E7%9F%A9%E9%98%B5.png" alt=""></p>
<h2 id="2-独立与不相关"><a href="#2-独立与不相关" class="headerlink" title="2.独立与不相关"></a>2.<strong>独立与不相关</strong></h2><p><img src="http://p4rlzrioq.bkt.clouddn.com/%E7%8B%AC%E7%AB%8B%E4%B8%8E%E4%B8%8D%E7%9B%B8%E5%85%B3.png" alt=""> </p>
<h2 id="3-贝叶斯公式"><a href="#3-贝叶斯公式" class="headerlink" title="3.贝叶斯公式"></a>3.<strong>贝叶斯公式</strong></h2><p>先看看什么是“先验概率”和“后验概率”，以一个例子来说明：</p>
<p>假设某种病在人群中的发病率是0.001，即1000人中大概会有1个人得病，则有： <strong>P(患病) = 0.1%</strong>；即：在没有做检验之前，我们预计的患病率为<strong>P(患病)=0.1%</strong>，这个就叫作<strong>“先验概率”</strong>。</p>
<p>再假设现在有一种该病的检测方法，其检测的准确率为<strong>95%</strong>；即：如果真的得了这种病，该检测法有<strong>95%</strong>的概率会检测出阳性，但也有<strong>5%</strong>的概率检测出阴性；或者反过来说，但如果没有得病，采用该方法有<strong>95%</strong>的概率检测出阴性，但也有<strong>5%</strong>的概率检测为阳性。用概率条件概率表示即为：<strong>P(显示阳性|患病)=95%</strong></p>
<p>现在我们想知道的是：在做完检测显示为阳性后，某人的患病率<strong>P(患病|显示阳性)</strong>，这个其实就称为<strong>“后验概率”。</strong></p>
<p>而这个叫贝叶斯的人其实就是为我们提供了一种可以<strong>利用先验概率计算后验概率</strong>的方法，我们将其称为<strong>“贝叶斯公式”。</strong></p>
<p>这里先了解<strong>条件概率公式</strong>：</p>
<p>$$P\left( B|A \right)=\frac{P\left( AB \right)}{P\left( A \right)} , P\left( A|B \right)=\frac{P\left( AB \right)}{P\left( B \right)}$$</p>
<p>由条件概率可以得到<strong>乘法公式</strong>：</p>
<p>$$P\left( AB \right)=P\left( B|A \right)P\left( A \right)=P\left( A|B \right)P\left( B \right)$$<br>将条件概率公式和乘法公式结合可以得到：</p>
<p>$$P\left( B|A \right)=\frac{P\left( A|B \right)\cdot P\left( B \right)}{P\left( A \right)}$$</p>
<p>再由<strong>全概率公式</strong>：</p>
<p>$$P\left( A \right)=\sum_{i=1}^{N}{P\left( A|B_{i} \right) \cdot P\left( B_{i}\right)} $$</p>
<p>代入可以得到<strong>贝叶斯公式</strong>：</p>
<p>$$P\left( B_{i}|A \right)=\frac{P\left( A|B_{i} \right)\cdot P\left( B_{i} \right)}{\sum_{i=1}^{N}{P\left( A|B_{i} \right) \cdot P\left( B_{i}\right)} }$$</p>
<h2 id="4-常见分布函数"><a href="#4-常见分布函数" class="headerlink" title="4.常见分布函数"></a>4.<strong>常见分布函数</strong></h2><h3 id="0-1分布"><a href="#0-1分布" class="headerlink" title="0-1分布"></a><strong>0-1分布</strong></h3><p>0-1分布是单个二值型离散随机变量的分布，其概率分布函数为：</p>
<p>$$P\left( X=1 \right) =p$$<br>$$P\left( X=0 \right) =1-p$$</p>
<h3 id="几何分布"><a href="#几何分布" class="headerlink" title="几何分布"></a><strong>几何分布</strong></h3><p>几何分布是离散型概率分布，其定义为：在n次伯努利试验中，试验k次才得到第一次成功的机率。即：前k-1次皆失败，第k次成功的概率。其概率分布函数为：</p>
<p>$$P\left( X=k \right) =\left( 1-p \right) ^{k-1} p$$</p>
<p>性质：<br>\(E\left( X \right) =\frac{1}{p}\)<br>\(Var\left( X \right) =\frac{1-p}{p^{2} }\)</p>
<h3 id="二项分布"><a href="#二项分布" class="headerlink" title="二项分布"></a><strong>二项分布</strong></h3><p>二项分布即重复n次伯努利试验，各次试验之间都相互独立，并且每次试验中只有两种可能的结果，而且这两种结果发生与否相互对立。如果每次试验时，事件发生的概率为p，不发生的概率为1-p，则n次重复独立试验中发生k次的概率为：</p>
<p>$$P\left( X=k \right) =C_{n}^{k} p^{k} \left( 1-p \right) ^{n-k}$$</p>
<p>性质：<br>\(E\left( X \right) =np\)<br>\(Var\left( X \right) =np\left( 1-p \right)\)</p>
<h3 id="高斯分布"><a href="#高斯分布" class="headerlink" title="高斯分布"></a><strong>高斯分布</strong></h3><p>高斯分布又叫正态分布，其曲线呈钟型，两头低，中间高，左右对称因其曲线呈钟形，如下图所示：<br><img src="http://p4rlzrioq.bkt.clouddn.com/488px-Normal_Distribution_PDF.svg.png" alt=""></p>
<p><img src="http://p4rlzrioq.bkt.clouddn.com/%E6%AD%A3%E6%80%81%E5%88%86%E5%B8%83.png" alt=""></p>
<p>若随机变量X服从一个数学期望为\(\mu\)，方差为\(\sigma ^{2}\)的正态分布，则我们将其记为：\(N\left( \mu ,\sigma^{2} \right)\)决定了正态分布的位置，其标准差\(\sigma\)（方差的开方）决定了正态分布的幅度。</p>
<h3 id="指数分布"><a href="#指数分布" class="headerlink" title="指数分布"></a><strong>指数分布</strong></h3><p>指数分布是事件的时间间隔的概率，它的一个重要特征是无记忆性。例如：如果某一元件的寿命的寿命为T，已知元件使用了t小时，它总共使用至少t+s小时的条件概率，与从开始使用时算起它使用至少s小时的概率相等。下面这些都属于指数分布：</p>
<ul>
<li>婴儿出生的时间间隔</li>
<li>网站访问的时间间隔</li>
<li>奶粉销售的时间间隔</li>
</ul>
<p>指数分布的公式可以从泊松分布推断出来。如果下一个婴儿要间隔时间t，就等同于t之内没有任何婴儿出生，即：</p>
<p>$$P\left( X\geq t \right) =P\left( N\left( t \right) =0 \right) =\frac{\left( \lambda t \right) ^{0}\cdot e^{-\lambda t} }{0!}=e^{-\lambda t} $$<br>则：</p>
<p>$$P\left( X\leq t \right) =1-P\left( X\geq t \right) =1-e^{-\lambda t}$$<br>如：接下来15分钟，会有婴儿出生的概率为：</p>
<p>$$P\left( X\leq \frac{1}{4} \right) =1-e^{-3\cdot \frac{1}{4} } \approx 0.53$$</p>
<p><img src="http://p4rlzrioq.bkt.clouddn.com/%E6%8C%87%E6%95%B0%E5%88%86%E5%B8%83.jpg" alt=""></p>
<h3 id="泊松分布"><a href="#泊松分布" class="headerlink" title="泊松分布"></a><strong>泊松分布</strong></h3><p>日常生活中，大量事件是有固定频率的，比如：</p>
<ul>
<li>某医院平均每小时出生3个婴儿</li>
<li>某网站平均每分钟有2次访问</li>
<li>某超市平均每小时销售4包奶粉</li>
</ul>
<p>它们的特点就是，我们可以预估这些事件的总数，但是没法知道具体的发生时间。已知平均每小时出生3个婴儿，请问下一个小时，会出生几个？有可能一下子出生6个，也有可能一个都不出生，这是我们没法知道的。</p>
<p><strong>泊松分布就是描述某段时间内，事件具体的发生概率。</strong>其概率函数为：</p>
<p>$$P\left( N\left( t \right) =n \right) =\frac{\left( \lambda t \right) ^{n}e^{-\lambda t} }{n!} $$<br>其中：</p>
<p>P表示概率，N表示某种函数关系，t表示时间，n表示数量，1小时内出生3个婴儿的概率，就表示为 P(N(1) = 3) ；λ 表示事件的频率。</p>
<p>还是以上面医院平均每小时出生3个婴儿为例，则\(\lambda =3\)；</p>
<p>那么，接下来两个小时，一个婴儿都不出生的概率可以求得为：</p>
<p>$$P\left( N\left(2 \right) =0 \right) =\frac{\left( 3\cdot 2 \right) ^{o} \cdot e^{-3\cdot 2} }{0!} \approx 0.0025$$<br>同理，我们可以求接下来一个小时，至少出生两个婴儿的概率：</p>
<p>$$P\left( N\left( 1 \right) \geq 2 \right) =1-P\left( N\left( 1 \right)=0 \right) - P\left( N\left( 1 \right)=1 \right)\approx 0.8$$</p>
<h2 id="5-常见的分布总结"><a href="#5-常见的分布总结" class="headerlink" title="5.常见的分布总结"></a>5.常见的分布总结</h2><p><img src="http://p4rlzrioq.bkt.clouddn.com/%E5%B8%B8%E8%A7%81%E5%88%86%E5%B8%83.jpg" alt="常见分布"></p>
<h2 id="6-极大似然估计（MLE）"><a href="#6-极大似然估计（MLE）" class="headerlink" title="6.极大似然估计（MLE）"></a>6.极大似然估计（MLE）</h2><p>极大似然估计是建立在这样的思想上：已知某个参数能使这个样本出现的概率最大，我们当然不会再去选择其他小概率的样本，所以干脆就把这个参数作为估计的真实值。</p>
<p>求极大似然函数估计值的一般步骤：</p>
<p>（1） 写出似然函数，即每个随机实验出现概率相乘，为这个抽样出现的概率。<br>（2） 对似然函数取对数，为了方便求导；<br>（3） 对参数求导数。<br>（4） 令导数=0，即求解极值，由实际情况知，该极值为极大值。解似然方程。</p>
<hr>
<h1 id="微积分"><a href="#微积分" class="headerlink" title="微积分"></a>微积分</h1><h2 id="1-导数与梯度"><a href="#1-导数与梯度" class="headerlink" title="1.导数与梯度"></a>1.导数与梯度</h2><ul>
<li><strong>导数</strong>：一个一元函数函数在某一点的导数描述了这个函数在这一点附近的变化率。</li>
<li><strong>梯度</strong>:多元函数的导数就是梯度。<ul>
<li>一阶导数，即梯度（gradient）</li>
<li>二阶导数，Hessian矩阵</li>
</ul>
</li>
</ul>
<h2 id="2-泰勒展开"><a href="#2-泰勒展开" class="headerlink" title="2.泰勒展开"></a>2.<strong>泰勒展开</strong></h2><ul>
<li>一元函数的泰勒展开：<br><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/d0070da6cb78cda75d9ff9521f85702c97862673" alt="link"></li>
<li>基尼指数的图像、熵、分类误差率三者之间的关系。<br><img src="http://p4rlzrioq.bkt.clouddn.com/%E6%B3%B0%E5%8B%92%E5%B1%95%E5%BC%80.jpg" alt="link"></li>
</ul>
<h2 id="3-Lagrange乘子法"><a href="#3-Lagrange乘子法" class="headerlink" title="3.Lagrange乘子法"></a>3.<strong>Lagrange乘子法</strong></h2><p>对于一般的求极值问题我们都知道，求导等于0就可以了。但是如果我们不但要求极值，还要求一个满足一定约束条件的极值，那么此时就可以构造Lagrange函数，其实就是<strong>把约束项添加到原函数上，然后对构造的新函数求导</strong>。</p>
<p>对于一个要求极值的函数\(f\left( x,y \right)\)，图上的蓝圈就是这个函数的等高图，就是说 \(f\left( x,y \right) =c_{1} ,c_{2} ,…,c_{n}\)分别代表不同的数值(每个值代表一圈，等高图)，我要找到一组\(\left( x,y \right)\)，使它的\(c_{i}\)值越大越好，但是这点必须满足约束条件\(g\left( x,y \right)\)（在黄线上）。</p>
<p><img src="http://p4rlzrioq.bkt.clouddn.com/%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E6%95%B0.jpg" alt=""></p>
<p>也就是说\(f(x,y)\)相切，或者说它们的梯度▽ \({f}\)和▽\({g}\)平行，因此它们的梯度（偏导）成倍数关系；那我么就假设为\(\lambda\)倍，然后把约束条件加到原函数后再对它求导，其实就等于满足了下图上的式子。</p>
<p>在<strong>支持向量机模型（SVM）</strong>的推导中一步很关键的就是利用拉格朗日对偶性将原问题转化为对偶问题。</p>
<hr>
<h1 id="信息论"><a href="#信息论" class="headerlink" title="信息论"></a>信息论</h1><h2 id="1-信息熵"><a href="#1-信息熵" class="headerlink" title="1.信息熵"></a>1.<strong>信息熵</strong></h2><p>熵的概念最早由统计热力学引入。</p>
<p>信息熵是由信息论之父香农提出来的，它用于随机变量的不确定性度量，先上信息熵的公式。</p>
<p><img src="http://p4rlzrioq.bkt.clouddn.com/%E4%BF%A1%E6%81%AF%E7%86%B5.png" alt="link"><br>信息是用来减少随机不确定性的东西（即不确定性的减少）。</p>
<p>我们可以用log ( 1/P )来衡量不确定性。P是一件事情发生的概率，概率越大，不确定性越小。</p>
<p>可以看到信息熵的公式，其实就是log ( 1/P )的期望，就是不确定性的期望，它代表了一个系统的不确定性，信息熵越大，不确定性越大。</p>
<p>注意这个公式有个默认前提，就是X分布下的随机变量x彼此之间相互独立。还有log的底默认为2，实际上底是多少都可以，但是在信息论中我们经常讨论的是二进制和比特，所以用2。</p>
<p>信息熵在联合概率分布的自然推广，就得到了联合熵</p>
<p><img src="http://p4rlzrioq.bkt.clouddn.com/%E4%BF%A1%E6%81%AF%E7%86%B51.png" alt=""></p>
<p>当X, Y相互独立时，H(X, Y) = H(X) + H(Y)</p>
<h3 id="信息熵的实例解释"><a href="#信息熵的实例解释" class="headerlink" title="信息熵的实例解释"></a><strong>信息熵的实例解释</strong></h3><p>举个例子说明信息熵的作用。</p>
<p>例子是知乎上看来的，我觉得讲的挺好的。</p>
<blockquote>
<p>比如赌马比赛，有4匹马{ A, B, C, D}，获胜概率分别为{ 1/2, 1/4, 1/8, 1/8 }，将哪一匹马获胜视为随机变量X属于 { A, B, C, D } 。</p>
<p>假定我们需要用尽可能少的二元问题来确定随机变量 X 的取值。</p>
<p>例如，问题1：A获胜了吗？　问题2：B获胜了吗？　问题3：C获胜了吗？</p>
<p>最后我们可以通过最多3个二元问题，来确定取值。</p>
<p>如果X = A，那么需要问1次（问题1：是不是A？），概率为1/2 </p>
<p>如果X = B，那么需要问2次（问题1：是不是A？问题2：是不是B？），概率为1/4 </p>
<p>如果X = C，那么需要问3次（问题1，问题2，问题3），概率为1/8 </p>
<p>如果X = D，那么需要问3次（问题1，问题2，问题3），概率为1/8 </p>
<p>那么为确定X取值的二元问题的数量为</p>
<p><img src="http://p4rlzrioq.bkt.clouddn.com/%E4%BF%A1%E6%81%AF%E7%86%B52.png" alt=""></p>
<p>回到信息熵的定义，会发现通过之前的信息熵公式，神奇地得到了：</p>
<p><img src="http://p4rlzrioq.bkt.clouddn.com/%E4%BF%A1%E6%81%AF%E7%86%B52.png" alt=""> </p>
<p>在二进制计算机中，一个比特为0或1，其实就代表了一个二元问题的回答。也就是说，在计算机中，我们给哪一匹马夺冠这个事件进行编码，所需要的平均码长为1.75个比特。</p>
<p>很显然，为了尽可能减少码长，我们要给发生概率 p(x)较大的事件，分配较短的码长 l(x)。这个问题深入讨论，可以得出霍夫曼编码的概念。</p>
<p>霍夫曼编码就是利用了这种大概率事件分配短码的思想，而且可以证明这种编码方式是最优的。我们可以证明上述现象：</p>
<ul>
<li>为了获得信息熵为 H(X) 的随机变量 X 的一个样本，平均需要抛掷均匀硬币（或二元问题） H(X)次（参考猜赛马问题的案例）</li>
<li>信息熵是数据压缩的一个临界值（参考码长部分的案例）</li>
</ul>
</blockquote>
<p>所以，信息熵H(X)可以看做，对X中的样本进行编码所需要的编码长度的期望值。</p>
<h2 id="2-相对熵-交叉熵-K-L散度"><a href="#2-相对熵-交叉熵-K-L散度" class="headerlink" title="2.相对熵/交叉熵/K-L散度"></a>2.<strong>相对熵/交叉熵/K-L散度</strong></h2><p>这里可以引申出交叉熵的理解，现在有两个分布，真实分布p和非真实分布q，我们的样本来自真实分布p。</p>
<p>按照真实分布p来编码样本所需的编码长度的期望为<img src="http://p4rlzrioq.bkt.clouddn.com/%E7%9B%B8%E5%AF%B9%E7%86%B51.png" alt="">，这就是上面说的<strong>信息熵H( p )</strong></p>
<p>按照不真实分布q来编码样本所需的编码长度的期望为<img src="http://p4rlzrioq.bkt.clouddn.com/%E7%9B%B8%E5%AF%B9%E7%86%B52.png" alt="">，这就是所谓的<strong>交叉熵H( p,q )</strong><br>交叉熵和熵，相当于，协方差和方差</p>
<p>这里引申出<strong>KL散度D(p||q)</strong> = H(p,q) - H(p) = <img src="http://p4rlzrioq.bkt.clouddn.com/%E7%9B%B8%E5%AF%B9%E7%86%B53.png" alt="">，也叫做<strong>相对熵</strong>，它表示两个分布的差异，差异越大，相对熵越大。</p>
<p>机器学习中，我们用非真实分布q去预测真实分布p，因为真实分布p是固定的，D(p||q) = H(p,q) - H(p) 中 H(p) 固定，也就是说交叉熵H(p,q)越大，相对熵D(p||q)越大，两个分布的差异越大。</p>
<p>所以交叉熵用来做损失函数就是这个道理，它衡量了真实分布和预测分布的差异性。</p>
<p>用图像形象化的表示二者之间的关系可以如下图：<br><img src="http://p4rlzrioq.bkt.clouddn.com/%E7%9B%B8%E5%AF%B9%E7%86%B54.png" alt="这里写图片描述"><br>上面是q所含的信息量/平均编码长度H(p)<br>第二行是cross-entropy，即用q来编码p所含的信息量/平均编码长度|或者称之为q对p的cross-entropy<br>第三行是上面两者之间的差值即为q对p的KL距离</p>
<p>从编码的角度，可以这样简单总结，信息熵是最优编码（最短的平均码长），交叉熵是非最优编码（大于最短的平均码长），KL散度是两者的差异（距离最优编码的差距）。</p>
<h2 id="3-互信息（信息增益）"><a href="#3-互信息（信息增益）" class="headerlink" title="3.互信息（信息增益）"></a>3.<strong>互信息（信息增益）</strong></h2><p>互信息就是一个联合分布中的两个信息的纠缠程度/或者叫相互影响那部分的信息量。<br><strong>决策树中的信息增益就是互信息</strong>，决策树是采用的上面第二种计算方法，即把分类的不同结果看成不同随机事件Y，然后把当前选择的特征看成X，则信息增益就是当前Y的信息熵减去已知X情况下的信息熵。</p>
<p><img src="http://p4rlzrioq.bkt.clouddn.com/%E4%BA%92%E4%BF%A1%E6%81%AF.png" alt=""></p>
<p>可以通过简单的计算得到：</p>
<p>H(X|Y) = H(X) - I(X, Y), </p>
<p>互信息为0，则随机变量X和Y是互相独立的。</p>
<p><img src="http://p4rlzrioq.bkt.clouddn.com/%E4%BA%92%E4%BF%A1%E6%81%AF1.png" alt=""></p>
<h2 id="信息论与机器学习的关系"><a href="#信息论与机器学习的关系" class="headerlink" title="信息论与机器学习的关系"></a>信息论与机器学习的关系</h2><table>
<thead>
<tr>
<th>信息论视角</th>
<th>机器学习视角</th>
</tr>
</thead>
<tbody>
<tr>
<td>接受信号</td>
<td>特征</td>
</tr>
<tr>
<td>信源</td>
<td>标签</td>
</tr>
<tr>
<td>平均互信息</td>
<td>特征有效性分析</td>
</tr>
<tr>
<td>最大熵模型</td>
<td>极大似然法</td>
</tr>
<tr>
<td>交叉熵</td>
<td>逻辑回归损失函数</td>
</tr>
</tbody>
</table>
<h2 id="最大熵模型"><a href="#最大熵模型" class="headerlink" title="最大熵模型"></a><strong>最大熵模型</strong></h2><p>最大熵模型的原则：</p>
<ul>
<li>承认已知事物（知识）；</li>
<li>对未知事物不做任何假设，没有任何偏见。</li>
</ul>
<p>对一个随机事件的概率分布进行预测时，我们的预测应当满足全部已知条件，而对未知的情况不要做任何主观假设。在这种情况下，概率分布最均匀，预测的风险最小。</p>
<p>因为这时概率分布的信息熵最大，所以人们把这种模型叫做“最大熵模型”（Maximum Entropy）。</p>
<p>Logistic回归是统计学习中的经典分类方法，可以用于二类分类也可以用于多类分类。</p>
<p>最大熵模型由最大熵原理推导出来，最大熵原理是概率模型学习或估计的一个准则，最大熵原理认为在所有可能的概率模型的集合中，熵最大的模型是最好的模型，最大熵模型也可以用于二类分类和多类分类。</p>
<p>Logistic回归模型与最大熵模型都属于对数线性模型。</p>
<p>逻辑回归跟最大熵模型<strong>没有本质区别</strong>。逻辑回归是最大熵对应类别为<strong>二类</strong>时的特殊情况</p>
<p><strong>指数簇分布的最大熵</strong>等价于其<strong>指数形式的最大似然</strong>。</p>
<p><strong>二项式</strong>分布的最大熵解等价于二项式指数形式(<strong>sigmoid</strong>)的最大似然；<br><strong>多项式</strong>分布的最大熵等价于多项式分布指数形式(<strong>softmax</strong>)的最大似然。</p>
<h2 id="熵总结"><a href="#熵总结" class="headerlink" title="熵总结"></a>熵总结</h2><ul>
<li><strong>熵：不确定性的度量；</strong></li>
<li><strong>似然：与知识的吻合程度；</strong></li>
<li><strong>最大熵模型：对不确定度的无偏分配；</strong></li>
<li><strong>最大似然估计：对知识的无偏理解。</strong></li>
</ul>
<h2 id="2-上溢和下溢"><a href="#2-上溢和下溢" class="headerlink" title="2.上溢和下溢"></a>2.<strong>上溢和下溢</strong></h2><p>在数字计算机上实现连续数学的基本困难是：我们需要通过有限数量的位模式来表示无限多的实数，这意味着我们在计算机中表示实数时几乎都会引入一些近似误差。在许多情况下，这仅仅是舍入误差。如果在理论上可行的算法没有被设计为最小化舍入误差的累积，可能会在实践中失效，因此舍入误差是有问题的，特别是在某些操作复合时。</p>
<p>一种特别毁灭性的舍入误差是<strong>下溢</strong>。当接近零的数被四舍五入为零时发生下溢。许多函数会在其参数为零而不是一个很小的正数时才会表现出质的不同。例如，我们通常要避免被零除<strong>。</strong></p>
<p>另一个极具破坏力的数值错误形式是<strong>上溢(overflow)</strong>。当大量级的数被近似为\(\varpi\)时发生上溢。进一步的运算通常将这些无限值变为非数字。</p>
<p>必须对上溢和下溢进行数值稳定的一个例子是<strong>softmax 函数</strong>。softmax 函数经常用于预测与multinoulli分布相关联的概率，定义为：</p>
<p><img src="http://p4rlzrioq.bkt.clouddn.com/%E4%B8%8A%E6%BA%A2%E5%92%8C%E4%B8%8B%E6%BA%A2.jpg" alt=""></p>
<p>softmax 函数在多分类问题中非常常见。这个函数的作用就是使得在负无穷到0的区间趋向于0，在0到正无穷的区间趋向于1。上面表达式其实是多分类问题中计算某个样本 \(x_{i}\) 的类别标签 \(y_{i}\)属于K个类别的概率，最后判别 \(y_{i}\)所属类别时就是将其归为对应概率最大的那一个。</p>
<p>当式中的\(w_{k} x_{i} +b\)都是很小的负数时，\(e^{w_{k} x_{i} +b }\)就会发生下溢，这意味着上面函数的分母会变成0，导致结果是未定的；同理，当式中的\(x_{w_{k} x_{i} +b}\)是很大的正数时，\(e^{w_{k} x_{i} +b }\)就会发生上溢导致结果是未定的。</p>
<hr>
<h1 id="凸优化"><a href="#凸优化" class="headerlink" title="凸优化"></a><strong>凸优化</strong></h1><h2 id="1-凸集-Convex-Sets"><a href="#1-凸集-Convex-Sets" class="headerlink" title="1.凸集(Convex Sets)"></a>1.凸集(Convex Sets)</h2><p>集合C是凸的，如果对于所有的\(x,y\in C\)和\(\theta\in\mathbb{R},0\leq\theta\leq 1\)有：<br>$$\theta x+(1-\theta)y\in C$$<br>可以这样理解：在集合C中任选两点，在这两点的连线上的所有点都属于集合C。<br><img src="http://p4rlzrioq.bkt.clouddn.com/%E5%87%B8%E9%9B%86.jpg" alt=""></p>
<h2 id="2-凸函数-Convex-Fuctions"><a href="#2-凸函数-Convex-Fuctions" class="headerlink" title="2.凸函数(Convex Fuctions)"></a>2.凸函数(Convex Fuctions)</h2><p>如果函数的定义域\({\cal D}(f)\)是一个凸集，并且对于所有的\(x,y\in {\cal D}(f)\)和\(\theta\in\mathbb{R},0\leq\theta\leq1\)，都有：<br>\(f(\theta x+(1-\theta)y)\leq\theta f(x)+(1-\theta)f(y)\)<br><img src="http://oddpnmpll.bkt.clouddn.com/2016-10-05-01%3A23%3A27.jpg" alt=""></p>
<h3 id="凸函数的一阶条件"><a href="#凸函数的一阶条件" class="headerlink" title="凸函数的一阶条件"></a>凸函数的一阶条件</h3><p><img src="http://p4rlzrioq.bkt.clouddn.com/%E5%87%B8%E5%87%BD%E6%95%B0%E7%9A%84%E4%B8%80%E9%98%B6%E6%9D%A1%E4%BB%B6.png" alt=""><br>直观上可以这样理解，在函数上随便挑一个点，该点的切线必然在函数的下方<br><img src="http://oddpnmpll.bkt.clouddn.com/2016-10-05-01%3A27%3A53.jpg" alt=""></p>
<h3 id="凸性质的二阶条件"><a href="#凸性质的二阶条件" class="headerlink" title="凸性质的二阶条件"></a>凸性质的二阶条件</h3><p><img src="http://p4rlzrioq.bkt.clouddn.com/%E5%87%B8%E5%87%BD%E6%95%B0%E7%9A%84%E4%BA%8C%E9%98%B6%E6%9D%A1%E4%BB%B6.png" alt=""></p>
<h3 id="琴生不等式-Jensen’s-Inequality"><a href="#琴生不等式-Jensen’s-Inequality" class="headerlink" title="琴生不等式(Jensen’s Inequality)"></a>琴生不等式(Jensen’s Inequality)</h3><p>假设凸函数的基本定义为:<br>\(f(\theta x+(1-\theta)y)\leq\theta f(x)+(1-\theta)f(y)\ \ \ \text{for} \ \ \ 0\leq\theta\leq1\)<br>上述等式可以扩展到多个点:<br>\(f\left(\sum_{i=1}^k\theta_ix_i\right)\leq\sum_{i=1}^k\theta_if(x_i)\ \ \ \text{for}\ \ \ \sum_{i=1}^k\theta_i=1,\theta_i\geq0 \ \ \forall i\)<br>再将上述等式扩展到积分形式:<br>\(f\left(\int p(x)xdx\right)\leq\int p(x)f(x)dx\ \ \ \text{for}\ \ \ \int p(x)dx=1,p(x)\leq0\ \ \forall x\)<br>由于\(p(x)\)积分为1，我们可以把\(p(x)\)看作是一个概率密度函数，所以尚属等式可以用以下形式表达：<br>\(f(\mathbb{E}[x])\leq\mathbb{E}[f(x)]\)<br>最后一条等式就是著名的<strong>琴生不等式</strong>。</p>
<h2 id="3-凸优化问题-Convex-Optimization-Problems"><a href="#3-凸优化问题-Convex-Optimization-Problems" class="headerlink" title="3.凸优化问题(Convex Optimization Problems)"></a>3.凸优化问题(Convex Optimization Problems)</h2><p>在凸优化问题中，一个最关键的点就是<strong>对于一个凸优化问题，所有的局部最优解(locally optimal)都是全局最优解(globally optimal)</strong>。<br>最优化的基本数学模型如下：</p>
<p><img src="http://p4rlzrioq.bkt.clouddn.com/%E5%87%B8%E4%BC%98%E5%8C%96%E9%97%AE%E9%A2%98.jpg" alt=""><br>它有三个基本要素，即：</p>
<ul>
<li>设计变量：x是一个实数域范围内的n维向量，被称为决策变量或问题的解；</li>
<li>目标函数：f(x)为目标函数；</li>
<li>约束条件：\(h_{i} \left( x \right) =0\)称为等式约束，\(g_{i} \left( x \right) \leq 0\)为不等式约束，\(i=0,1,2,……\)</li>
</ul>
<h2 id="4-牛顿法"><a href="#4-牛顿法" class="headerlink" title="4.牛顿法"></a>4.牛顿法</h2><h3 id="牛顿法介绍"><a href="#牛顿法介绍" class="headerlink" title="牛顿法介绍"></a><strong>牛顿法介绍</strong></h3><p><strong>牛顿法</strong>也是求解<strong>无约束最优化</strong>问题常用的方法，<strong>最大的优点是收敛速度快</strong>。</p>
<p>从本质上去看，<strong>牛顿法是二阶收敛，梯度下降是一阶收敛，所以牛顿法就更快</strong>。<strong>通俗地说</strong>，比如你想找一条最短的路径走到一个盆地的最底部，梯度下降法 每次只从你当前所处位置选一个坡度最大的方向走一步，牛顿法在选择方向时，不仅会考虑坡度是否够大，还会考虑你走了一步之后，坡度是否会变得更大。所以， 可以说牛顿法比梯度下降法看得更远一点，能更快地走到最底部。</p>
<p><img src="http://p4rlzrioq.bkt.clouddn.com/%E7%89%9B%E9%A1%BF%E6%B3%95.jpg" alt=""></p>
<p>或者从几何上说，<strong>牛顿法就是用一个二次曲面去拟合你当前所处位置的局部曲面，而梯度下降法是用一个平面去拟合当前的局部曲面</strong>，通常情况下，二次曲面的拟合会比平面更好，所以牛顿法选择的下降路径会更符合真实的最优下降路径。</p>
<h3 id="牛顿法的推导"><a href="#牛顿法的推导" class="headerlink" title="牛顿法的推导"></a><strong>牛顿法的推导</strong></h3><p>将目标函数\(f\left( x \right)\) 在\(x_{k}\)处进行二阶泰勒展开，可得：</p>
<p>$$f\left( x \right) =f\left( x_{k} \right) +f^{‘} \left( x_{k} \right) \left( x-x_{k} \right) +\frac{1}{2} f^{‘’}\left( x_{k} \right) \left( x-x_{k} \right) ^{2}$$<br>因为目标函数\(f\left( x \right)\)有极值的必要条件是在极值点处一阶导数为0，即：\(f^{‘} \left( x \right) =0\)</p>
<p>所以对上面的展开式两边同时求导（注意\({x}\)才是变量，\(x_{k}\)是常量\(\Rightarrow f^{‘} \left( x_{k} \right) ,f^{‘’} \left( x_{k} \right)\)都是常量），并令\(f^{‘} \left( x \right) =0\)可得：</p>
<p>$$f^{‘} \left( x_{k} \right) +f^{‘’} \left( x_{k} \right) \left( x-x_{k} \right) =0$$<br>即：</p>
<p>$$x=x_{k} -\frac{f^{‘} \left( x_{k} \right) }{f^{‘’} \left( x_{k} \right) } $$</p>
<p>于是可以构造如下的迭代公式：</p>
<p>$$x_{k+1} =x_{k} -\frac{f^{‘} \left( x_{k} \right) }{f^{‘’} \left( x_{k} \right) }$$</p>
<p>这样，我们就可以利用该迭代式依次产生的序列逐渐逼近\(f\left( x \right)\)的极小值点了。</p>
<p>牛顿法的迭代示意图如下：</p>
<p><img src="http://p4rlzrioq.bkt.clouddn.com/%E7%89%9B%E9%A1%BF%E6%B3%95%E7%9A%84%E8%BF%AD%E4%BB%A3%E7%A4%BA%E6%84%8F%E5%9B%BE%E5%A6%82%E4%B8%8B.jpg" alt=""></p>
<p>上面讨论的是2维情况，<strong>高维情况</strong>的牛顿迭代公式是：</p>
<p><img src="http://p4rlzrioq.bkt.clouddn.com/%E9%AB%98%E7%BB%B4%E6%83%85%E5%86%B5%E7%9A%84%E7%89%9B%E9%A1%BF%E8%BF%AD%E4%BB%A3%E5%85%AC%E5%BC%8F.jpg" alt=""></p>
<p>式中， ▽\({f}\)是\(f\left( x \right)\)的梯度，即：</p>
<p><img src="http://p4rlzrioq.bkt.clouddn.com/%E7%89%9B%E9%A1%BF%E6%B3%953.jpg" alt=""></p>
<p>H是Hessen矩阵，即：</p>
<p><img src="http://p4rlzrioq.bkt.clouddn.com/Hessen%E7%9F%A9%E9%98%B5.jpg" alt=""></p>
<h3 id="牛顿法的过程"><a href="#牛顿法的过程" class="headerlink" title="牛顿法的过程"></a><strong>牛顿法的过程</strong></h3><ul>
<li>1、给定初值\(x_{0} ]\)和精度阈值\(\varepsilon\)，并令\(k=0\)；</li>
<li>2、计算\(x_{k}\)和\(H_{k}\)；</li>
<li>3、若\(\left| \left| g_{k} \right| \right| &lt;\varepsilon\)则停止迭代；否则确定搜索方向：\(d_{k} =-H_{k}^{-1} \cdot g_{k}\)；</li>
<li>4、计算新的迭代点：\(x_{k+1} =x_{k} +d_{k}\)；</li>
<li>5、令\(k=k+1\)，转至2。</li>
</ul>
<h2 id="5-阻尼牛顿法"><a href="#5-阻尼牛顿法" class="headerlink" title="5.阻尼牛顿法"></a>5.<strong>阻尼牛顿法</strong></h2><h3 id="引入"><a href="#引入" class="headerlink" title="引入"></a><strong>引入</strong></h3><p>注意到，牛顿法的迭代公式中没有步长因子，是定步长迭代。对于非二次型目标函数，有时候会出现\(f\left( x_{k+1} \right) &gt;f\left( x_{k} \right)\)的情况，这表明，原始牛顿法不能保证函数值稳定的下降。在严重的情况下甚至会造成序列发散而导致计算失败。</p>
<p>为消除这一弊病，人们又提出阻尼牛顿法。阻尼牛顿法每次迭代的方向仍然是\(x_{k}\)，但每次迭代会沿此方向做一维搜索，寻求最优的步长因子\(\lambda _{k}\)，即：</p>
<p>\(\lambda <em>{k} = minf\left( x</em>{k} +\lambda d_{k} \right)\)</p>
<h3 id="算法过程"><a href="#算法过程" class="headerlink" title="算法过程"></a><strong>算法过程</strong></h3><ul>
<li>1、给定初值\(x_{0}\)和精度阈值\(\varepsilon\)，并令\(k=0\)；</li>
<li>2、计算\(g_{k}\)（\(f\left( x \right)\)在\(x_{k}\)处的梯度值）和\(H_{k}\)；</li>
<li>3、若\(\left| \left| g_{k} \right| \right| &lt;\varepsilon\)则停止迭代；否则确定搜索方向：\(d_{k} =-H_{k}^{-1} \cdot g_{k}\)；</li>
<li>4、利用\(d_{k} =-H_{k}^{-1} \cdot g_{k}\)得到步长\(\lambda <em>{k}\)，并令\(x</em>{k+1} =x_{k} +\lambda <em>{k} d</em>{k}\)</li>
<li>5、令\(k=k+1\)，转至2。</li>
</ul>
<h2 id="6-拟牛顿法"><a href="#6-拟牛顿法" class="headerlink" title="6.拟牛顿法"></a>6.<strong>拟牛顿法</strong></h2><h3 id="概述"><a href="#概述" class="headerlink" title="概述"></a><strong>概述</strong></h3><p>由于<strong>牛顿法</strong>每一步都要求解目标函数的<strong>Hessen矩阵的逆矩阵</strong>，<strong>计算量比较大</strong>（求矩阵的逆运算量比较大），因此提出一种<strong>改进方法</strong>，即<strong>通过正定矩阵近似代替Hessen矩阵的逆矩阵，简化这一计算过程</strong>，改进后的方法称为<strong>拟牛顿法</strong>。</p>
<h3 id="拟牛顿法的推导"><a href="#拟牛顿法的推导" class="headerlink" title="拟牛顿法的推导"></a><strong>拟牛顿法的推导</strong></h3><p>先将目标函数在\(x_{k+1}\)处展开，得到：</p>
<p>$$f\left( x \right) =f\left( x_{k+1} \right) +f^{‘} \left( x_{k+1} \right) \left( x-x_{k+1} \right) +\frac{1}{2} f^{‘’}\left( x_{k+1} \right) \left( x-x_{k+1} \right) ^{2}$$<br>两边同时取梯度，得：</p>
<p>$$f^{‘}\left( x \right) = f^{‘} \left( x_{k+1} \right) +f^{‘’} \left( x_{k+1} \right) \left( x-x_{k+1} \right)$$</p>
<p>取上式中的\(x=x_{k}\)，得：</p>
<p>$$f^{‘}\left( x_{k} \right) = f^{‘} \left( x_{k+1} \right) +f^{‘’} \left( x_{k+1} \right) \left( x-x_{k+1} \right)$$</p>
<p>即：</p>
<p>$$g_{k+1} -g_{k} =H_{k+1} \cdot \left( x_{k+1} -x_{k} \right)$$<br>可得：</p>
<p>$$H_{k}^{-1} \cdot \left( g_{k+1} -g_{k} \right) =x_{k+1} -x_{k}$$</p>
<p>上面这个式子称为<strong>“拟牛顿条件”</strong>，由它来对Hessen矩阵做约束。</p>
<hr>
<h1 id="计算复杂性与NP问题"><a href="#计算复杂性与NP问题" class="headerlink" title="计算复杂性与NP问题"></a><strong>计算复杂性与NP问题</strong></h1><h2 id="时间复杂度"><a href="#时间复杂度" class="headerlink" title="时间复杂度"></a>时间复杂度</h2><p>表明问题规模扩大后，程序需要的时间长度增长得有多快。程序的时间复杂度一般可以分为两种级别：</p>
<ul>
<li>多项式级的复杂度，如O(1)，O(log(n))、O（n^a）等，</li>
<li>非多项式级的，如O(a^n)、O(n!)等。后者的复杂度计算机往往不能承受。</li>
</ul>
<h2 id="约化-Reducibility"><a href="#约化-Reducibility" class="headerlink" title="约化(Reducibility)"></a>约化(Reducibility)</h2><p>简单的说，一个问题A可以约化为问题B的含义是，可以用问题B的解法解决问题A。（个人感觉也就是说，问题A是B的一种特殊情况。）标准化的定义是，如果能找到一个变化法则，对任意一个A程序的输入，都能按照这个法则变换成B程序的输入，使两程序的输出相同，那么我们说，问题A可以约化为问题B。</p>
<p>例如求解一元一次方程这个问题可以约化为求解一元二次方程，即可以令对应项系数不变，二次项的系数为0，将A的问题的输入参数带入到B问题的求解程序去求解。</p>
<p>另外，约化还具有传递性，A可以化约为B，B可以约化为C，那么A也可以约化为C。</p>
<h2 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h2><h3 id="P-Problem"><a href="#P-Problem" class="headerlink" title="P Problem"></a>P Problem</h3><p>假设有 n 个数要排序。一个初级的冒泡排序算法所需时间可能与 n2 成正比，快一点的算法所需时间与 nlog（n） 成正比。在某些条件下，桶排序算法所需时间甚至只和 n 成正比。最不实用的算法就是输入的数字随机排列，直到出现完全有序的情况为止……记前三个算法的时间复杂度分别记为 O(n2)、O(nlogn) 和 O(n)，最后的<a href="http://zh.wikipedia.org/wiki/Bogo%E6%8E%92%E5%BA%8F" target="_blank" rel="noopener">“猴子排序”(Bogosort)算法</a>平均时间复杂度则达到了 O(n*n!)。</p>
<p>在上面的例子中，前三种算法的复杂度是 n 的多项式函数；最后一种算法的复杂度是 n 的阶乘，根据斯特林公式，n! 相当于指数级别的增长。当 n 特别小时，多项式级的算法已经快过指数级的算法。当 n 非常大时，人类根本看不到指数级复杂度算法结束的那天。自然的，大家会对多项式级别的算法抱有好感，希望对每一个问题都能找到多项式级别的算法。问题是——每个问题都能找到想要的多项式级别的算法吗？</p>
<p>在一个由问题构成的集合中，如果每个问题都存在多项式级复杂度的算法，这个集合就是 P 类问题（Polynomial）。</p>
<h3 id="NP-Nondeterministic-Polynomial-问题"><a href="#NP-Nondeterministic-Polynomial-问题" class="headerlink" title="NP (Nondeterministic Polynomial)问题"></a>NP (Nondeterministic Polynomial)问题</h3><p>NP 类问题指的是，能在多项式时间内<strong>检验</strong>一个解是否正确的问题。比如我的机器上存有一个密码文件，于是就能在多项式时间内验证另一个字符串文件是否等于这个密码，所以“破译密码”是一个 NP 类问题。NP 类问题也等价为能在多项式时间内<strong>猜出</strong>一个解的问题。这里的“猜”指的是如果有解，那每次都能在很多种可能的选择中运气极佳地选择正确的一步。</p>
<p>不妨举个例子：给出 n 个城市和两两之间的距离，求找到一个行走方案，使得到达每个城市一次的总路程最短。我们可以这样来“猜测”它的解：先求一个总路程不超过 100 的方案，假设我们可以依靠极好的运气“猜出”一个行走路线，使得总长度确实不超过 100，那么我们只需要每次猜一条路一共猜 n 次。接下来我们再找总长度不超过 50 的方案，找不到就将阈值提高到75…… 假设最后找到了总长度为 90 的方案，而找不到总长度小于 90 的方案。我们最终便在多项式时间内“猜”到了这个旅行商问题的解是一个长度为 90 的路线。它是一个 NP 类的问题。</p>
<p>也就是说，NP 问题能在多项式时间内“解决”，只不过需要好运气。显然，P 类问题肯定属于 NP 类问题。所谓“P=NP”，就是问——是不是所有的 NP 问题，都能找到多项式时间的确定性算法？</p>
<h3 id="NPC-Problem"><a href="#NPC-Problem" class="headerlink" title="NPC Problem"></a>NPC Problem</h3><p>在与数不尽的问题搏斗的过程中，人们有时候会发现，解决问题 A 的算法可以同时用来解决问题 B。例如问题 A 是对学生的姓名与所属班级同时排序，问题 B 是对人们按照姓名做排序。这时候，我们只需要让班级全都相同，便能照搬问题 A 的算法来解决问题 B。这种情况下，数学家就说，问题 B 能归约为问题 A。</p>
<p>人们发现，不同的 NP 问题之间也会出现可归约的关系，甚至存在这么一类（不只是一个）问题，使得任何其它的 NP 问题都能归约到它们上。也就是说，能够解决它们的算法就能够解决所有其它的 NP 问题。这一类问题就是 NPC 问题。这样的问题人们已经找到了几千个，如果我们给其中任何一个找到了多项式级别的算法，就相当于证明了 P=NP。</p>
<p>但NPC问题目前没有多项式的有效算法，只能用指数级甚至阶乘级复杂度的搜索。</p>
<h3 id="P-NP？"><a href="#P-NP？" class="headerlink" title="P=NP？"></a>P=NP？</h3><p>证明 P=NP 的一个主要方法就是，给某一个 NPC 问题找到一个快速算法。但是，也不排除有人给出一个“存在性”而非“构造性”的证明，只是告诉大家存在符合要求的算法，但没法详细描述出来。如果 P=NP 被人以这种方式证明出来了，我们也没法依葫芦画瓢地把这个神奇的算法在电脑上写出来，所以对破解密码仍然没有帮助。</p>
<p>退一步说，假如有人构造出可以运用的多项式算法，以此证明了这个问题。这个算法恐怕也很复杂（毕竟这么难找），它的多项式级别的复杂度也可能会非常慢。假设这个算法的复杂度达到了 O(n10)，那我们依然面临着不小的麻烦。即使 n=100，运算时间也会增长到非常巨大的地步。</p>
<p>再退一步，假设人类的运气好到 P=NP 是真的，并且找到了复杂度不超过 O(n3) 的算法。如果到了这一步，我们就会有一个算法，能够很快算出某个帐号的密码。《基本演绎法》里面所想象的可能就要成真了，所有的加密系统都会失去效果——应该说，所有会把密码变成数字信息的系统都会失去效果，因为这个数字串很容易被“金钥匙”计算出来。</p>
<p>除此之外，我们需要担心或期许的事情还有很多：</p>
<ul>
<li>一大批耳熟能详的游戏，如扫雷、俄罗斯方块、超级玛丽等，人们将为它们编写出高效的AI，使得电脑玩游戏的水平无人能及。</li>
<li>整数规划、旅行商问题等许多运筹学中的难题会被高效地解决，这个方向的研究将提升到前所未有的高度。</li>
<li>蛋白质的折叠问题也是一个 NPC 问题，新的算法无疑是生物与医学界的一个福音。</li>
</ul>
<p>参考文献：<br><a href="http://www.junnanzhu.com/?p=141" target="_blank" rel="noopener">http://www.junnanzhu.com/?p=141</a><br><a href="https://www.zybuluo.com/frank-shaw/note/139175" target="_blank" rel="noopener">https://www.zybuluo.com/frank-shaw/note/139175</a><br><a href="http://colah.github.io/posts/2015-09-Visual-Information/" target="_blank" rel="noopener">http://colah.github.io/posts/2015-09-Visual-Information/</a><br><a href="https://www.guokr.com/article/437662/" target="_blank" rel="noopener">https://www.guokr.com/article/437662/</a><br><a href="https://www.zhihu.com/question/22178202" target="_blank" rel="noopener">https://www.zhihu.com/question/22178202</a></p>

      
    </div>
    
    
    

    

    <div>
      
        <div>
    
        <div style="text-align:center;color: #ccc;font-size:14px;">-------------本文结束<i class="fa fa-paw"></i>感谢您的阅读-------------</div>
    
</div>
      
    </div>

    
      <div>
        <div style="padding: 10px 0; margin: 20px auto; width: 90%; text-align: center;">
  <div>Donate comment here</div>
  <button id="rewardButton" disable="enable" onclick="var qr = document.getElementById('QR'); if (qr.style.display === 'none') {qr.style.display='block';} else {qr.style.display='none'}">
    <span>打赏</span>
  </button>
  <div id="QR" style="display: none;">

    
      <div id="wechat" style="display: inline-block">
        <img id="wechat_qr" src="/images/wechatpay.png" alt="FGY 微信支付"/>
        <p>微信支付</p>
      </div>
    

    
      <div id="alipay" style="display: inline-block">
        <img id="alipay_qr" src="/images/alipay.jpg" alt="FGY 支付宝"/>
        <p>支付宝</p>
      </div>
    

    

  </div>
</div>

      </div>
    

    
      <div>
        <ul class="post-copyright">
  <li class="post-copyright-author">
    <strong>本文作者：</strong>
    FGY
  </li>
  <li class="post-copyright-link">
    <strong>本文链接：</strong>
    <a href="http://frankblog.site/2018/05/30/机器学习基础（二）/" title="机器学习基础（二）">http://frankblog.site/2018/05/30/机器学习基础（二）/</a>
  </li>
  <li class="post-copyright-license">
    <strong>版权声明： </strong>
    本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/3.0/" rel="external nofollow" target="_blank">CC BY-NC-SA 3.0</a> 许可协议。转载请注明出处！
  </li>
</ul>

      </div>
    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/机器学习/" rel="tag"><i class="fa fa-tag"></i> 机器学习</a>
          
            <a href="/tags/深度学习/" rel="tag"><i class="fa fa-tag"></i> 深度学习</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2018/05/18/机器学习基础/" rel="next" title="机器学习基础（一）">
                <i class="fa fa-chevron-left"></i> 机器学习基础（一）
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2018/06/01/深度学习之Tensorflow(一)/" rel="prev" title="深度学习之Tensorflow(一)">
                深度学习之Tensorflow(一) <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>
  <aside id="sidebar" class="sidebar">
    
      <div id="sidebar-dimmer"></div>
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="/images/风景.jpeg"
                alt="FGY" />
            
              <p class="site-author-name" itemprop="name">FGY</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">
            

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">22</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">11</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">32</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>

            

          </nav>


          
            <div class="feed-link motion-element">
              <a href="/atom.xml" rel="alternate">
                <i class="fa fa-rss"></i>
                RSS
              </a>
            </div>
          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/fgyeason" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i>GitHub</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="https://www.kaggle.com/fgy0303" target="_blank" title="Kaggle">
                      
                        <i class="fa fa-fw fa-database"></i>Kaggle</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="https://music.163.com/#/playlist?id=2130685222" target="_blank" title="云音乐">
                      
                        <i class="fa fa-fw fa-music"></i>云音乐</a>
                  </span>
                
            </div>
          

          
          

          

          
            <div class="links-of-blogroll motion-element links-of-blogroll-inline">
              <div class="links-of-blogroll-title">
                <i class="fa  fa-fw fa-link"></i>
                Links
              </div>
              <ul class="links-of-blogroll-list">
                
                  <li class="links-of-blogroll-item">
                    <a href="http://xgboost.apachecn.org/cn/latest/" title="XGBoost" target="_blank">XGBoost</a>
                  </li>
                
                  <li class="links-of-blogroll-item">
                    <a href="https://www.lfd.uci.edu/~gohlke/pythonlibs/#wordcloud" title="Py_whl" target="_blank">Py_whl</a>
                  </li>
                
                  <li class="links-of-blogroll-item">
                    <a href="https://www.coursera.org/" title="Coursera" target="_blank">Coursera</a>
                  </li>
                
                  <li class="links-of-blogroll-item">
                    <a href="https://juejin.im" title="掘金" target="_blank">掘金</a>
                  </li>
                
                  <li class="links-of-blogroll-item">
                    <a href="https://uqer.io/data/browse/0/?page=1" title="量化" target="_blank">量化</a>
                  </li>
                
                  <li class="links-of-blogroll-item">
                    <a href="https://www.jiqizhixin.com/" title="机器之心" target="_blank">机器之心</a>
                  </li>
                
                  <li class="links-of-blogroll-item">
                    <a href="http://tool.chinaz.com/" title="站长工具" target="_blank">站长工具</a>
                  </li>
                
              </ul>
            </div>
          
          

          
        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#线性代数"><span class="nav-number">1.</span> <span class="nav-text">线性代数</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-数据类型比较"><span class="nav-number">1.1.</span> <span class="nav-text">1.数据类型比较</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-线性代数概念"><span class="nav-number">1.2.</span> <span class="nav-text">2.线性代数概念</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-新视角看待矩阵运算"><span class="nav-number">1.3.</span> <span class="nav-text">3.新视角看待矩阵运算</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-矩阵"><span class="nav-number">1.3.1.</span> <span class="nav-text">1 矩阵</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-线性相关和线性无关"><span class="nav-number">1.3.2.</span> <span class="nav-text">2 线性相关和线性无关</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-向量空间的基"><span class="nav-number">1.3.3.</span> <span class="nav-text">3 向量空间的基</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-四个基本的子空间"><span class="nav-number">1.3.4.</span> <span class="nav-text">4 四个基本的子空间</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4-矩阵导数"><span class="nav-number">1.4.</span> <span class="nav-text">4.矩阵导数</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#5-特征分解"><span class="nav-number">1.5.</span> <span class="nav-text">5.特征分解</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-特征分解"><span class="nav-number">1.5.1.</span> <span class="nav-text">1 特征分解</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-PCA"><span class="nav-number">1.5.2.</span> <span class="nav-text">2 PCA</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#6-奇异值分解（Singular-Value-Decomposition，SVD）"><span class="nav-number">1.6.</span> <span class="nav-text">6.奇异值分解（Singular Value Decomposition，SVD）</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#7-常见距离"><span class="nav-number">1.7.</span> <span class="nav-text">7.常见距离</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-闵可夫斯基距离"><span class="nav-number">1.7.1.</span> <span class="nav-text">1.闵可夫斯基距离</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-向量内积"><span class="nav-number">1.7.2.</span> <span class="nav-text">2. 向量内积</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-分类数据点间的距离"><span class="nav-number">1.7.3.</span> <span class="nav-text">3. 分类数据点间的距离</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#概率论和统计"><span class="nav-number">2.</span> <span class="nav-text">概率论和统计</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-统计量"><span class="nav-number">2.1.</span> <span class="nav-text">1.统计量</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#协方差"><span class="nav-number">2.1.1.</span> <span class="nav-text">协方差</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Pearson相关系数"><span class="nav-number">2.1.2.</span> <span class="nav-text">Pearson相关系数</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#协方差矩阵"><span class="nav-number">2.1.3.</span> <span class="nav-text">协方差矩阵</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-独立与不相关"><span class="nav-number">2.2.</span> <span class="nav-text">2.独立与不相关</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-贝叶斯公式"><span class="nav-number">2.3.</span> <span class="nav-text">3.贝叶斯公式</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4-常见分布函数"><span class="nav-number">2.4.</span> <span class="nav-text">4.常见分布函数</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#0-1分布"><span class="nav-number">2.4.1.</span> <span class="nav-text">0-1分布</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#几何分布"><span class="nav-number">2.4.2.</span> <span class="nav-text">几何分布</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#二项分布"><span class="nav-number">2.4.3.</span> <span class="nav-text">二项分布</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#高斯分布"><span class="nav-number">2.4.4.</span> <span class="nav-text">高斯分布</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#指数分布"><span class="nav-number">2.4.5.</span> <span class="nav-text">指数分布</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#泊松分布"><span class="nav-number">2.4.6.</span> <span class="nav-text">泊松分布</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#5-常见的分布总结"><span class="nav-number">2.5.</span> <span class="nav-text">5.常见的分布总结</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#6-极大似然估计（MLE）"><span class="nav-number">2.6.</span> <span class="nav-text">6.极大似然估计（MLE）</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#微积分"><span class="nav-number">3.</span> <span class="nav-text">微积分</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-导数与梯度"><span class="nav-number">3.1.</span> <span class="nav-text">1.导数与梯度</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-泰勒展开"><span class="nav-number">3.2.</span> <span class="nav-text">2.泰勒展开</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-Lagrange乘子法"><span class="nav-number">3.3.</span> <span class="nav-text">3.Lagrange乘子法</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#信息论"><span class="nav-number">4.</span> <span class="nav-text">信息论</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-信息熵"><span class="nav-number">4.1.</span> <span class="nav-text">1.信息熵</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#信息熵的实例解释"><span class="nav-number">4.1.1.</span> <span class="nav-text">信息熵的实例解释</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-相对熵-交叉熵-K-L散度"><span class="nav-number">4.2.</span> <span class="nav-text">2.相对熵/交叉熵/K-L散度</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-互信息（信息增益）"><span class="nav-number">4.3.</span> <span class="nav-text">3.互信息（信息增益）</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#信息论与机器学习的关系"><span class="nav-number">4.4.</span> <span class="nav-text">信息论与机器学习的关系</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#最大熵模型"><span class="nav-number">4.5.</span> <span class="nav-text">最大熵模型</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#熵总结"><span class="nav-number">4.6.</span> <span class="nav-text">熵总结</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-上溢和下溢"><span class="nav-number">4.7.</span> <span class="nav-text">2.上溢和下溢</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#凸优化"><span class="nav-number">5.</span> <span class="nav-text">凸优化</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-凸集-Convex-Sets"><span class="nav-number">5.1.</span> <span class="nav-text">1.凸集(Convex Sets)</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-凸函数-Convex-Fuctions"><span class="nav-number">5.2.</span> <span class="nav-text">2.凸函数(Convex Fuctions)</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#凸函数的一阶条件"><span class="nav-number">5.2.1.</span> <span class="nav-text">凸函数的一阶条件</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#凸性质的二阶条件"><span class="nav-number">5.2.2.</span> <span class="nav-text">凸性质的二阶条件</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#琴生不等式-Jensen’s-Inequality"><span class="nav-number">5.2.3.</span> <span class="nav-text">琴生不等式(Jensen’s Inequality)</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-凸优化问题-Convex-Optimization-Problems"><span class="nav-number">5.3.</span> <span class="nav-text">3.凸优化问题(Convex Optimization Problems)</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4-牛顿法"><span class="nav-number">5.4.</span> <span class="nav-text">4.牛顿法</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#牛顿法介绍"><span class="nav-number">5.4.1.</span> <span class="nav-text">牛顿法介绍</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#牛顿法的推导"><span class="nav-number">5.4.2.</span> <span class="nav-text">牛顿法的推导</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#牛顿法的过程"><span class="nav-number">5.4.3.</span> <span class="nav-text">牛顿法的过程</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#5-阻尼牛顿法"><span class="nav-number">5.5.</span> <span class="nav-text">5.阻尼牛顿法</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#引入"><span class="nav-number">5.5.1.</span> <span class="nav-text">引入</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#算法过程"><span class="nav-number">5.5.2.</span> <span class="nav-text">算法过程</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#6-拟牛顿法"><span class="nav-number">5.6.</span> <span class="nav-text">6.拟牛顿法</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#概述"><span class="nav-number">5.6.1.</span> <span class="nav-text">概述</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#拟牛顿法的推导"><span class="nav-number">5.6.2.</span> <span class="nav-text">拟牛顿法的推导</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#计算复杂性与NP问题"><span class="nav-number">6.</span> <span class="nav-text">计算复杂性与NP问题</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#时间复杂度"><span class="nav-number">6.1.</span> <span class="nav-text">时间复杂度</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#约化-Reducibility"><span class="nav-number">6.2.</span> <span class="nav-text">约化(Reducibility)</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#基本概念"><span class="nav-number">6.3.</span> <span class="nav-text">基本概念</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#P-Problem"><span class="nav-number">6.3.1.</span> <span class="nav-text">P Problem</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#NP-Nondeterministic-Polynomial-问题"><span class="nav-number">6.3.2.</span> <span class="nav-text">NP (Nondeterministic Polynomial)问题</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#NPC-Problem"><span class="nav-number">6.3.3.</span> <span class="nav-text">NPC Problem</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#P-NP？"><span class="nav-number">6.3.4.</span> <span class="nav-text">P=NP？</span></a></li></ol></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

<iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width=330 height=450 src="//music.163.com/outchain/player?type=0&id=2130685222&auto=1&height=430"></iframe>

      

    </div>
  </aside>




        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js">
</script>

<div class="copyright">&copy; <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">FGY</span>

  
</div>



  <div class="powered-by">
  <i class="fa fa-user-md"></i><span id="busuanzi_container_site_uv">
    本站访客数: <span id="busuanzi_value_site_uv"></span>人
  </span>
  </div>
<span>|</span>
  <div class="powered-by">
  <i class="fa fa-user-md"></i><span id="busuanzi_container_site_uv">
    访问量: <span id="busuanzi_value_site_pv"></span>次
  </span>
  </div>


<!--  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Muse</a> v5.1.4</div>



-->
<!--
<div class="theme-info">
  <div class="powered-by"></div>
  <span class="post-count">博客全站共72.6k字</span>
</div>
-->




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    
      <div id="needsharebutton-float">
        <span class="btn">
          <i class="fa fa-share-alt" aria-hidden="true"></i>
        </span>
      </div>
    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  


  











  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  

  
  
    <script type="text/javascript" src="/lib/canvas-nest/canvas-nest.min.js"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  

  
  
  
  <link rel="stylesheet" href="/lib/needsharebutton/needsharebutton.css">

  
  
  <script src="/lib/needsharebutton/needsharebutton.js"></script>

  <script>
    
    
      flOptions = {};
      
          flOptions.iconStyle = "box";
      
          flOptions.boxForm = "horizontal";
      
          flOptions.position = "middleRight";
      
          flOptions.networks = "Weibo,Wechat,Douban,QQZone,Twitter,Facebook";
      
      new needShareButton('#needsharebutton-float', flOptions);
    
  </script>

  

  
  


  

  

<!-- -->
  
</body>
</html>

<!-- 页面点击小红心 -->
<script type="text/javascript" src="/js/src/love.js"></script>
