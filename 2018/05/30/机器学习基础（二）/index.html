<!DOCTYPE html>



  


<html class="theme-next muse use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">


  
  
    
    
  <script src="/lib/pace/pace.min.js?v=1.0.2"></script>
  <link href="/lib/pace/pace-theme-minimal.min.css?v=1.0.2" rel="stylesheet">


 <script>     
    (function(){
        if(''){
            if (prompt('请输入文章密码') !== ''){
                alert('密码错误！');
                history.back();
            }
        }
    })();
</script>







<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="机器学习,深度学习," />





  <link rel="alternate" href="/atom.xml" title="Frank's Blog" type="application/atom+xml" />






<meta name="keywords" content="机器学习,深度学习">
<meta property="og:type" content="article">
<meta property="og:title" content="机器学习基础（二）">
<meta property="og:url" content="http://frankblog.site/2018/05/30/机器学习基础（二）/index.html">
<meta property="og:site_name" content="Frank&#39;s Blog">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="http://p4rlzrioq.bkt.clouddn.com/ai%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0.jpg">
<meta property="og:image" content="http://p4rlzrioq.bkt.clouddn.com/%E7%9F%A9%E9%98%B5%E5%88%86%E5%AD%90%E5%88%86%E6%AF%8D%E5%B8%83%E5%B1%80%E8%BF%90%E7%AE%97.png">
<meta property="og:image" content="http://p4rlzrioq.bkt.clouddn.com/%E7%9F%A9%E9%98%B5%E6%B1%82%E5%AF%BC%E9%9C%80%E8%A6%81%E6%B3%A8%E6%84%8F%E7%9A%84%E8%A7%84%E5%88%99.png">
<meta property="og:image" content="http://p4rlzrioq.bkt.clouddn.com/%E7%9F%A9%E9%98%B5%E6%B1%82%E5%AF%BC%E9%9C%80%E8%A6%81%E6%B3%A8%E6%84%8F%E7%9A%84%E8%A7%84%E5%88%991.png">
<meta property="og:image" content="http://p4rlzrioq.bkt.clouddn.com/%E7%9F%A9%E9%98%B5%E6%B1%82%E5%AF%BC%E9%9C%80%E8%A6%81%E6%B3%A8%E6%84%8F%E7%9A%84%E8%A7%84%E5%88%992.png">
<meta property="og:image" content="http://p4rlzrioq.bkt.clouddn.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%B8%B8%E8%A7%81%E6%B1%82%E5%AF%BC%E6%96%B9%E5%BC%8F.png">
<meta property="og:image" content="http://p4rlzrioq.bkt.clouddn.com/%E4%B8%89%E9%98%B6%E5%BC%A0%E9%87%8F.jpg">
<meta property="og:image" content="http://p4rlzrioq.bkt.clouddn.com/%E8%8C%83%E6%95%B0.jpg">
<meta property="og:image" content="https://pic4.zhimg.com/80/v2-1581c66947da5c30172f4ef80dd0b70f_hd.jpg">
<meta property="og:image" content="https://pic4.zhimg.com/80/v2-2845b623dc537e3bae0db22c4938e9c1_hd.jpg">
<meta property="og:image" content="http://p4rlzrioq.bkt.clouddn.com/%E5%8D%8F%E6%96%B9%E5%B7%AE.png">
<meta property="og:image" content="http://p4rlzrioq.bkt.clouddn.com/%E5%8D%8F%E6%96%B9%E5%B7%AE1.png">
<meta property="og:image" content="http://p4rlzrioq.bkt.clouddn.com/%E5%8D%8F%E6%96%B9%E5%B7%AE2.png">
<meta property="og:image" content="http://p4rlzrioq.bkt.clouddn.com/Pearson%E7%9B%B8%E5%85%B3%E7%B3%BB%E6%95%B0.png">
<meta property="og:image" content="http://p4rlzrioq.bkt.clouddn.com/%E5%8D%8F%E6%96%B9%E5%B7%AE%E7%9F%A9%E9%98%B5.png">
<meta property="og:image" content="http://p4rlzrioq.bkt.clouddn.com/%E7%8B%AC%E7%AB%8B%E4%B8%8E%E4%B8%8D%E7%9B%B8%E5%85%B3.png">
<meta property="og:image" content="http://p4rlzrioq.bkt.clouddn.com/488px-Normal_Distribution_PDF.svg.png">
<meta property="og:image" content="http://p4rlzrioq.bkt.clouddn.com/%E6%AD%A3%E6%80%81%E5%88%86%E5%B8%83.png">
<meta property="og:image" content="http://p4rlzrioq.bkt.clouddn.com/%E6%8C%87%E6%95%B0%E5%88%86%E5%B8%83.jpg">
<meta property="og:image" content="http://p4rlzrioq.bkt.clouddn.com/%E5%B8%B8%E8%A7%81%E5%88%86%E5%B8%83.jpg">
<meta property="og:image" content="https://wikimedia.org/api/rest_v1/media/math/render/svg/d0070da6cb78cda75d9ff9521f85702c97862673">
<meta property="og:image" content="http://p4rlzrioq.bkt.clouddn.com/%E6%B3%B0%E5%8B%92%E5%B1%95%E5%BC%80.jpg">
<meta property="og:image" content="http://p4rlzrioq.bkt.clouddn.com/gini%E7%86%B5.png">
<meta property="og:image" content="http://p4rlzrioq.bkt.clouddn.com/%E6%9D%A1%E4%BB%B6%E7%86%B5.jpg">
<meta property="og:image" content="http://p4rlzrioq.bkt.clouddn.com/%E4%BA%92%E4%BF%A1%E6%81%AF.jpg">
<meta property="og:image" content="http://p4rlzrioq.bkt.clouddn.com/%E4%B8%8A%E6%BA%A2%E5%92%8C%E4%B8%8B%E6%BA%A2.jpg">
<meta property="og:image" content="http://p4rlzrioq.bkt.clouddn.com/%E5%87%B8%E9%9B%86.jpg">
<meta property="og:image" content="http://oddpnmpll.bkt.clouddn.com/2016-10-05-01%3A23%3A27.jpg">
<meta property="og:image" content="http://p4rlzrioq.bkt.clouddn.com/%E5%87%B8%E5%87%BD%E6%95%B0%E7%9A%84%E4%B8%80%E9%98%B6%E6%9D%A1%E4%BB%B6.png">
<meta property="og:image" content="http://oddpnmpll.bkt.clouddn.com/2016-10-05-01%3A27%3A53.jpg">
<meta property="og:image" content="http://p4rlzrioq.bkt.clouddn.com/%E5%87%B8%E5%87%BD%E6%95%B0%E7%9A%84%E4%BA%8C%E9%98%B6%E6%9D%A1%E4%BB%B6.png">
<meta property="og:image" content="http://p4rlzrioq.bkt.clouddn.com/%E5%87%B8%E4%BC%98%E5%8C%96%E9%97%AE%E9%A2%98.jpg">
<meta property="og:image" content="http://p4rlzrioq.bkt.clouddn.com/%E7%89%9B%E9%A1%BF%E6%B3%95.jpg">
<meta property="og:image" content="http://p4rlzrioq.bkt.clouddn.com/%E7%89%9B%E9%A1%BF%E6%B3%95%E7%9A%84%E8%BF%AD%E4%BB%A3%E7%A4%BA%E6%84%8F%E5%9B%BE%E5%A6%82%E4%B8%8B.jpg">
<meta property="og:image" content="http://p4rlzrioq.bkt.clouddn.com/%E9%AB%98%E7%BB%B4%E6%83%85%E5%86%B5%E7%9A%84%E7%89%9B%E9%A1%BF%E8%BF%AD%E4%BB%A3%E5%85%AC%E5%BC%8F.jpg">
<meta property="og:image" content="http://p4rlzrioq.bkt.clouddn.com/%E7%89%9B%E9%A1%BF%E6%B3%953.jpg">
<meta property="og:image" content="http://p4rlzrioq.bkt.clouddn.com/Hessen%E7%9F%A9%E9%98%B5.jpg">
<meta property="og:updated_time" content="2018-06-01T07:48:32.933Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="机器学习基础（二）">
<meta name="twitter:image" content="http://p4rlzrioq.bkt.clouddn.com/ai%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0.jpg">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":true},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://frankblog.site/2018/05/30/机器学习基础（二）/"/>





  <title>机器学习基础（二） | Frank's Blog</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">
  
  
    
  
  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>
    
    <a href="https://github.com/fgyeason" class="github-corner" aria-label="View source on Github"><svg width="80" height="80" viewBox="0 0 250 250" style="fill:#151513; color:#fff; position: absolute; top: 0; border: 0; right: 0;" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a><style>.github-corner:hover .octo-arm{animation:octocat-wave 560ms ease-in-out}@keyframes octocat-wave{0%,100%{transform:rotate(0)}20%,60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}@media (max-width:500px){.github-corner:hover .octo-arm{animation:none}.github-corner .octo-arm{animation:octocat-wave 560ms ease-in-out}}</style>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Frank's Blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">Enjoy everything fun and challenging</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            关于
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-books">
          <a href="/books/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-book"></i> <br />
            
            书籍
          </a>
        </li>
      
        
        <li class="menu-item menu-item-films">
          <a href="/films/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-film"></i> <br />
            
            电影
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off"
             placeholder="搜索..." spellcheck="false"
             type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>
<script src="https://cdn.bootcss.com/aplayer/1.6.0/APlayer.min.js"></script>


 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://frankblog.site/2018/05/30/机器学习基础（二）/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="FGY">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/风景.jpeg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Frank's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">机器学习基础（二）</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
              
                <span class="post-meta-item-text">发表于</span>
              

              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-05-30T14:05:51+08:00">
                2018-05-30
              </time>
            

            
              <span class="post-meta-divider">|</span>
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-check-o"></i>
              </span>
              
                <span class="post-meta-item-text">更新于&#58;</span>
              
              <time title="更新于" itemprop="dateModified" datetime="2018-06-01T15:48:32+08:00">
                2018-06-01
              </time>
            
          </span>


          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习</span>
                  </a>
                </span>

                
                
              
            </span>
          





          
            
          

        
          


          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  8,623 字  
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  34 分钟  
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <script src="\assets\js\APlayer.min.js"> </script><p><img src="http://p4rlzrioq.bkt.clouddn.com/ai%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0.jpg" alt=""></p>
<a id="more"></a>
<blockquote class="blockquote-center"><font size="5">从IT时代走向DT时代</font></blockquote>

<hr>
<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script>

<h1 id="线性代数"><a href="#线性代数" class="headerlink" title="线性代数"></a>线性代数</h1><h2 id="1-数据类型比较"><a href="#1-数据类型比较" class="headerlink" title="1.数据类型比较"></a>1.数据类型比较</h2><p>Scalar: 标量，可以看成一个数<br>Vector: 向量，可以看成一个一维数组<br>Matrix: 矩阵，可以看成二维数组<br>Tensor: 张量，三维或三维以上的数组的统称，维度不定</p>
<h2 id="2-矩阵导数"><a href="#2-矩阵导数" class="headerlink" title="2.矩阵导数"></a>2.矩阵导数</h2><ul>
<li>分子、分母布局：<br>分子布局：分子为列向量，或者分母为行向量；<br>分母布局：分母为列向量，或者分子为行向量；</li>
<li>运算规则：<br><img src="http://p4rlzrioq.bkt.clouddn.com/%E7%9F%A9%E9%98%B5%E5%88%86%E5%AD%90%E5%88%86%E6%AF%8D%E5%B8%83%E5%B1%80%E8%BF%90%E7%AE%97.png" alt=""></li>
<li>需要注意的规则：<br>以下公式默认在分子布局下的结果<br><img src="http://p4rlzrioq.bkt.clouddn.com/%E7%9F%A9%E9%98%B5%E6%B1%82%E5%AF%BC%E9%9C%80%E8%A6%81%E6%B3%A8%E6%84%8F%E7%9A%84%E8%A7%84%E5%88%99.png" alt="">；<img src="http://p4rlzrioq.bkt.clouddn.com/%E7%9F%A9%E9%98%B5%E6%B1%82%E5%AF%BC%E9%9C%80%E8%A6%81%E6%B3%A8%E6%84%8F%E7%9A%84%E8%A7%84%E5%88%991.png" alt="">；<img src="http://p4rlzrioq.bkt.clouddn.com/%E7%9F%A9%E9%98%B5%E6%B1%82%E5%AF%BC%E9%9C%80%E8%A6%81%E6%B3%A8%E6%84%8F%E7%9A%84%E8%A7%84%E5%88%992.png" alt=""></li>
<li>常用公式<br><img src="http://p4rlzrioq.bkt.clouddn.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%B8%B8%E8%A7%81%E6%B1%82%E5%AF%BC%E6%96%B9%E5%BC%8F.png" alt=""></li>
</ul>
<h2 id="3-张量（Tensor）"><a href="#3-张量（Tensor）" class="headerlink" title="3.张量（Tensor）"></a>3.<strong>张量（Tensor）</strong></h2><ul>
<li><p>几何代数中定义的张量是基于向量和矩阵的推广，通俗一点理解的话，我们可以将标量视为零阶张量，矢量视为一阶张量，那么矩阵就是二阶张量。<br>例如，可以将任意一张彩色图片表示成一个三阶张量，三个维度分别是图片的高度、宽度和色彩数据。将这张图用张量表示出来，就是最下方的那张表格：<br><img src="http://p4rlzrioq.bkt.clouddn.com/%E4%B8%89%E9%98%B6%E5%BC%A0%E9%87%8F.jpg" alt=""></p>
</li>
<li><p>当然我们还可以将这一定义继续扩展，即：我们可以用四阶张量表示一个包含多张图片的数据集，这四个维度分别是：图片在数据集中的编号，图片高度、宽度，以及色彩数据。</p>
</li>
<li><p>张量在深度学习中是一个很重要的概念，因为它是一个深度学习框架中的一个核心组件，后续的所有运算和优化算法几乎都是基于张量进行的。</p>
</li>
</ul>
<h2 id="4-范数（Norm）"><a href="#4-范数（Norm）" class="headerlink" title="4.范数（Norm）"></a>4.<strong>范数（Norm）</strong></h2><p>有时我们需要衡量一个向量的大小。在机器学习中，我们经常使用被称为范数(norm) 的函数衡量矩阵大小。Lp 范数如下：</p>
<p>$$<br>Lp=\sqrt[p]{\sum\limits_{1}^n  x_i^p}，x=(x_1,x_2,\cdots,x_n)<br>$$<br>所以：<br>L1范数\(\left| \left| x \right| \right|\)：为x向量各个元素绝对值之和；<br>L2范数\(\left| \left| x \right| \right| _{2}\)： 为x向量各个元素平方和。<br><img src="http://p4rlzrioq.bkt.clouddn.com/%E8%8C%83%E6%95%B0.jpg" alt="link"></p>
<h2 id="5-特殊矩阵"><a href="#5-特殊矩阵" class="headerlink" title="5.特殊矩阵"></a>5.特殊矩阵</h2><p>对角矩阵<br>实对称矩阵及其性质：<br>（1）A的特征值为实数，且其特征向量为实向量<br>（2）A的不同特征值对应的特征向量必定正交<br>（3）A一定有n个线性无关的特征向量，从而A相似于对角矩阵<br>正交矩阵的性质： \(A^{-1}=A^{\top}\)</p>
<h2 id="6-奇异值分解（Singular-Value-Decomposition，SVD）"><a href="#6-奇异值分解（Singular-Value-Decomposition，SVD）" class="headerlink" title="6.奇异值分解（Singular Value Decomposition，SVD）"></a>6.<strong>奇异值分解（Singular Value Decomposition，SVD）</strong></h2><p>那就是只有对可对角化的矩阵才可以进行特征分解。但实际中很多矩阵往往不满足这一条件，甚至很多矩阵都不是方阵，就是说连矩阵行和列的数目都不相等。这时候怎么办呢？人们将矩阵的特征分解进行推广，得到了一种叫作“矩阵的奇异值分解”的方法，简称SVD。</p>
<p>$$A=UDV^{T} $$<br>假设A是一个<strong>m\(\times \)n</strong>矩阵，那么<strong>U是一个m\(\times \)m矩阵</strong>，<strong>D是一个m\(\times \)n矩阵</strong>，<strong>V是一个n\(\times \)n矩阵</strong>。</p>
<p>这些矩阵每一个都拥有特殊的结构，其中U和V都是正交矩阵，D是对角矩阵（注意，D不一定是方阵）。对角矩阵D对角线上的元素被称为矩阵A的奇异值。矩阵U的列向量被称为<strong>左奇异向量</strong>，矩阵V 的列向量被称<strong>右奇异向量</strong>。</p>
<p>SVD最有用的一个性质可能是拓展矩阵求逆到非方矩阵上。另外，SVD可用于推荐系统中。</p>
<h2 id="7-Moore-Penrose伪逆"><a href="#7-Moore-Penrose伪逆" class="headerlink" title="7.Moore-Penrose伪逆"></a>7.<strong>Moore-Penrose伪逆</strong></h2><p>对于非方矩阵而言，其逆矩阵没有定义。假设在下面问题中，我们想通过矩阵A的左逆B来求解线性方程：</p>
<p>\(Ax=y\)</p>
<p>等式两边同时左乘左逆B后，得到：</p>
<p>\(x=By\)</p>
<p>是否存在唯一的映射将A映射到B取决于问题的形式。</p>
<p>如果矩阵A的行数大于列数，那么上述方程可能没有解；如果矩阵A的行数小于列数，那么上述方程可能有多个解。</p>
<p>Moore-Penrose伪逆使我们能够解决这种情况，矩阵A的伪逆定义为：</p>
<p><img src="https://pic4.zhimg.com/80/v2-1581c66947da5c30172f4ef80dd0b70f_hd.jpg" alt=""></p>
<p>但是计算伪逆的实际算法没有基于这个式子，而是使用下面的公式：</p>
<p><img src="https://pic4.zhimg.com/80/v2-2845b623dc537e3bae0db22c4938e9c1_hd.jpg" alt=""></p>
<p>其中，矩阵U，D 和V 是矩阵A奇异值分解后得到的矩阵。对角矩阵D 的伪逆D+ 是其非零元素取倒之后再转置得到的。</p>
<h2 id="8-常见距离"><a href="#8-常见距离" class="headerlink" title="8.常见距离"></a>8.常见距离</h2><p>上面大致说过， 在机器学习里，我们的运算一般都是基于向量的，一条用户具有100个特征，那么他对应的就是一个100维的向量，通过计算两个用户对应向量之间的距离值大小，有时候能反映出这两个用户的相似程度。这在后面的KNN算法和K-means算法中很明显。</p>
<p>设有两个n维变量\(A=\left[ x_{11}, x_{12},…,x_{1n} \right]\)和\(A=\left[ x_{11}, x_{12},…,x_{1n} \right]\)，则一些常用的距离公式定义如下：</p>
<h3 id="曼哈顿距离"><a href="#曼哈顿距离" class="headerlink" title="曼哈顿距离"></a><strong>曼哈顿距离</strong></h3><ul>
<li>曼哈顿距离也称为城市街区距离，数学定义如下：</li>
</ul>
<p>$$<br>d_{12} =\sum_{k=1}^{n}{\left| x_{1k}-x_{2k} \right| }<br>$$</p>
<ul>
<li>曼哈顿距离的Python实现：</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> *</span><br><span class="line">vector1 = mat([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>])</span><br><span class="line">vector2 = mat([<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>])</span><br><span class="line"><span class="keyword">print</span> sum(abs(vector1-vector2))</span><br></pre></td></tr></table></figure>
<h3 id="欧氏距离"><a href="#欧氏距离" class="headerlink" title="欧氏距离"></a><strong>欧氏距离</strong></h3><ul>
<li>欧氏距离其实就是L2范数，数学定义如下：</li>
</ul>
<p>$$d_{12} =\sqrt{\sum_{k=1}^{n}{\left( x_{1k} -x_{2k} \right) ^{2} } }$$</p>
<ul>
<li>欧氏距离的Python实现：</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> *</span><br><span class="line">vector1 = mat([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>])</span><br><span class="line">vector2 = mat([<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>])</span><br><span class="line"><span class="keyword">print</span> sqrt((vector1-vector2)*(vector1-vector2).T)</span><br></pre></td></tr></table></figure>
<h3 id="闵可夫斯基距离"><a href="#闵可夫斯基距离" class="headerlink" title="闵可夫斯基距离"></a><strong>闵可夫斯基距离</strong></h3><ul>
<li>从严格意义上讲，闵可夫斯基距离不是一种距离，而是一组距离的定义：</li>
</ul>
<p>$$d_{12} =\sqrt[p]{\sum_{k=1}^{n}{\left( x_{1k} -x_{2k} \right) ^{p} } } $$</p>
<ul>
<li>实际上，当p=1时，就是曼哈顿距离；当p=2时，就是欧式距离。</li>
</ul>
<h3 id="切比雪夫距离"><a href="#切比雪夫距离" class="headerlink" title="切比雪夫距离"></a><strong>切比雪夫距离</strong></h3><ul>
<li>切比雪夫距离就是\(L_{\varpi}\)<br>即无穷范数，数学表达式如下：</li>
</ul>
<p>$$d_{12} =max\left( \left| x_{1k}-x_{2k} \right| \right)$$</p>
<ul>
<li>切比雪夫距离额Python实现如下：</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> *</span><br><span class="line">vector1 = mat([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>])</span><br><span class="line">vector2 = mat([<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>])</span><br><span class="line"><span class="keyword">print</span> sqrt(abs(vector1-vector2).max)</span><br></pre></td></tr></table></figure>
<h3 id="夹角余弦"><a href="#夹角余弦" class="headerlink" title="夹角余弦"></a><strong>夹角余弦</strong></h3><ul>
<li><p>夹角余弦的取值范围为[-1,1]，可以用来衡量两个向量方向的差异；夹角余弦越大，表示两个向量的夹角越小；当两个向量的方向重合时，夹角余弦取最大值1；当两个向量的方向完全相反时，夹角余弦取最小值-1。</p>
</li>
<li><p>机器学习中用这一概念来衡量样本向量之间的差异，其数学表达式如下：</p>
</li>
</ul>
<p>$$cos\theta =\frac{AB}{\left| A \right| \left|B \right| } =\frac{\sum_{k=1}^{n}{x_{1k}x_{2k} } }{\sqrt{\sum_{k=1}^{n}{x_{1k}^{2} } } \sqrt{\sum_{k=1}^{n}{x_{2k}^{2} } } } $$</p>
<ul>
<li>夹角余弦的Python实现：</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> *</span><br><span class="line">vector1 = mat([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>])</span><br><span class="line">vector2 = mat([<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>])</span><br><span class="line"><span class="keyword">print</span> dot(vector1,vector2)/(linalg.norm(vector1)*linalg.norm(vector2))</span><br></pre></td></tr></table></figure>
<h3 id="汉明距离"><a href="#汉明距离" class="headerlink" title="汉明距离"></a><strong>汉明距离</strong></h3><ul>
<li>汉明距离定义的是两个字符串中不相同位数的数目。<br>例如：字符串‘1111’与‘1001’之间的汉明距离为2。</li>
<li>信息编码中一般应使得编码间的汉明距离尽可能的小。</li>
<li>汉明距离的Python实现：</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> *</span><br><span class="line">matV = mat([<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>],[<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>])</span><br><span class="line">smstr = nonzero(matV[<span class="number">0</span>]-matV[<span class="number">1</span>])</span><br><span class="line"><span class="keyword">print</span> smstr</span><br></pre></td></tr></table></figure>
<h3 id="杰卡德相似系数"><a href="#杰卡德相似系数" class="headerlink" title="杰卡德相似系数"></a><strong>杰卡德相似系数</strong></h3><ul>
<li>两个集合A和B的交集元素在A和B的并集中所占的比例称为两个集合的杰卡德相似系数，用符号J(A,B)表示，数学表达式为：</li>
</ul>
<p>$$J\left( A,B \right) =\frac{\left| A\cap B\right| }{\left|A\cup B \right| } $$</p>
<ul>
<li>杰卡德相似系数是衡量两个集合的相似度的一种指标。一般可以将其用在衡量样本的相似度上。</li>
</ul>
<h3 id="杰卡德距离"><a href="#杰卡德距离" class="headerlink" title="杰卡德距离"></a><strong>杰卡德距离</strong></h3><ul>
<li>与杰卡德相似系数相反的概念是杰卡德距离，其定义式为：</li>
</ul>
<p>$$J_{\sigma} =1-J\left( A,B \right) =\frac{\left| A\cup B \right| -\left| A\cap B \right| }{\left| A\cup B \right| } $$</p>
<ul>
<li>杰卡德距离的Python实现：</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">import</span> scipy.spatial.distance <span class="keyword">as</span> dist</span><br><span class="line">matV = mat([<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>],[<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>])</span><br><span class="line"><span class="keyword">print</span> dist.pdist(matV,<span class="string">'jaccard'</span>)</span><br></pre></td></tr></table></figure>
<hr>
<h1 id="概率论和统计"><a href="#概率论和统计" class="headerlink" title="概率论和统计"></a>概率论和统计</h1><h2 id="1-统计量"><a href="#1-统计量" class="headerlink" title="1.统计量"></a>1.统计量</h2><h3 id="协方差"><a href="#协方差" class="headerlink" title="协方差"></a>协方差</h3><p><img src="http://p4rlzrioq.bkt.clouddn.com/%E5%8D%8F%E6%96%B9%E5%B7%AE.png" alt=""><br><img src="http://p4rlzrioq.bkt.clouddn.com/%E5%8D%8F%E6%96%B9%E5%B7%AE1.png" alt=""><br><img src="http://p4rlzrioq.bkt.clouddn.com/%E5%8D%8F%E6%96%B9%E5%B7%AE2.png" alt=""></p>
<h3 id="Pearson相关系数"><a href="#Pearson相关系数" class="headerlink" title="Pearson相关系数"></a><strong>Pearson相关系数</strong></h3><p><img src="http://p4rlzrioq.bkt.clouddn.com/Pearson%E7%9B%B8%E5%85%B3%E7%B3%BB%E6%95%B0.png" alt=""></p>
<h3 id="协方差矩阵"><a href="#协方差矩阵" class="headerlink" title="协方差矩阵"></a><strong>协方差矩阵</strong></h3><p><img src="http://p4rlzrioq.bkt.clouddn.com/%E5%8D%8F%E6%96%B9%E5%B7%AE%E7%9F%A9%E9%98%B5.png" alt=""></p>
<h2 id="2-独立与不相关"><a href="#2-独立与不相关" class="headerlink" title="2.独立与不相关"></a>2.<strong>独立与不相关</strong></h2><p><img src="http://p4rlzrioq.bkt.clouddn.com/%E7%8B%AC%E7%AB%8B%E4%B8%8E%E4%B8%8D%E7%9B%B8%E5%85%B3.png" alt=""> </p>
<h2 id="3-贝叶斯公式"><a href="#3-贝叶斯公式" class="headerlink" title="3.贝叶斯公式"></a>3.<strong>贝叶斯公式</strong></h2><p>先看看什么是“先验概率”和“后验概率”，以一个例子来说明：</p>
<p>假设某种病在人群中的发病率是0.001，即1000人中大概会有1个人得病，则有： <strong>P(患病) = 0.1%</strong>；即：在没有做检验之前，我们预计的患病率为<strong>P(患病)=0.1%</strong>，这个就叫作<strong>“先验概率”</strong>。</p>
<p>再假设现在有一种该病的检测方法，其检测的准确率为<strong>95%</strong>；即：如果真的得了这种病，该检测法有<strong>95%</strong>的概率会检测出阳性，但也有<strong>5%</strong>的概率检测出阴性；或者反过来说，但如果没有得病，采用该方法有<strong>95%</strong>的概率检测出阴性，但也有<strong>5%</strong>的概率检测为阳性。用概率条件概率表示即为：<strong>P(显示阳性|患病)=95%</strong></p>
<p>现在我们想知道的是：在做完检测显示为阳性后，某人的患病率<strong>P(患病|显示阳性)</strong>，这个其实就称为<strong>“后验概率”。</strong></p>
<p>而这个叫贝叶斯的人其实就是为我们提供了一种可以<strong>利用先验概率计算后验概率</strong>的方法，我们将其称为<strong>“贝叶斯公式”。</strong></p>
<p>这里先了解<strong>条件概率公式</strong>：</p>
<p>$$P\left( B|A \right)=\frac{P\left( AB \right)}{P\left( A \right)} , P\left( A|B \right)=\frac{P\left( AB \right)}{P\left( B \right)}$$</p>
<p>由条件概率可以得到<strong>乘法公式</strong>：</p>
<p>$$P\left( AB \right)=P\left( B|A \right)P\left( A \right)=P\left( A|B \right)P\left( B \right)$$<br>将条件概率公式和乘法公式结合可以得到：</p>
<p>$$P\left( B|A \right)=\frac{P\left( A|B \right)\cdot P\left( B \right)}{P\left( A \right)}$$</p>
<p>再由<strong>全概率公式</strong>：</p>
<p>$$P\left( A \right)=\sum_{i=1}^{N}{P\left( A|B_{i} \right) \cdot P\left( B_{i}\right)} $$</p>
<p>代入可以得到<strong>贝叶斯公式</strong>：</p>
<p>$$P\left( B_{i}|A \right)=\frac{P\left( A|B_{i} \right)\cdot P\left( B_{i} \right)}{\sum_{i=1}^{N}{P\left( A|B_{i} \right) \cdot P\left( B_{i}\right)} }$$</p>
<h2 id="4-常见分布函数"><a href="#4-常见分布函数" class="headerlink" title="4.常见分布函数"></a>4.<strong>常见分布函数</strong></h2><h3 id="0-1分布"><a href="#0-1分布" class="headerlink" title="0-1分布"></a><strong>0-1分布</strong></h3><p>0-1分布是单个二值型离散随机变量的分布，其概率分布函数为：</p>
<p>$$P\left( X=1 \right) =p$$<br>$$P\left( X=0 \right) =1-p$$</p>
<h3 id="几何分布"><a href="#几何分布" class="headerlink" title="几何分布"></a><strong>几何分布</strong></h3><p>几何分布是离散型概率分布，其定义为：在n次伯努利试验中，试验k次才得到第一次成功的机率。即：前k-1次皆失败，第k次成功的概率。其概率分布函数为：</p>
<p>$$P\left( X=k \right) =\left( 1-p \right) ^{k-1} p$$</p>
<p>性质：<br>\(E\left( X \right) =\frac{1}{p}\)<br>\(Var\left( X \right) =\frac{1-p}{p^{2} }\)</p>
<h3 id="二项分布"><a href="#二项分布" class="headerlink" title="二项分布"></a><strong>二项分布</strong></h3><p>二项分布即重复n次伯努利试验，各次试验之间都相互独立，并且每次试验中只有两种可能的结果，而且这两种结果发生与否相互对立。如果每次试验时，事件发生的概率为p，不发生的概率为1-p，则n次重复独立试验中发生k次的概率为：</p>
<p>$$P\left( X=k \right) =C_{n}^{k} p^{k} \left( 1-p \right) ^{n-k}$$</p>
<p>性质：<br>\(E\left( X \right) =np\)<br>\(Var\left( X \right) =np\left( 1-p \right)\)</p>
<h3 id="高斯分布"><a href="#高斯分布" class="headerlink" title="高斯分布"></a><strong>高斯分布</strong></h3><p>高斯分布又叫正态分布，其曲线呈钟型，两头低，中间高，左右对称因其曲线呈钟形，如下图所示：<br><img src="http://p4rlzrioq.bkt.clouddn.com/488px-Normal_Distribution_PDF.svg.png" alt=""></p>
<p><img src="http://p4rlzrioq.bkt.clouddn.com/%E6%AD%A3%E6%80%81%E5%88%86%E5%B8%83.png" alt=""></p>
<p>若随机变量X服从一个数学期望为\(\mu\)，方差为\(\sigma ^{2}\)的正态分布，则我们将其记为：\(N\left( \mu ,\sigma^{2} \right)\)决定了正态分布的位置，其标准差\(\sigma\)（方差的开方）决定了正态分布的幅度。</p>
<h3 id="指数分布"><a href="#指数分布" class="headerlink" title="指数分布"></a><strong>指数分布</strong></h3><p>指数分布是事件的时间间隔的概率，它的一个重要特征是无记忆性。例如：如果某一元件的寿命的寿命为T，已知元件使用了t小时，它总共使用至少t+s小时的条件概率，与从开始使用时算起它使用至少s小时的概率相等。下面这些都属于指数分布：</p>
<ul>
<li>婴儿出生的时间间隔</li>
<li>网站访问的时间间隔</li>
<li>奶粉销售的时间间隔</li>
</ul>
<p>指数分布的公式可以从泊松分布推断出来。如果下一个婴儿要间隔时间t，就等同于t之内没有任何婴儿出生，即：</p>
<p>$$P\left( X\geq t \right) =P\left( N\left( t \right) =0 \right) =\frac{\left( \lambda t \right) ^{0}\cdot e^{-\lambda t} }{0!}=e^{-\lambda t} $$<br>则：</p>
<p>$$P\left( X\leq t \right) =1-P\left( X\geq t \right) =1-e^{-\lambda t}$$<br>如：接下来15分钟，会有婴儿出生的概率为：</p>
<p>$$P\left( X\leq \frac{1}{4} \right) =1-e^{-3\cdot \frac{1}{4} } \approx 0.53$$</p>
<p><img src="http://p4rlzrioq.bkt.clouddn.com/%E6%8C%87%E6%95%B0%E5%88%86%E5%B8%83.jpg" alt=""></p>
<h3 id="泊松分布"><a href="#泊松分布" class="headerlink" title="泊松分布"></a><strong>泊松分布</strong></h3><p>日常生活中，大量事件是有固定频率的，比如：</p>
<ul>
<li>某医院平均每小时出生3个婴儿</li>
<li>某网站平均每分钟有2次访问</li>
<li>某超市平均每小时销售4包奶粉</li>
</ul>
<p>它们的特点就是，我们可以预估这些事件的总数，但是没法知道具体的发生时间。已知平均每小时出生3个婴儿，请问下一个小时，会出生几个？有可能一下子出生6个，也有可能一个都不出生，这是我们没法知道的。</p>
<p><strong>泊松分布就是描述某段时间内，事件具体的发生概率。</strong>其概率函数为：</p>
<p>$$P\left( N\left( t \right) =n \right) =\frac{\left( \lambda t \right) ^{n}e^{-\lambda t} }{n!} $$<br>其中：</p>
<p>P表示概率，N表示某种函数关系，t表示时间，n表示数量，1小时内出生3个婴儿的概率，就表示为 P(N(1) = 3) ；λ 表示事件的频率。</p>
<p>还是以上面医院平均每小时出生3个婴儿为例，则\(\lambda =3\)；</p>
<p>那么，接下来两个小时，一个婴儿都不出生的概率可以求得为：</p>
<p>$$P\left( N\left(2 \right) =0 \right) =\frac{\left( 3\cdot 2 \right) ^{o} \cdot e^{-3\cdot 2} }{0!} \approx 0.0025$$<br>同理，我们可以求接下来一个小时，至少出生两个婴儿的概率：</p>
<p>$$P\left( N\left( 1 \right) \geq 2 \right) =1-P\left( N\left( 1 \right)=0 \right) - P\left( N\left( 1 \right)=1 \right)\approx 0.8$$</p>
<h2 id="5-常见的分布总结"><a href="#5-常见的分布总结" class="headerlink" title="5.常见的分布总结"></a>5.常见的分布总结</h2><p><img src="http://p4rlzrioq.bkt.clouddn.com/%E5%B8%B8%E8%A7%81%E5%88%86%E5%B8%83.jpg" alt="常见分布"></p>
<h2 id="6-极大似然估计"><a href="#6-极大似然估计" class="headerlink" title="6.极大似然估计"></a>6.极大似然估计</h2><p>极大似然估计是建立在这样的思想上：已知某个参数能使这个样本出现的概率最大，我们当然不会再去选择其他小概率的样本，所以干脆就把这个参数作为估计的真实值。</p>
<p>求极大似然函数估计值的一般步骤：</p>
<p>（1） 写出似然函数，即每个随机实验出现概率相乘，为这个抽样出现的概率。<br>（2） 对似然函数取对数，为了方便求导；<br>（3） 对参数求导数。<br>（4） 令导数=0，即求解极值，由实际情况知，该极值为极大值。解似然方程。</p>
<hr>
<h1 id="微积分"><a href="#微积分" class="headerlink" title="微积分"></a>微积分</h1><h2 id="1-导数与梯度"><a href="#1-导数与梯度" class="headerlink" title="1.导数与梯度"></a>1.导数与梯度</h2><ul>
<li><strong>导数</strong>：一个一元函数函数在某一点的导数描述了这个函数在这一点附近的变化率。</li>
<li><strong>梯度</strong>:多元函数的导数就是梯度。<ul>
<li>一阶导数，即梯度（gradient）</li>
<li>二阶导数，Hessian矩阵</li>
</ul>
</li>
</ul>
<h2 id="2-泰勒展开"><a href="#2-泰勒展开" class="headerlink" title="2.泰勒展开"></a>2.<strong>泰勒展开</strong></h2><ul>
<li>一元函数的泰勒展开：<br><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/d0070da6cb78cda75d9ff9521f85702c97862673" alt="link"></li>
<li>基尼指数的图像、熵、分类误差率三者之间的关系。<br><img src="http://p4rlzrioq.bkt.clouddn.com/%E6%B3%B0%E5%8B%92%E5%B1%95%E5%BC%80.jpg" alt="link"></li>
</ul>
<h2 id="3-Lagrange乘子法"><a href="#3-Lagrange乘子法" class="headerlink" title="3.Lagrange乘子法"></a>3.<strong>Lagrange乘子法</strong></h2><p>对于一般的求极值问题我们都知道，求导等于0就可以了。但是如果我们不但要求极值，还要求一个满足一定约束条件的极值，那么此时就可以构造Lagrange函数，其实就是<strong>把约束项添加到原函数上，然后对构造的新函数求导</strong>。</p>
<p>对于一个要求极值的函数\(f\left( x,y \right)\)，图上的蓝圈就是这个函数的等高图，就是说 \(f\left( x,y \right) =c_{1} ,c_{2} ,…,c_{n}\)分别代表不同的数值(每个值代表一圈，等高图)，我要找到一组\(\left( x,y \right)\)，使它的\(c_{i}\)值越大越好，但是这点必须满足约束条件\(g\left( x,y \right)\)（在黄线上）。</p>
<p><img src="http://p4rlzrioq.bkt.clouddn.com/gini%E7%86%B5.png" alt=""></p>
<p>也就是说\(f(x,y)\)相切，或者说它们的梯度▽ \({f}\)和▽\({g}\)平行，因此它们的梯度（偏导）成倍数关系；那我么就假设为\(\lambda\)倍，然后把约束条件加到原函数后再对它求导，其实就等于满足了下图上的式子。</p>
<p>在<strong>支持向量机模型（SVM）</strong>的推导中一步很关键的就是利用拉格朗日对偶性将原问题转化为对偶问题。</p>
<hr>
<h1 id="信息论"><a href="#信息论" class="headerlink" title="信息论"></a>信息论</h1><h2 id="1-熵"><a href="#1-熵" class="headerlink" title="1.熵"></a>1.<strong>熵</strong></h2><p>如果一个随机变量X概率分布为\(P\left( X=x_{i} \right) =p_{i} ,i=1,2,…..,n\)，则随机变量X的熵定义为<strong>H(X)</strong>：</p>
<p>$$H\left( X \right) =-\sum_{i=1}^{n}{P\left( x_{i} \right) logP\left( x_{i} \right) } =\sum_{i=1}^{n}{P\left( x_{i} \right) \frac{1}{logP\left( x_{i} \right) } } $$</p>
<h3 id="联合熵"><a href="#联合熵" class="headerlink" title="联合熵"></a><strong>联合熵</strong></h3><p>两个随机变量X和Y的联合分布可以形成联合熵，定义为联合自信息的数学期望，它是二维随机变量XY的不确定性的度量，用<strong>H(X,Y)</strong>表示：</p>
<p>$$H\left( X,Y \right) =-\sum_{i=1}^{n}{\sum_{j=1}^{n}{P\left( x_{i} ,y_{j} \right)} logP\left( x_{i},y_{j} \right) } $$</p>
<h3 id="条件熵"><a href="#条件熵" class="headerlink" title="条件熵"></a><strong>条件熵</strong></h3><p>在随机变量X发生的前提下，随机变量Y发生新带来的熵，定义为Y的条件熵，用<strong>H(Y|X)</strong>表示：</p>
<p>$$H\left(Y|X \right) =-\sum_{x,y}^{}{P\left( x,y \right) logP\left( y|x \right) } $$<br>条件熵用来衡量在已知随机变量X的条件下，随机变量Y的不确定性。</p>
<p>实际上，熵、联合熵和条件熵之间存在以下关系：</p>
<p>$$H\left( Y|X \right) =H\left( X,Y\right) -H\left( X \right)$$<br>推导过程如下：</p>
<p><img src="http://p4rlzrioq.bkt.clouddn.com/%E6%9D%A1%E4%BB%B6%E7%86%B5.jpg" alt=""></p>
<p>其中：</p>
<ul>
<li>第二行推到第三行的依据是边缘分布P(x)等于联合分布P(x,y)的和；</li>
<li>第三行推到第四行的依据是把公因子logP(x)乘进去，然后把x,y写在一起；</li>
<li>第四行推到第五行的依据是：因为两个sigma都有P(x,y)，故提取公因子P(x,y)放到外边，然后把里边的-（log P(x,y) - log P(x)）写成- log (P(x,y) / P(x) ) ；</li>
<li>第五行推到第六行的依据是：P(x,y) = P(x) * P(y|x)，故P(x,y) / P(x) = P(y|x)。</li>
</ul>
<p>相对熵又称互熵、交叉熵、KL散度、信息增益，是描述两个概率分布P和Q差异的一种方法，记为<strong>D(P||Q)</strong>。在信息论中，D(P||Q)表示当用概率分布Q来拟合真实分布P时，产生的信息损耗，其中P表示真实分布，Q表示P的拟合分布。</p>
<p>对于一个离散随机变量的两个概率分布P和Q来说，它们的相对熵定义为：</p>
<p>$$D\left( P||Q \right) =\sum_{i=1}^{n}{P\left( x_{i} \right) log\frac{P\left( x_{i} \right) }{Q\left( x_{i} \right) } } $$<br>注意：D(P||Q) ≠ D(Q||P)</p>
<p>相对熵又称<strong>KL散度( Kullback–Leibler divergence)</strong>，KL散度也是一个机器学习中常考的概念。</p>
<h3 id="互信息"><a href="#互信息" class="headerlink" title="互信息"></a><strong>互信息</strong></h3><p>两个随机变量X，Y的互信息定义为X，Y的联合分布和各自独立分布乘积的相对熵称为互信息，用<strong>I(X,Y)</strong>表示。互信息是信息论里一种有用的信息度量方式，它可以看成是一个随机变量中包含的关于另一个随机变量的信息量，或者说是一个随机变量由于已知另一个随机变量而减少的不肯定性。</p>
<p>$$I\left( X,Y \right) =\sum_{x\in X}^{}{\sum_{y\in Y}^{}{P\left( x,y \right) } log\frac{P\left( x,y \right) }{P\left( x \right) P\left( y \right) } } $$</p>
<p>互信息、熵和条件熵之间存在以下关系：$$H\left( Y|X \right) =H\left( Y \right) -I\left( X,Y \right) $$<br>推导过程如下：</p>
<p><img src="http://p4rlzrioq.bkt.clouddn.com/%E4%BA%92%E4%BF%A1%E6%81%AF.jpg" alt=""></p>
<p>通过上面的计算过程发现有：<strong>H(Y|X) = H(Y) - I(X,Y)</strong>，又由前面条件熵的定义有：<strong>H(Y|X) = H(X,Y) - H(X)</strong>，于是有<strong>I(X,Y)= H(X) + H(Y) - H(X,Y)</strong>，此结论被多数文献作为<strong>互信息的定义</strong>。</p>
<h3 id="最大熵模型"><a href="#最大熵模型" class="headerlink" title="最大熵模型"></a><strong>最大熵模型</strong></h3><p>最大熵原理是概率模型学习的一个准则，它认为：学习概率模型时，在所有可能的概率分布中，熵最大的模型是最好的模型。通常用约束条件来确定模型的集合，所以，<strong>最大熵模型原理也可以表述为：在满足约束条件的模型集合中选取熵最大的模型。</strong></p>
<p>前面我们知道，若随机变量X的概率分布是\(P\left( x_{i} \right)\)，则其熵定义如下：</p>
<p>$$H\left( X \right) =-\sum_{i=1}^{n}{P\left( x_{i} \right) logP\left( x_{i} \right) } =\sum_{i=1}^{n}{P\left( x_{i} \right) \frac{1}{logP\left( x_{i} \right) } }$$</p>
<h3 id="熵满足下列不等式："><a href="#熵满足下列不等式：" class="headerlink" title="熵满足下列不等式："></a><strong>熵满足下列不等式</strong>：</h3><p>$$0\leq H\left( X \right) \leq log\left| X \right| $$<br>式中，<strong>|X|是X的取值个数</strong>，<strong>当且仅当X的分布是均匀分布时右边的等号成立</strong>。<strong>也就是说，当X服从均匀分布时，熵最大。</strong></p>
<p>直观地看，最大熵原理认为：要选择概率模型，首先必须满足已有的事实，即约束条件；在没有更多信息的情况下，那些不确定的部分都是“等可能的”。<strong>最大熵原理通过熵的最大化来表示等可能性；“等可能”不易操作，而熵则是一个可优化的指标。</strong></p>
<h2 id="2-上溢和下溢"><a href="#2-上溢和下溢" class="headerlink" title="2.上溢和下溢"></a>2.<strong>上溢和下溢</strong></h2><p>在数字计算机上实现连续数学的基本困难是：我们需要通过有限数量的位模式来表示无限多的实数，这意味着我们在计算机中表示实数时几乎都会引入一些近似误差。在许多情况下，这仅仅是舍入误差。如果在理论上可行的算法没有被设计为最小化舍入误差的累积，可能会在实践中失效，因此舍入误差是有问题的，特别是在某些操作复合时。</p>
<p>一种特别毁灭性的舍入误差是<strong>下溢</strong>。当接近零的数被四舍五入为零时发生下溢。许多函数会在其参数为零而不是一个很小的正数时才会表现出质的不同。例如，我们通常要避免被零除<strong>。</strong></p>
<p>另一个极具破坏力的数值错误形式是<strong>上溢(overflow)</strong>。当大量级的数被近似为\(\varpi\)时发生上溢。进一步的运算通常将这些无限值变为非数字。</p>
<p>必须对上溢和下溢进行数值稳定的一个例子是<strong>softmax 函数</strong>。softmax 函数经常用于预测与multinoulli分布相关联的概率，定义为：</p>
<p><img src="http://p4rlzrioq.bkt.clouddn.com/%E4%B8%8A%E6%BA%A2%E5%92%8C%E4%B8%8B%E6%BA%A2.jpg" alt=""></p>
<p>softmax 函数在多分类问题中非常常见。这个函数的作用就是使得在负无穷到0的区间趋向于0，在0到正无穷的区间趋向于1。上面表达式其实是多分类问题中计算某个样本 \(x_{i}\) 的类别标签 \(y_{i}\)属于K个类别的概率，最后判别 \(y_{i}\)所属类别时就是将其归为对应概率最大的那一个。</p>
<p>当式中的\(w_{k} x_{i} +b\)都是很小的负数时，\(e^{w_{k} x_{i} +b }\)就会发生下溢，这意味着上面函数的分母会变成0，导致结果是未定的；同理，当式中的\(x_{w_{k} x_{i} +b}\)是很大的正数时，\(e^{w_{k} x_{i} +b }\)就会发生上溢导致结果是未定的。</p>
<hr>
<h1 id="凸优化"><a href="#凸优化" class="headerlink" title="凸优化"></a><strong>凸优化</strong></h1><h2 id="1-凸集-Convex-Sets"><a href="#1-凸集-Convex-Sets" class="headerlink" title="1.凸集(Convex Sets)"></a>1.凸集(Convex Sets)</h2><p>集合C是凸的，如果对于所有的\(x,y\in C\)和\(\theta\in\mathbb{R},0\leq\theta\leq 1\)有：<br>$$\theta x+(1-\theta)y\in C$$<br>可以这样理解：在集合C中任选两点，在这两点的连线上的所有点都属于集合C。<br><img src="http://p4rlzrioq.bkt.clouddn.com/%E5%87%B8%E9%9B%86.jpg" alt=""></p>
<h2 id="2-凸函数-Convex-Fuctions"><a href="#2-凸函数-Convex-Fuctions" class="headerlink" title="2.凸函数(Convex Fuctions)"></a>2.凸函数(Convex Fuctions)</h2><p>如果函数的定义域\({\cal D}(f)\)是一个凸集，并且对于所有的\(x,y\in {\cal D}(f)\)和\(\theta\in\mathbb{R},0\leq\theta\leq1\)，都有：<br>\(f(\theta x+(1-\theta)y)\leq\theta f(x)+(1-\theta)f(y)\)<br><img src="http://oddpnmpll.bkt.clouddn.com/2016-10-05-01%3A23%3A27.jpg" alt=""></p>
<h3 id="凸函数的一阶条件"><a href="#凸函数的一阶条件" class="headerlink" title="凸函数的一阶条件"></a>凸函数的一阶条件</h3><p><img src="http://p4rlzrioq.bkt.clouddn.com/%E5%87%B8%E5%87%BD%E6%95%B0%E7%9A%84%E4%B8%80%E9%98%B6%E6%9D%A1%E4%BB%B6.png" alt=""><br>直观上可以这样理解，在函数上随便挑一个点，该点的切线必然在函数的下方<br><img src="http://oddpnmpll.bkt.clouddn.com/2016-10-05-01%3A27%3A53.jpg" alt=""></p>
<h3 id="凸性质的二阶条件"><a href="#凸性质的二阶条件" class="headerlink" title="凸性质的二阶条件"></a>凸性质的二阶条件</h3><p><img src="http://p4rlzrioq.bkt.clouddn.com/%E5%87%B8%E5%87%BD%E6%95%B0%E7%9A%84%E4%BA%8C%E9%98%B6%E6%9D%A1%E4%BB%B6.png" alt=""></p>
<h3 id="琴生不等式-Jensen’s-Inequality"><a href="#琴生不等式-Jensen’s-Inequality" class="headerlink" title="琴生不等式(Jensen’s Inequality)"></a>琴生不等式(Jensen’s Inequality)</h3><p>假设凸函数的基本定义为:<br>\(f(\theta x+(1-\theta)y)\leq\theta f(x)+(1-\theta)f(y)\ \ \ \text{for} \ \ \ 0\leq\theta\leq1\)<br>上述等式可以扩展到多个点:<br>\(f\left(\sum_{i=1}^k\theta_ix_i\right)\leq\sum_{i=1}^k\theta_if(x_i)\ \ \ \text{for}\ \ \ \sum_{i=1}^k\theta_i=1,\theta_i\geq0 \ \ \forall i\)<br>再将上述等式扩展到积分形式:<br>\(f\left(\int p(x)xdx\right)\leq\int p(x)f(x)dx\ \ \ \text{for}\ \ \ \int p(x)dx=1,p(x)\leq0\ \ \forall x\)<br>由于\(p(x)\)积分为1，我们可以把\(p(x)\)看作是一个概率密度函数，所以尚属等式可以用以下形式表达：<br>\(f(\mathbb{E}[x])\leq\mathbb{E}[f(x)]\)<br>最后一条等式就是著名的<strong>琴生不等式</strong>。</p>
<h2 id="3-凸优化问题-Convex-Optimization-Problems"><a href="#3-凸优化问题-Convex-Optimization-Problems" class="headerlink" title="3.凸优化问题(Convex Optimization Problems)"></a>3.凸优化问题(Convex Optimization Problems)</h2><p>在凸优化问题中，一个最关键的点就是<strong>对于一个凸优化问题，所有的局部最优解(locally optimal)都是全局最优解(globally optimal)</strong>。<br>最优化的基本数学模型如下：</p>
<p><img src="http://p4rlzrioq.bkt.clouddn.com/%E5%87%B8%E4%BC%98%E5%8C%96%E9%97%AE%E9%A2%98.jpg" alt=""><br>它有三个基本要素，即：</p>
<ul>
<li>设计变量：x是一个实数域范围内的n维向量，被称为决策变量或问题的解；</li>
<li>目标函数：f(x)为目标函数；</li>
<li>约束条件：\(h_{i} \left( x \right) =0\)称为等式约束，\(g_{i} \left( x \right) \leq 0\)为不等式约束，\(i=0,1,2,……\)</li>
</ul>
<h2 id="4-牛顿法"><a href="#4-牛顿法" class="headerlink" title="4.牛顿法"></a>4.牛顿法</h2><h3 id="牛顿法介绍"><a href="#牛顿法介绍" class="headerlink" title="牛顿法介绍"></a><strong>牛顿法介绍</strong></h3><p><strong>牛顿法</strong>也是求解<strong>无约束最优化</strong>问题常用的方法，<strong>最大的优点是收敛速度快</strong>。</p>
<p>从本质上去看，<strong>牛顿法是二阶收敛，梯度下降是一阶收敛，所以牛顿法就更快</strong>。<strong>通俗地说</strong>，比如你想找一条最短的路径走到一个盆地的最底部，梯度下降法 每次只从你当前所处位置选一个坡度最大的方向走一步，牛顿法在选择方向时，不仅会考虑坡度是否够大，还会考虑你走了一步之后，坡度是否会变得更大。所以， 可以说牛顿法比梯度下降法看得更远一点，能更快地走到最底部。</p>
<p><img src="http://p4rlzrioq.bkt.clouddn.com/%E7%89%9B%E9%A1%BF%E6%B3%95.jpg" alt=""></p>
<p>或者从几何上说，<strong>牛顿法就是用一个二次曲面去拟合你当前所处位置的局部曲面，而梯度下降法是用一个平面去拟合当前的局部曲面</strong>，通常情况下，二次曲面的拟合会比平面更好，所以牛顿法选择的下降路径会更符合真实的最优下降路径。</p>
<h3 id="牛顿法的推导"><a href="#牛顿法的推导" class="headerlink" title="牛顿法的推导"></a><strong>牛顿法的推导</strong></h3><p>将目标函数\(f\left( x \right)\) 在\(x_{k}\)处进行二阶泰勒展开，可得：</p>
<p>$$f\left( x \right) =f\left( x_{k} \right) +f^{‘} \left( x_{k} \right) \left( x-x_{k} \right) +\frac{1}{2} f^{‘’}\left( x_{k} \right) \left( x-x_{k} \right) ^{2}$$<br>因为目标函数\(f\left( x \right)\)有极值的必要条件是在极值点处一阶导数为0，即：\(f^{‘} \left( x \right) =0\)</p>
<p>所以对上面的展开式两边同时求导（注意\({x}\)才是变量，\(x_{k}\)是常量\(\Rightarrow f^{‘} \left( x_{k} \right) ,f^{‘’} \left( x_{k} \right)\)都是常量），并令\(f^{‘} \left( x \right) =0\)可得：</p>
<p>$$f^{‘} \left( x_{k} \right) +f^{‘’} \left( x_{k} \right) \left( x-x_{k} \right) =0$$<br>即：</p>
<p>$$x=x_{k} -\frac{f^{‘} \left( x_{k} \right) }{f^{‘’} \left( x_{k} \right) } $$</p>
<p>于是可以构造如下的迭代公式：</p>
<p>$$x_{k+1} =x_{k} -\frac{f^{‘} \left( x_{k} \right) }{f^{‘’} \left( x_{k} \right) }$$</p>
<p>这样，我们就可以利用该迭代式依次产生的序列逐渐逼近\(f\left( x \right)\)的极小值点了。</p>
<p>牛顿法的迭代示意图如下：</p>
<p><img src="http://p4rlzrioq.bkt.clouddn.com/%E7%89%9B%E9%A1%BF%E6%B3%95%E7%9A%84%E8%BF%AD%E4%BB%A3%E7%A4%BA%E6%84%8F%E5%9B%BE%E5%A6%82%E4%B8%8B.jpg" alt=""></p>
<p>上面讨论的是2维情况，<strong>高维情况</strong>的牛顿迭代公式是：</p>
<p><img src="http://p4rlzrioq.bkt.clouddn.com/%E9%AB%98%E7%BB%B4%E6%83%85%E5%86%B5%E7%9A%84%E7%89%9B%E9%A1%BF%E8%BF%AD%E4%BB%A3%E5%85%AC%E5%BC%8F.jpg" alt=""></p>
<p>式中， ▽\({f}\)是\(f\left( x \right)\)的梯度，即：</p>
<p><img src="http://p4rlzrioq.bkt.clouddn.com/%E7%89%9B%E9%A1%BF%E6%B3%953.jpg" alt=""></p>
<p>H是Hessen矩阵，即：</p>
<p><img src="http://p4rlzrioq.bkt.clouddn.com/Hessen%E7%9F%A9%E9%98%B5.jpg" alt=""></p>
<h3 id="牛顿法的过程"><a href="#牛顿法的过程" class="headerlink" title="牛顿法的过程"></a><strong>牛顿法的过程</strong></h3><ul>
<li>1、给定初值\(x_{0} ]\)和精度阈值\(\varepsilon\)，并令\(k=0\)；</li>
<li>2、计算\(x_{k}\)和\(H_{k}\)；</li>
<li>3、若\(\left| \left| g_{k} \right| \right| &lt;\varepsilon\)则停止迭代；否则确定搜索方向：\(d_{k} =-H_{k}^{-1} \cdot g_{k}\)；</li>
<li>4、计算新的迭代点：\(x_{k+1} =x_{k} +d_{k}\)；</li>
<li>5、令\(k=k+1\)，转至2。</li>
</ul>
<h2 id="5-阻尼牛顿法"><a href="#5-阻尼牛顿法" class="headerlink" title="5.阻尼牛顿法"></a>5.<strong>阻尼牛顿法</strong></h2><h3 id="引入"><a href="#引入" class="headerlink" title="引入"></a><strong>引入</strong></h3><p>注意到，牛顿法的迭代公式中没有步长因子，是定步长迭代。对于非二次型目标函数，有时候会出现\(f\left( x_{k+1} \right) &gt;f\left( x_{k} \right)\)的情况，这表明，原始牛顿法不能保证函数值稳定的下降。在严重的情况下甚至会造成序列发散而导致计算失败。</p>
<p>为消除这一弊病，人们又提出阻尼牛顿法。阻尼牛顿法每次迭代的方向仍然是\(x_{k}\)，但每次迭代会沿此方向做一维搜索，寻求最优的步长因子\(\lambda _{k}\)，即：</p>
<p>\(\lambda <em>{k} = minf\left( x</em>{k} +\lambda d_{k} \right)\)</p>
<h3 id="算法过程"><a href="#算法过程" class="headerlink" title="算法过程"></a><strong>算法过程</strong></h3><ul>
<li>1、给定初值\(x_{0}\)和精度阈值\(\varepsilon\)，并令\(k=0\)；</li>
<li>2、计算\(g_{k}\)（\(f\left( x \right)\)在\(x_{k}\)处的梯度值）和\(H_{k}\)；</li>
<li>3、若\(\left| \left| g_{k} \right| \right| &lt;\varepsilon\)则停止迭代；否则确定搜索方向：\(d_{k} =-H_{k}^{-1} \cdot g_{k}\)；</li>
<li>4、利用\(d_{k} =-H_{k}^{-1} \cdot g_{k}\)得到步长\(\lambda <em>{k}\)，并令\(x</em>{k+1} =x_{k} +\lambda <em>{k} d</em>{k}\)</li>
<li>5、令\(k=k+1\)，转至2。</li>
</ul>
<h2 id="6-拟牛顿法"><a href="#6-拟牛顿法" class="headerlink" title="6.拟牛顿法"></a>6.<strong>拟牛顿法</strong></h2><h3 id="概述"><a href="#概述" class="headerlink" title="概述"></a><strong>概述</strong></h3><p>由于<strong>牛顿法</strong>每一步都要求解目标函数的<strong>Hessen矩阵的逆矩阵</strong>，<strong>计算量比较大</strong>（求矩阵的逆运算量比较大），因此提出一种<strong>改进方法</strong>，即<strong>通过正定矩阵近似代替Hessen矩阵的逆矩阵，简化这一计算过程</strong>，改进后的方法称为<strong>拟牛顿法</strong>。</p>
<h3 id="拟牛顿法的推导"><a href="#拟牛顿法的推导" class="headerlink" title="拟牛顿法的推导"></a><strong>拟牛顿法的推导</strong></h3><p>先将目标函数在\(x_{k+1}\)处展开，得到：</p>
<p>$$f\left( x \right) =f\left( x_{k+1} \right) +f^{‘} \left( x_{k+1} \right) \left( x-x_{k+1} \right) +\frac{1}{2} f^{‘’}\left( x_{k+1} \right) \left( x-x_{k+1} \right) ^{2}$$<br>两边同时取梯度，得：</p>
<p>$$f^{‘}\left( x \right) = f^{‘} \left( x_{k+1} \right) +f^{‘’} \left( x_{k+1} \right) \left( x-x_{k+1} \right)$$</p>
<p>取上式中的\(x=x_{k}\)，得：</p>
<p>$$f^{‘}\left( x_{k} \right) = f^{‘} \left( x_{k+1} \right) +f^{‘’} \left( x_{k+1} \right) \left( x-x_{k+1} \right)$$</p>
<p>即：</p>
<p>$$g_{k+1} -g_{k} =H_{k+1} \cdot \left( x_{k+1} -x_{k} \right)$$<br>可得：</p>
<p>$$H_{k}^{-1} \cdot \left( g_{k+1} -g_{k} \right) =x_{k+1} -x_{k}$$</p>
<p>上面这个式子称为<strong>“拟牛顿条件”</strong>，由它来对Hessen矩阵做约束。</p>
<hr>
<h1 id="计算复杂性与NP问题"><a href="#计算复杂性与NP问题" class="headerlink" title="计算复杂性与NP问题"></a><strong>计算复杂性与NP问题</strong></h1><h2 id="1、算法复杂性"><a href="#1、算法复杂性" class="headerlink" title="1、算法复杂性"></a><strong>1、算法复杂性</strong></h2><p>现实中大多数问题都是离散的数据集，为了反映统计规律，有时数据量很大，而且多数目标函数都不能简单地求得解析解。这就带来一个问题：<strong>算法的复杂性</strong>。</p>
<p>算法理论被认为是解决各类现实问题的方法论。衡量算法有两个重要的指标：<strong>时间复杂度和空间复杂度</strong>，这是对算法执行所需要的两类资源——时间和空间的估算。</p>
<p>一般，衡量问题是否可解的重要指标是：该问题能否在<strong>多项式时间</strong>内求解，还是只能在<strong>指数时间</strong>内求解？在各类算法理论中，通常使用多项式时间算法即可解决的问题看作是易解问题，需要指数时间算法解决的问题看作是难解问题。</p>
<p>指数时间算法的计算时间随着问题规模的增长而呈指数化上升，这类问题虽然有解，但并不适用于大规模问题。所以当前算法研究的一个重要任务就是将指数时间算法变换为多项式时间算法。</p>
<h2 id="2、确定性和非确定性"><a href="#2、确定性和非确定性" class="headerlink" title="2、确定性和非确定性"></a><strong>2、确定性和非确定性</strong></h2><p>除了问题规模与运算时间的比较，衡量一个算法还需要考虑确定性和非确定性的概念。</p>
<p>这里先介绍一下<strong>“自动机”</strong>的概念。自动机实际上是指一种基于状态变化进行迭代的算法。在算法领域常把这类算法看作一个机器，比较知名的有<strong>图灵机、玻尔兹曼机、支持向量机</strong>等。</p>
<p>所谓确定性，是指针对各种自动机模型，根据当时的状态和输入，若自动机的状态转移是唯一确定的，则称<strong>确定性</strong>；若在某一时刻自动机有多个状态可供选择，并尝试执行每个可选择的状态，则称为<strong>非确定性</strong>。</p>
<p>换个说法就是：确定性是程序每次运行时产生下一步的结果是唯一的，因此返回的结果也是唯一的；非确定性是程序在每个运行时执行的路径是并行且随机的，所有路径都可能返回结果，也可能只有部分返回结果，也可能不返回结果，但是只要有一个路径返回结果，那么算法就结束。</p>
<p>在求解优化问题时，非确定性算法可能会陷入局部最优。</p>
<h2 id="3、NP问题"><a href="#3、NP问题" class="headerlink" title="3、NP问题"></a><strong>3、NP问题</strong></h2><p>有了时间上的衡量标准和状态转移的确定性与非确定性的概念，我们来定义一下问题的计算复杂度。</p>
<p><strong>P类问题</strong>就是能够以<strong>多项式时间</strong>的<strong>确定性算法</strong>来对问题进行判定或求解，实现它的算法在每个运行状态都是唯一的，最终一定能够确定一个唯一的结果——最优的结果。</p>
<p><strong>NP问题</strong>是指可以用<strong>多项式时间</strong>的<strong>非确定性算法</strong>来判定或求解，即这类问题求解的算法大多是非确定性的，但时间复杂度有可能是多项式级别的。</p>
<p>但是，NP问题还要一个子类称为<strong>NP完全问题</strong>，它是NP问题中最难的问题，其中任何一个问题至今都没有找到多项式时间的算法。</p>
<p><strong>机器学习</strong>中多数算法都是针对NP问题（包括NP完全问题）的。</p>
<hr>
<p>参考文献：<br><a href="http://www.junnanzhu.com/?p=141" target="_blank" rel="noopener">http://www.junnanzhu.com/?p=141</a><br><a href="https://www.zybuluo.com/frank-shaw/note/139175" target="_blank" rel="noopener">https://www.zybuluo.com/frank-shaw/note/139175</a></p>

      
    </div>
    
    
    

    

    <div>
      
        <div>
    
        <div style="text-align:center;color: #ccc;font-size:14px;">-------------本文结束<i class="fa fa-paw"></i>感谢您的阅读-------------</div>
    
</div>
      
    </div>

    
      <div>
        <div style="padding: 10px 0; margin: 20px auto; width: 90%; text-align: center;">
  <div>Donate comment here</div>
  <button id="rewardButton" disable="enable" onclick="var qr = document.getElementById('QR'); if (qr.style.display === 'none') {qr.style.display='block';} else {qr.style.display='none'}">
    <span>打赏</span>
  </button>
  <div id="QR" style="display: none;">

    
      <div id="wechat" style="display: inline-block">
        <img id="wechat_qr" src="/images/wechatpay.png" alt="FGY 微信支付"/>
        <p>微信支付</p>
      </div>
    

    
      <div id="alipay" style="display: inline-block">
        <img id="alipay_qr" src="/images/alipay.jpg" alt="FGY 支付宝"/>
        <p>支付宝</p>
      </div>
    

    

  </div>
</div>

      </div>
    

    
      <div>
        <ul class="post-copyright">
  <li class="post-copyright-author">
    <strong>本文作者：</strong>
    FGY
  </li>
  <li class="post-copyright-link">
    <strong>本文链接：</strong>
    <a href="http://frankblog.site/2018/05/30/机器学习基础（二）/" title="机器学习基础（二）">http://frankblog.site/2018/05/30/机器学习基础（二）/</a>
  </li>
  <li class="post-copyright-license">
    <strong>版权声明： </strong>
    本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/3.0/" rel="external nofollow" target="_blank">CC BY-NC-SA 3.0</a> 许可协议。转载请注明出处！
  </li>
</ul>

      </div>
    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/机器学习/" rel="tag"><i class="fa fa-tag"></i> 机器学习</a>
          
            <a href="/tags/深度学习/" rel="tag"><i class="fa fa-tag"></i> 深度学习</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2018/05/18/机器学习基础/" rel="next" title="机器学习基础（一）">
                <i class="fa fa-chevron-left"></i> 机器学习基础（一）
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2018/06/01/深度学习之Tensorflow(一)/" rel="prev" title="深度学习之Tensorflow(一)">
                深度学习之Tensorflow(一) <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>
  <aside id="sidebar" class="sidebar">
    
      <div id="sidebar-dimmer"></div>
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="/images/风景.jpeg"
                alt="FGY" />
            
              <p class="site-author-name" itemprop="name">FGY</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">
            

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">10</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">7</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">13</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>

            

          </nav>


          
            <div class="feed-link motion-element">
              <a href="/atom.xml" rel="alternate">
                <i class="fa fa-rss"></i>
                RSS
              </a>
            </div>
          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/fgyeason" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i>GitHub</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="https://www.kaggle.com/fgy0303" target="_blank" title="Kaggle">
                      
                        <i class="fa fa-fw fa-database"></i>Kaggle</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="https://music.163.com/#/playlist?id=2130685222" target="_blank" title="云音乐">
                      
                        <i class="fa fa-fw fa-music"></i>云音乐</a>
                  </span>
                
            </div>
          

          
          

          

          
            <div class="links-of-blogroll motion-element links-of-blogroll-inline">
              <div class="links-of-blogroll-title">
                <i class="fa  fa-fw fa-link"></i>
                Links
              </div>
              <ul class="links-of-blogroll-list">
                
                  <li class="links-of-blogroll-item">
                    <a href="https://www.lfd.uci.edu/~gohlke/pythonlibs/#wordcloud" title="Py_whl" target="_blank">Py_whl</a>
                  </li>
                
                  <li class="links-of-blogroll-item">
                    <a href="https://public.tableau.com/en-us/s/gallery" title="Tableau" target="_blank">Tableau</a>
                  </li>
                
                  <li class="links-of-blogroll-item">
                    <a href="https://www.coursera.org/" title="Coursera" target="_blank">Coursera</a>
                  </li>
                
                  <li class="links-of-blogroll-item">
                    <a href="http://lightgbm.apachecn.org/cn/latest/" title="LightGBM" target="_blank">LightGBM</a>
                  </li>
                
                  <li class="links-of-blogroll-item">
                    <a href="https://segmentfault.com/" title="SegmentFault" target="_blank">SegmentFault</a>
                  </li>
                
                  <li class="links-of-blogroll-item">
                    <a href="https://glyphsearch.com/" title="Font" target="_blank">Font</a>
                  </li>
                
                  <li class="links-of-blogroll-item">
                    <a href="http://liyangbit.com/math/jupyter-latex/" title="LaTex" target="_blank">LaTex</a>
                  </li>
                
                  <li class="links-of-blogroll-item">
                    <a href="https://juejin.im" title="掘金" target="_blank">掘金</a>
                  </li>
                
                  <li class="links-of-blogroll-item">
                    <a href="https://uqer.io/data/browse/0/?page=1" title="量化" target="_blank">量化</a>
                  </li>
                
                  <li class="links-of-blogroll-item">
                    <a href="https://www.jiqizhixin.com/" title="机器之心" target="_blank">机器之心</a>
                  </li>
                
                  <li class="links-of-blogroll-item">
                    <a href="http://tool.chinaz.com/" title="站长工具" target="_blank">站长工具</a>
                  </li>
                
              </ul>
            </div>
          
          

          
        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#线性代数"><span class="nav-number">1.</span> <span class="nav-text">线性代数</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-数据类型比较"><span class="nav-number">1.1.</span> <span class="nav-text">1.数据类型比较</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-矩阵导数"><span class="nav-number">1.2.</span> <span class="nav-text">2.矩阵导数</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-张量（Tensor）"><span class="nav-number">1.3.</span> <span class="nav-text">3.张量（Tensor）</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4-范数（Norm）"><span class="nav-number">1.4.</span> <span class="nav-text">4.范数（Norm）</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#5-特殊矩阵"><span class="nav-number">1.5.</span> <span class="nav-text">5.特殊矩阵</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#6-奇异值分解（Singular-Value-Decomposition，SVD）"><span class="nav-number">1.6.</span> <span class="nav-text">6.奇异值分解（Singular Value Decomposition，SVD）</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#7-Moore-Penrose伪逆"><span class="nav-number">1.7.</span> <span class="nav-text">7.Moore-Penrose伪逆</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#8-常见距离"><span class="nav-number">1.8.</span> <span class="nav-text">8.常见距离</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#曼哈顿距离"><span class="nav-number">1.8.1.</span> <span class="nav-text">曼哈顿距离</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#欧氏距离"><span class="nav-number">1.8.2.</span> <span class="nav-text">欧氏距离</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#闵可夫斯基距离"><span class="nav-number">1.8.3.</span> <span class="nav-text">闵可夫斯基距离</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#切比雪夫距离"><span class="nav-number">1.8.4.</span> <span class="nav-text">切比雪夫距离</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#夹角余弦"><span class="nav-number">1.8.5.</span> <span class="nav-text">夹角余弦</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#汉明距离"><span class="nav-number">1.8.6.</span> <span class="nav-text">汉明距离</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#杰卡德相似系数"><span class="nav-number">1.8.7.</span> <span class="nav-text">杰卡德相似系数</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#杰卡德距离"><span class="nav-number">1.8.8.</span> <span class="nav-text">杰卡德距离</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#概率论和统计"><span class="nav-number">2.</span> <span class="nav-text">概率论和统计</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-统计量"><span class="nav-number">2.1.</span> <span class="nav-text">1.统计量</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#协方差"><span class="nav-number">2.1.1.</span> <span class="nav-text">协方差</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Pearson相关系数"><span class="nav-number">2.1.2.</span> <span class="nav-text">Pearson相关系数</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#协方差矩阵"><span class="nav-number">2.1.3.</span> <span class="nav-text">协方差矩阵</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-独立与不相关"><span class="nav-number">2.2.</span> <span class="nav-text">2.独立与不相关</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-贝叶斯公式"><span class="nav-number">2.3.</span> <span class="nav-text">3.贝叶斯公式</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4-常见分布函数"><span class="nav-number">2.4.</span> <span class="nav-text">4.常见分布函数</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#0-1分布"><span class="nav-number">2.4.1.</span> <span class="nav-text">0-1分布</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#几何分布"><span class="nav-number">2.4.2.</span> <span class="nav-text">几何分布</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#二项分布"><span class="nav-number">2.4.3.</span> <span class="nav-text">二项分布</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#高斯分布"><span class="nav-number">2.4.4.</span> <span class="nav-text">高斯分布</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#指数分布"><span class="nav-number">2.4.5.</span> <span class="nav-text">指数分布</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#泊松分布"><span class="nav-number">2.4.6.</span> <span class="nav-text">泊松分布</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#5-常见的分布总结"><span class="nav-number">2.5.</span> <span class="nav-text">5.常见的分布总结</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#6-极大似然估计"><span class="nav-number">2.6.</span> <span class="nav-text">6.极大似然估计</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#微积分"><span class="nav-number">3.</span> <span class="nav-text">微积分</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-导数与梯度"><span class="nav-number">3.1.</span> <span class="nav-text">1.导数与梯度</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-泰勒展开"><span class="nav-number">3.2.</span> <span class="nav-text">2.泰勒展开</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-Lagrange乘子法"><span class="nav-number">3.3.</span> <span class="nav-text">3.Lagrange乘子法</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#信息论"><span class="nav-number">4.</span> <span class="nav-text">信息论</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-熵"><span class="nav-number">4.1.</span> <span class="nav-text">1.熵</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#联合熵"><span class="nav-number">4.1.1.</span> <span class="nav-text">联合熵</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#条件熵"><span class="nav-number">4.1.2.</span> <span class="nav-text">条件熵</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#互信息"><span class="nav-number">4.1.3.</span> <span class="nav-text">互信息</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#最大熵模型"><span class="nav-number">4.1.4.</span> <span class="nav-text">最大熵模型</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#熵满足下列不等式："><span class="nav-number">4.1.5.</span> <span class="nav-text">熵满足下列不等式：</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-上溢和下溢"><span class="nav-number">4.2.</span> <span class="nav-text">2.上溢和下溢</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#凸优化"><span class="nav-number">5.</span> <span class="nav-text">凸优化</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-凸集-Convex-Sets"><span class="nav-number">5.1.</span> <span class="nav-text">1.凸集(Convex Sets)</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-凸函数-Convex-Fuctions"><span class="nav-number">5.2.</span> <span class="nav-text">2.凸函数(Convex Fuctions)</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#凸函数的一阶条件"><span class="nav-number">5.2.1.</span> <span class="nav-text">凸函数的一阶条件</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#凸性质的二阶条件"><span class="nav-number">5.2.2.</span> <span class="nav-text">凸性质的二阶条件</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#琴生不等式-Jensen’s-Inequality"><span class="nav-number">5.2.3.</span> <span class="nav-text">琴生不等式(Jensen’s Inequality)</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-凸优化问题-Convex-Optimization-Problems"><span class="nav-number">5.3.</span> <span class="nav-text">3.凸优化问题(Convex Optimization Problems)</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4-牛顿法"><span class="nav-number">5.4.</span> <span class="nav-text">4.牛顿法</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#牛顿法介绍"><span class="nav-number">5.4.1.</span> <span class="nav-text">牛顿法介绍</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#牛顿法的推导"><span class="nav-number">5.4.2.</span> <span class="nav-text">牛顿法的推导</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#牛顿法的过程"><span class="nav-number">5.4.3.</span> <span class="nav-text">牛顿法的过程</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#5-阻尼牛顿法"><span class="nav-number">5.5.</span> <span class="nav-text">5.阻尼牛顿法</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#引入"><span class="nav-number">5.5.1.</span> <span class="nav-text">引入</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#算法过程"><span class="nav-number">5.5.2.</span> <span class="nav-text">算法过程</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#6-拟牛顿法"><span class="nav-number">5.6.</span> <span class="nav-text">6.拟牛顿法</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#概述"><span class="nav-number">5.6.1.</span> <span class="nav-text">概述</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#拟牛顿法的推导"><span class="nav-number">5.6.2.</span> <span class="nav-text">拟牛顿法的推导</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#计算复杂性与NP问题"><span class="nav-number">6.</span> <span class="nav-text">计算复杂性与NP问题</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#1、算法复杂性"><span class="nav-number">6.1.</span> <span class="nav-text">1、算法复杂性</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2、确定性和非确定性"><span class="nav-number">6.2.</span> <span class="nav-text">2、确定性和非确定性</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3、NP问题"><span class="nav-number">6.3.</span> <span class="nav-text">3、NP问题</span></a></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

<iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width=330 height=450 src="//music.163.com/outchain/player?type=0&id=2130685222&auto=1&height=430"></iframe>

      

    </div>
  </aside>




        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js">
</script>

<div class="copyright">&copy; <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">FGY</span>

  
</div>



  <div class="powered-by">
  <i class="fa fa-user-md"></i><span id="busuanzi_container_site_uv">
    本站访客数: <span id="busuanzi_value_site_uv"></span>人
  </span>
  </div>
<span>|</span>
  <div class="powered-by">
  <i class="fa fa-user-md"></i><span id="busuanzi_container_site_uv">
    访问量: <span id="busuanzi_value_site_pv"></span>次
  </span>
  </div>


<!--  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Muse</a> v5.1.4</div>



-->
<!--
<div class="theme-info">
  <div class="powered-by"></div>
  <span class="post-count">博客全站共32.5k字</span>
</div>
-->




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    
      <div id="needsharebutton-float">
        <span class="btn">
          <i class="fa fa-share-alt" aria-hidden="true"></i>
        </span>
      </div>
    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  


  











  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  

  
  
    <script type="text/javascript" src="/lib/canvas-nest/canvas-nest.min.js"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  

  
  
  
  <link rel="stylesheet" href="/lib/needsharebutton/needsharebutton.css">

  
  
  <script src="/lib/needsharebutton/needsharebutton.js"></script>

  <script>
    
    
      flOptions = {};
      
          flOptions.iconStyle = "box";
      
          flOptions.boxForm = "horizontal";
      
          flOptions.position = "middleRight";
      
          flOptions.networks = "Weibo,Wechat,Douban,QQZone,Twitter,Facebook";
      
      new needShareButton('#needsharebutton-float', flOptions);
    
  </script>

  

  

  

  

<!-- -->
  
</body>
</html>

<!-- 页面点击小红心 -->
<script type="text/javascript" src="/js/src/love.js"></script>
