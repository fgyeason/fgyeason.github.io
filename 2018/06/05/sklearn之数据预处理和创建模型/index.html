<!DOCTYPE html>



  


<html class="theme-next muse use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">


  
  
    
    
  <script src="/lib/pace/pace.min.js?v=1.0.2"></script>
  <link href="/lib/pace/pace-theme-minimal.min.css?v=1.0.2" rel="stylesheet">


 <script>     
    (function(){
        if(''){
            if (prompt('请输入文章密码') !== ''){
                alert('密码错误！');
                history.back();
            }
        }
    })();
</script>







<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="机器学习,sklearn," />





  <link rel="alternate" href="/atom.xml" title="Frank's Blog" type="application/atom+xml" />






<meta name="keywords" content="机器学习,sklearn">
<meta property="og:type" content="article">
<meta property="og:title" content="sklearn之数据预处理和创建模型">
<meta property="og:url" content="http://frankblog.site/2018/06/05/sklearn之数据预处理和创建模型/index.html">
<meta property="og:site_name" content="Frank&#39;s Blog">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="http://p4rlzrioq.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86_%E5%B0%81%E9%9D%A2.png">
<meta property="og:image" content="http://p4rlzrioq.bkt.clouddn.com/%E9%A2%84%E5%A4%84%E7%90%861.png">
<meta property="og:image" content="http://p4rlzrioq.bkt.clouddn.com/%E9%A2%84%E5%A4%84%E7%90%862.png">
<meta property="og:image" content="http://p4rlzrioq.bkt.clouddn.com/%E5%88%9B%E5%BB%BA%E5%B2%AD%E5%9B%9E%E5%BD%92.png">
<meta property="og:image" content="http://p4rlzrioq.bkt.clouddn.com/%E8%AE%A1%E7%AE%97%E7%89%B9%E5%BE%81%E7%9A%84%E7%9B%B8%E5%AF%B9%E9%87%8D%E8%A6%81%E6%80%A71.png">
<meta property="og:image" content="http://p4rlzrioq.bkt.clouddn.com/%E8%AE%A1%E7%AE%97%E7%89%B9%E5%BE%81%E7%9A%84%E7%9B%B8%E5%AF%B9%E9%87%8D%E8%A6%81%E6%80%A72.png">
<meta property="og:image" content="http://p4rlzrioq.bkt.clouddn.com/%E8%AE%A1%E7%AE%97%E7%89%B9%E5%BE%81%E7%9A%84%E7%9B%B8%E5%AF%B9%E9%87%8D%E8%A6%81%E6%80%A73.png">
<meta property="og:image" content="http://p4rlzrioq.bkt.clouddn.com/%E5%85%B1%E4%BA%AB%E5%8D%95%E8%BD%A6.png">
<meta property="og:image" content="http://p4rlzrioq.bkt.clouddn.com/%E5%85%B1%E4%BA%AB%E5%8D%95%E8%BD%A62.png">
<meta property="og:updated_time" content="2018-06-06T04:14:14.934Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="sklearn之数据预处理和创建模型">
<meta name="twitter:image" content="http://p4rlzrioq.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86_%E5%B0%81%E9%9D%A2.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":true},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://frankblog.site/2018/06/05/sklearn之数据预处理和创建模型/"/>





  <title>sklearn之数据预处理和创建模型 | Frank's Blog</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">
  
  
    
  
  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>
    
    <a href="https://github.com/fgyeason" class="github-corner" aria-label="View source on Github"><svg width="80" height="80" viewBox="0 0 250 250" style="fill:#151513; color:#fff; position: absolute; top: 0; border: 0; right: 0;" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a><style>.github-corner:hover .octo-arm{animation:octocat-wave 560ms ease-in-out}@keyframes octocat-wave{0%,100%{transform:rotate(0)}20%,60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}@media (max-width:500px){.github-corner:hover .octo-arm{animation:none}.github-corner .octo-arm{animation:octocat-wave 560ms ease-in-out}}</style>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Frank's Blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">Enjoy everything fun and challenging</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            关于
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-books">
          <a href="/books/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-book"></i> <br />
            
            书籍
          </a>
        </li>
      
        
        <li class="menu-item menu-item-films">
          <a href="/films/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-film"></i> <br />
            
            电影
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off"
             placeholder="搜索..." spellcheck="false"
             type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>
<script src="https://cdn.bootcss.com/aplayer/1.6.0/APlayer.min.js"></script>


 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://frankblog.site/2018/06/05/sklearn之数据预处理和创建模型/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="FGY">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/风景.jpeg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Frank's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">sklearn之数据预处理和创建模型</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
              
                <span class="post-meta-item-text">发表于</span>
              

              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-06-05T15:43:32+08:00">
                2018-06-05
              </time>
            

            
              <span class="post-meta-divider">|</span>
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-check-o"></i>
              </span>
              
                <span class="post-meta-item-text">更新于&#58;</span>
              
              <time title="更新于" itemprop="dateModified" datetime="2018-06-06T12:14:14+08:00">
                2018-06-06
              </time>
            
          </span>


          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习</span>
                  </a>
                </span>

                
                
              
            </span>
          





          
            
          

        
          


          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  5,403 字  
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  23 分钟  
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <script src="\assets\js\APlayer.min.js"> </script><p><img src="http://p4rlzrioq.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86_%E5%B0%81%E9%9D%A2.png" alt=""></p>
<a id="more"></a>
<blockquote class="blockquote-center"><font size="5">从IT时代走向DT时代</font></blockquote>

<hr>
<h1 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">from sklearn import preprocessing</span><br><span class="line"></span><br><span class="line">data = np.array([[ 3, -1.5, 2, -5.4],</span><br><span class="line">[ 0, 4, -0.3, 2.1],</span><br><span class="line">[ 1, 3.3, -1.9, -4.3]])</span><br></pre></td></tr></table></figure>
<h2 id="均值移除-mean-removal"><a href="#均值移除-mean-removal" class="headerlink" title="均值移除 mean removal"></a>均值移除 mean removal</h2><ul>
<li>“通常我们会把每个特征的平均值移除，以保证特征均值为0（即标准化处理）。这样做可以消除特征彼此间的偏差（bias）”</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">data_standardized = preprocessing.scale(data)</span><br><span class="line">print (&quot;\nMean特征均值 =&quot;, data_standardized.mean(axis=0))</span><br><span class="line">print (&quot;Std deviation标准偏差 =&quot;, data_standardized.std(axis=0))</span><br></pre></td></tr></table></figure>
<blockquote>
<p>Mean特征均值 = [ 5.55111512e-17 -1.11022302e-16 -7.40148683e-17 -7.40148683e-17]<br>Std deviation标准偏差 = [1. 1. 1. 1.]</p>
</blockquote>
<h2 id="范围缩放-min-max-scaling"><a href="#范围缩放-min-max-scaling" class="headerlink" title="范围缩放 min max scaling"></a>范围缩放 min max scaling</h2><ul>
<li>“数据点中每个特征的数值范围可能变化很大，因此，有时将特征的数值范围缩放到合理的大小是非常重要的。”</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">data_scaler = preprocessing.MinMaxScaler(feature_range=(0, 1))</span><br><span class="line">data_scaled = data_scaler.fit_transform(data)</span><br><span class="line">print (&quot;\nMin max scaled data范围缩放数据:\n&quot;, data_scaled)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>Min max scaled data范围缩放数据:<br> [[1.         0.         1.         0.        ]<br> [0.         1.         0.41025641 1.        ]<br> [0.33333333 0.87272727 0.         0.14666667]]</p>
</blockquote>
<h2 id="归一化-normalization"><a href="#归一化-normalization" class="headerlink" title="归一化 normalization"></a>归一化 normalization</h2><ul>
<li>“数据归一化用于需要对特征向量的值进行调整时，以保证每个特征向量的值都缩放到相同的数值范围。机器学习中最常用的归一化形式就是将特征向量调整为L1范数，使特征向量的数值之和为1。”</li>
<li>“这个方法经常用于确保数据点没有因为特征的基本性质而产生较大差异，即确保数据处于同一数量级，提高不同特征数据的可比性。”</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">data_normalized = preprocessing.normalize(data, norm=&apos;l1&apos;)</span><br><span class="line">print (&quot;\nL1 normalized data归一化后数据:\n&quot;, data_normalized)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>L1 normalized data归一化后数据:<br> [[ 0.25210084 -0.12605042  0.16806723 -0.45378151]<br> [ 0.          0.625      -0.046875    0.328125  ]<br> [ 0.0952381   0.31428571 -0.18095238 -0.40952381]]</p>
</blockquote>
<h2 id="二值化-binarization"><a href="#二值化-binarization" class="headerlink" title="二值化 binarization"></a>二值化 binarization</h2><ul>
<li>“二值化用于将数值特征向量转换为布尔类型向量。”</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">data_binarized = preprocessing.Binarizer(threshold=1.4).transform(data)</span><br><span class="line">print (&quot;\n二值化 data:\n&quot;, data_binarized)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>二值化 data:<br> [[1. 0. 1. 0.]<br> [0. 1. 0. 1.]<br> [0. 1. 0. 0.]]</p>
</blockquote>
<h2 id="独热编码"><a href="#独热编码" class="headerlink" title="独热编码"></a>独热编码</h2><ul>
<li><p>one hot encoding独热编码<br>“通常，需要处理的数值都是稀疏地、散乱地分布在空间中，然而，我们并不需要存储这些大数值，这时就需要使用独热编码（One-Hot Encoding）。可以把独热编码看作是一种收紧 （tighten）特征向量的工具。它把特征向量的每个特征与特征的非重复总数相对应，通过one-of-k 的形式对每个值进行编码。特征向量的每个特征值都按照这种方式编码，这样可以更加有效地表示空间。例如，我们需要处理4维向量空间，当给一个特性向量的第n 个特征进行编码时，编码器会遍历每个特征向量的第n 个特征，然后进行非重复计数。如果非重复计数的值是K ，那么就把这个特征转换为只有一个值是1其他值都是0的K 维向量。”</p>
</li>
<li><p>“在下面的示例中，观察一下每个特征向量的第三个特征，分别是1 、5 、2 、4 这4个不重复的值，也就是说独热编码向量的长度是4。如果你需要对5 进行编码，那么向量就是[0, 1, 0, 0] 。向量中只有一个值是1。第二个元素是1，对应的值是5 。”</p>
</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">encoder = preprocessing.OneHotEncoder()</span><br><span class="line">encoder.fit([[0, 2, 1, 12], [1, 3, 5, 3], [2, 3, 2, 12], [1, 2, 4, 3]])</span><br><span class="line">encoded_vector = encoder.transform([[2, 3, 5, 3]]).toarray()</span><br><span class="line">print (&quot;\n编码矢量:\n&quot;, encoded_vector)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>编码矢量:<br> [[0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 0.]]</p>
</blockquote>
<h2 id="标记编码方法"><a href="#标记编码方法" class="headerlink" title="标记编码方法"></a>标记编码方法</h2><p>在监督学习中，经常需要处理各种各样的标记。这些标记可能是数字，也可能是单词。如果标记是数字，那么算法可以直接使用它们，但是，许多情况下，标记都需要以人们可理解的形式存在，因此，人们通常会用单词标记训练数据集。标记编码就是要把单词标记转换成数值形式，让算法懂得如何操作标记。接下来看看如何标记编码。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">from sklearn import preprocessing</span><br><span class="line"># 定义一个标记编码器</span><br><span class="line">label_encoder = preprocessing.LabelEncoder()</span><br><span class="line"></span><br><span class="line"># label_encoder对象知道如何理解单词标记，接下来创建标记</span><br><span class="line">input_classes = [&apos;audi&apos;, &apos;ford&apos;, &apos;audi&apos;, &apos;toyota&apos;, &apos;ford&apos;, &apos;bmw&apos;]</span><br><span class="line"># 开始标记</span><br><span class="line">label_encoder.fit(input_classes)</span><br><span class="line">print(&quot;Classes mapping: 结果显示单词背转换成从0开始的索引值&quot;)</span><br><span class="line">for i, item in enumerate(lable_encoder.classes_):</span><br><span class="line">print(item, &apos;--&gt;&apos;, i)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>Classes mapping: 结果显示单词背转换成从0开始的索引值<br>audi –&gt; 0<br>bmw –&gt; 1<br>ford –&gt; 2<br>toyota –&gt; 3</p>
</blockquote>
<p>这时，如果遇到一组数据就可以轻松的转换它们了。（如药品数据的药品名）<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">labels = [&apos;toyota&apos;, &apos;f</span><br><span class="line">ord&apos;, &apos;audi&apos;]</span><br><span class="line">encoded_labels = label_encoder.transform(labels)</span><br><span class="line">print (&quot;\nLabels =&quot;, labels)</span><br><span class="line">print (&quot;Encoded labels =&quot;, list(encoded_labels))</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>Labels = [‘toyota’, ‘ford’, ‘audi’]<br>Encoded labels = [3, 2, 0]</p>
</blockquote>
<p>还可以数字反转回单词（或字符串）:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">encoded_labels = [2,1,0,3,1]</span><br><span class="line">decoded_labels = label_encoder.inverse_transform(encoded_labels)</span><br><span class="line">print(encoded_labels)</span><br><span class="line">print(list(decoded_labels))</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>[2, 1, 0, 3, 1]<br>[‘ford’, ‘bmw’, ‘audi’, ‘toyota’, ‘bmw’]</p>
</blockquote>
<h1 id="创建线性回归"><a href="#创建线性回归" class="headerlink" title="创建线性回归"></a>创建线性回归</h1><p>回归是估计输入数据与连续值输出数据之间关系的过程。数据通常是实数形式的，我们的目标是<strong>估计满足输入到输出映射关系的基本函数。</strong></p>
<p>线性回归的目标是提取输入变量与输出变量的关联线性模型，这就要求实际输出与线性方程预测的输出的残差平方和（sum of squares of differences）最小化。这种方法被称为普通最小二乘法 （Ordinary Least Squares，OLS）。</p>
<p>你可能觉得用一条曲线对这些点进行拟合效果会更好，但是线性回归不允许这样做。线性回归的主要优点就是方程简单。如果你想用非线性回归，可能会得到更准确的模型，但是拟合速度会慢很多。线性回归模型就像前面那张图里显示的，<strong>用一条直线近似数据点的趋势</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">import sys</span><br><span class="line">import numpy as np</span><br><span class="line"># 加载数据</span><br><span class="line">filename = sys.argv[1]</span><br><span class="line">X = []</span><br><span class="line">y = []</span><br><span class="line">with open(&apos;data_singlevar.txt&apos;, &apos;r&apos;) as f:</span><br><span class="line">    for line in f.readlines():</span><br><span class="line">    data = [float(i) for i in line.split(&apos;,&apos;)]</span><br><span class="line">    xt, yt = data[:-1], data[-1]</span><br><span class="line">    X.append(xt)</span><br><span class="line">    y.append(yt)</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># 80%训练集和20%测试集</span><br><span class="line">num_train = int(0.8 * len(X))</span><br><span class="line">num_test = len(X) - num_train</span><br><span class="line">X_train = np.array(X[:num_train]).reshape(num_train,1)</span><br><span class="line">y_train = np.array(y[:num_train])</span><br><span class="line"></span><br><span class="line">X_test = np.array(X[num_train:]).reshape(num_test, 1)</span><br><span class="line">y_test = np.array(y[num_train:])</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">from sklearn import linear_model</span><br><span class="line">linear_regr = linear_model.LinearRegression()</span><br><span class="line">linear_regr.fit(X_train, y_train)</span><br></pre></td></tr></table></figure>
<p>我们利用训练数据集训练了线性回归器。向fit 方法提供输入数据即可训练模型。用下面的代码看看它如何拟合<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">print(&apos;训练集拟合效果&apos;)</span><br><span class="line">y_train_pred = linear_regr.predict(X_train)</span><br><span class="line">plt.figure()</span><br><span class="line">plt.scatter(X_train, y_train)</span><br><span class="line">plt.plot(X_train, y_train_pred, color=&apos;green&apos;, linewidth=2)</span><br><span class="line">plt.title(&apos;Training Data&apos;)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></p>
<p><img src="http://p4rlzrioq.bkt.clouddn.com/%E9%A2%84%E5%A4%84%E7%90%861.png" alt=""></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">y_test_pred = linear_regr.predict(X_test)</span><br><span class="line">print(&quot;测试集拟合效果&quot;)</span><br><span class="line">plt.scatter(X_test, y_test)</span><br><span class="line">plt.plot(X_test, y_test_pred, color=&apos;green&apos;)</span><br><span class="line">plt.title(&quot;Test Data&quot;)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="http://p4rlzrioq.bkt.clouddn.com/%E9%A2%84%E5%A4%84%E7%90%862.png" alt=""></p>
<h1 id="计算回归准确性"><a href="#计算回归准确性" class="headerlink" title="计算回归准确性"></a>计算回归准确性</h1><p>现在已经建立了回归器，接下来最重要的就是如何评价回归器的拟合效果。在模型评价的相关内容中，用误差 （error）表示实际值与模型预测值之间的差值。</p>
<p>下面快速了解几个衡量回归器拟合效果的重要指标（metric）。回归器可以用许多不同的指标进行衡量，部分指标如下所示。</p>
<ul>
<li><p><strong>平均绝对误差（mean absolute error）</strong> ：这是给定数据集的所有数据点的绝对误差平均值。</p>
</li>
<li><p><strong>均方误差（mean squared error）</strong> ：这是给定数据集的所有数据点的误差的平方的平均值。这是最流行的指标之一。</p>
</li>
<li><p><strong>中位数绝对误差（median absolute error）</strong> ：这是给定数据集的所有数据点的误差的中位数。这个指标的主要优点是可以消除异常值（outlier）的干扰。测试数据集中的单个坏点不会影响整个误差指标，均值误差指标会受到异常点的影响。</p>
</li>
<li><p><strong>解释方差分（explained variance score）</strong> ：这个分数用于衡量我们的模型对数据集波动的解释能力。如果得分1.0分，那么表明我们的模型是完美的。</p>
</li>
<li><p><strong>R方得分（R2 score）</strong> ：这个指标读作“R方”，是指确定性相关系数，用于衡量模型对未知样本预测的效果。最好的得分是1.0，值也可以是负数。</p>
</li>
</ul>
<p>“每个指标都描述得面面俱到是非常乏味的，因此只选择一两个指标来评估我们的模型。通常的做法是尽量保证均方误差最低，而且解释方差分最高”<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">import sklearn.metrics as sm</span><br><span class="line"></span><br><span class="line">print(&quot;平均绝对误差（mean absolute error） ：&quot;</span><br><span class="line"> , round(sm.mean_absolute_error(y_test, y_test_pred), 2))</span><br><span class="line"></span><br><span class="line">print(&quot;均方误差（mean squared error） ：&quot;</span><br><span class="line"> , round(sm.mean_squared_error(y_test, y_test_pred), 2))</span><br><span class="line"></span><br><span class="line">print(&quot;中位数绝对误差（median absolute error） ：&quot;</span><br><span class="line"> , round(sm.median_absolute_error(y_test, y_test_pred), 2))</span><br><span class="line"></span><br><span class="line">print(&quot;解释方差分（explained variance score） ：&quot;</span><br><span class="line"> , round(sm.explained_variance_score(y_test, y_test_pred), 2))</span><br><span class="line"></span><br><span class="line">print(&quot;R方得分（R2 score） ：&quot;</span><br><span class="line"> , round(sm.r2_score(y_test, y_test_pred)))</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>平均绝对误差（mean absolute error） ： 0.54<br>均方误差（mean squared error） ： 0.38<br>中位数绝对误差（median absolute error） ： 0.54<br>解释方差分（explained variance score） ： 0.68<br>R方得分（R2 score） ： 1.0</p>
</blockquote>
<h1 id="保存模型数据"><a href="#保存模型数据" class="headerlink" title="保存模型数据"></a>保存模型数据</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">import pickle</span><br><span class="line"></span><br><span class="line">regr = pickle.dumps(linear_regr) # 保存</span><br><span class="line">regr1 = pickle.loads(regr) # 加载</span><br><span class="line">regr1.predict(X_test)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>array([2.20369892, 4.45873314, 2.12918475, 3.1253216 , 3.21944477,3.75673118, 3.91360313, 2.66647116, 3.32925513, 2.77235973])</p>
</blockquote>
<p>在scikit的具体情况下，使用 joblib 替换 pickle（ joblib.dump &amp; joblib.load ）可能会更有趣，这对大数据更有效，但只能序列化 (pickle) 到磁盘而不是字符串变量:</p>
<p>之后，您可以加载已保存的模型（可能在另一个 Python 进程中）:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.externals import joblib</span><br><span class="line">joblib.dump(linear_regr, &apos;regr.pkl&apos;) </span><br><span class="line">regr2 = joblib.load(&apos;regr.pkl&apos;) </span><br><span class="line">regr2.predict(X_test)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>array([2.20369892, 4.45873314, 2.12918475, 3.1253216 , 3.21944477,3.75673118, 3.91360313, 2.66647116, 3.32925513, 2.77235973])</p>
</blockquote>
<h1 id="创建岭回归"><a href="#创建岭回归" class="headerlink" title="创建岭回归"></a>创建岭回归</h1><p>线性回归的主要问题是对异常值敏感。在真实世界的数据收集过程中，经常会遇到错误的度量结果。而线性回归使用的普通最小二乘法，其目标是使平方误差最小化。这时，由于异常值误差的绝对值很大，因此会引起问题，从而破坏整个模型。</p>
<p>普通最小二乘法在建模时会考虑每个数据点的影响，因此，最终模型就会瘦异常值影响较大。显然，我们发现这个模型不是最优的。为了避免这个问题，我们引入正则化项 的系数作为阈值来消除异常值的影响。这个方法被称为岭回归 。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">import pandas as pd</span><br><span class="line">X = []</span><br><span class="line">y = []</span><br><span class="line">with open(&apos;data_multivar.txt&apos;, &apos;r&apos;) as f:</span><br><span class="line">    for line in f.readlines():</span><br><span class="line">    data = [float(i) for i in line.split(&apos;,&apos;)]</span><br><span class="line">    xt, yt = data[:-1], data[-1]</span><br><span class="line">    X.append(xt)</span><br><span class="line">    y.append(yt)</span><br><span class="line"># 80%训练集和20%测试集</span><br><span class="line">num_train = int(0.8 * len(X))</span><br><span class="line">num_test = len(X) - num_train</span><br><span class="line">X_train = np.array(X[:num_train]).reshape(num_train,3)</span><br><span class="line">y_train = np.array(y[:num_train])</span><br><span class="line"></span><br><span class="line">X_test = np.array(X[num_train:]).reshape(num_test, 3)</span><br><span class="line">y_test = np.array(y[num_train:])</span><br></pre></td></tr></table></figure>
<p>alpha 参数控制回归器的复杂程度。当alpha 趋于0 时，岭回归器就是用普通最小二乘法的线性回归器。因此，如果你希望模型对异常值不那么敏感，就需要设置一个较大的alpha 值。这里把alpha 值设置为0.01 。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">rid = linear_model.Ridge(alpha=0.01, fit_intercept=True, max_iter=10000)</span><br><span class="line"></span><br><span class="line">rid.fit(X_train, y_train)</span><br><span class="line">y_test_pred = rid.predict(X_test)</span><br><span class="line"></span><br><span class="line">import sklearn.metrics as sm</span><br><span class="line"></span><br><span class="line">print(&quot;平均绝对误差（mean absolute error） ：&quot;</span><br><span class="line"> , round(sm.mean_absolute_error(y_test, y_test_pred), 2))</span><br><span class="line"></span><br><span class="line">print(&quot;均方误差（mean squared error） ：&quot;</span><br><span class="line"> , round(sm.mean_squared_error(y_test, y_test_pred), 2))</span><br><span class="line"></span><br><span class="line">print(&quot;中位数绝对误差（median absolute error） ：&quot;</span><br><span class="line"> , round(sm.median_absolute_error(y_test, y_test_pred), 2))</span><br><span class="line"></span><br><span class="line">print(&quot;解释方差分（explained variance score） ：&quot;</span><br><span class="line"> , round(sm.explained_variance_score(y_test, y_test_pred), 2))</span><br><span class="line"></span><br><span class="line">print(&quot;R方得分（R2 score） ：&quot;</span><br><span class="line"> , round(sm.r2_score(y_test, y_test_pred)))</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>平均绝对误差（mean absolute error） ： 3.95<br>均方误差（mean squared error） ： 23.15<br>中位数绝对误差（median absolute error） ： 3.69<br>解释方差分（explained variance score） ： 0.84<br>R方得分（R2 score） ： 1.0</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">from pyecharts import Line</span><br><span class="line">line = Line(&quot;期望值测试对比&quot;)</span><br><span class="line">line.add(&apos;测试目标值&apos;, np.linspace(-20,40,len(y_test)), y_test, mark_line=[&quot;average&quot;], is_datazoom_show=True)</span><br><span class="line">line.add(&apos;实际测试值&apos;, np.linspace(-20,40,len(y_test)),  y_test_pred, mark_line=[&quot;average&quot;], is_datazoom_show=True)</span><br><span class="line">line</span><br><span class="line"></span><br><span class="line"># 80%训练集和20%测试集</span><br><span class="line">num_train = int(0.8 * len(X))</span><br><span class="line">num_test = len(X) - num_train</span><br><span class="line">X_train = np.array(X[:num_train]).reshape(num_train,1)</span><br><span class="line">y_train = np.array(y[:num_train])</span><br><span class="line"></span><br><span class="line">X_test = np.array(X[num_train:]).reshape(num_test, 1)</span><br><span class="line">y_test = np.array(y[num_train:])</span><br></pre></td></tr></table></figure>
<p><img src="http://p4rlzrioq.bkt.clouddn.com/%E5%88%9B%E5%BB%BA%E5%B2%AD%E5%9B%9E%E5%BD%92.png" alt=""></p>
<h1 id="创建多项式回归器（重点）"><a href="#创建多项式回归器（重点）" class="headerlink" title="创建多项式回归器（重点）"></a>创建多项式回归器（重点）</h1><p>数据点本身的模式中带有自然的曲线，而线性模型是不能捕捉到这一点的。多项式回归模型的曲率是由多项式的次数决定的。随着模型曲率的增加，模型变得更准确。但是，增加曲率的同时也增加了模型的复杂性，因此拟合速度会变慢。当我们对模型的准确性的理想追求与计算能力限制的残酷现实发生冲突时，就需要综合考虑了。</p>
<p>下面使用岭回归的数据，注意和简单线性回归的区别。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.preprocessing import PolynomialFeatures</span><br><span class="line"></span><br><span class="line">#将曲线的多项式次数初始值设置为3</span><br><span class="line">poly = PolynomialFeatures(degree = 20)</span><br><span class="line"># “其中，X_train_transformed 表示多项式形式的输入，与线性回归模型是一样的。”</span><br><span class="line">X_train_transformed = poly.fit_transform(X_train)</span><br><span class="line"></span><br><span class="line">#测试一下</span><br><span class="line">dp = X_train[0].reshape(1,-1)</span><br><span class="line">poly_dp = poly.fit_transform(dp)</span><br><span class="line"></span><br><span class="line">poly_liner = linear_model.LinearRegression()</span><br><span class="line">poly_liner.fit(X_train_transformed, y_train) #这里注意输入转换后的X_train</span><br><span class="line"></span><br><span class="line">print (&quot;\nLinear regression:&quot;, rid.predict(dp)[0])</span><br><span class="line">print (&quot;\nPolynomial regression:&quot;, poly_liner.predict(poly_dp)[0]) ##这输入转换后的X_test</span><br></pre></td></tr></table></figure>
<blockquote>
<p>Linear regression: -11.058646635286552<br>Polynomial regression: -8.070076359128953</p>
</blockquote>
<ul>
<li>多项式次数为1时 返回预测结果为：-11.058729498335897，欠拟合</li>
<li>多项式次数为10时 返回预测结果为：-8.206005341193759，这里与真实值-8.07已经非常接近了</li>
<li>多项式次数为20时 返回预测结果为：-8.070076359128953，针对这个值的预测最完美</li>
<li>多项式次数为100时 返回预测结果为：10.01397529328105，说明出现过拟合</li>
</ul>
<h1 id="AdaBoost算法估算房屋价格"><a href="#AdaBoost算法估算房屋价格" class="headerlink" title="AdaBoost算法估算房屋价格"></a>AdaBoost算法估算房屋价格</h1><p><strong>利用AdaBoost算法的决策树回归器<code>（decision tree regreessor）</code>来估算房屋价格</strong></p>
<p>决策树是一个树状模型，每个节点都做出一个决策，从而影响最终结果。叶子节点表示输出数值，分支表示根据输入特征做出的中间决策。<code>AdaBoost</code>算法是指自适应增强（<code>adaptive boosting</code>）算法，这是一种利用其他系统增强模型准确性的技术。这种技术是将不同版本的算法结果进行组合，用加权汇总的方式获得最终结果，被称为弱学习器 （<code>weak learners</code>）。<code>AdaBoost</code>算法在每个阶段获取的信息都会反馈到模型中，这样学习器就可以在后一阶段重点训练难以分类的样本。这种学习方式可以增强系统的准确性。</p>
<p>首先使用<code>AdaBoost</code>算法对数据集进行回归拟合，再计算误差，然后根据误差评估结果，用同样的数据集重新拟合。可以把这些看作是回归器的调优过程，直到达到预期的准确性。假设你拥有一个包含影响房价的各种参数的数据集，我们的目标就是估计这些参数与房价的关系，这样就可以根据未知参数估计房价了。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">from sklearn.tree import DecisionTreeRegressor</span><br><span class="line">from sklearn.ensemble import AdaBoostRegressor</span><br><span class="line">from sklearn import datasets</span><br><span class="line">from sklearn.metrics import mean_squared_error, explained_variance_score</span><br><span class="line">from sklearn.utils import shuffle</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line"></span><br><span class="line">hous_data = datasets.load_boston()</span><br></pre></td></tr></table></figure></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"># 利用shuffle函数把数据的顺序打乱（参数random_state用来控制如何打乱数据）</span><br><span class="line">X, y = shuffle(hous_data.data, hous_data.target, random_state=7)</span><br><span class="line"></span><br><span class="line">num = int(0.8 * len(X))</span><br><span class="line">X_train, y_train = X[:num], y[:num]</span><br><span class="line">X_test, y_test = X[num:], y[num:]</span><br><span class="line"></span><br><span class="line"># 选择最大深度为5的决策树回归模型</span><br><span class="line">dtre = DecisionTreeRegressor(max_depth=5)</span><br><span class="line">dtre.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line"># 再用带AdaBoost算法的决策树回归模型进行拟合与上面进行比较</span><br><span class="line">abre = AdaBoostRegressor(DecisionTreeRegressor(max_depth=5), n_estimators=400, random_state=7)</span><br><span class="line">abre.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line">#  看看AdaBoost算法对决策树回归器的训练效果有多大改善</span><br><span class="line">y_pred_dt = dtre.predict(X_test)</span><br><span class="line">mse = mean_squared_error(y_test, y_pred_dt)</span><br><span class="line">evs = explained_variance_score(y_test, y_pred_dt)</span><br><span class="line">print(&quot;决策树-均方误差: &quot;, mse)</span><br><span class="line">print(&quot;决策树-解释方差: &quot;, evs)</span><br><span class="line"></span><br><span class="line">y_pred_ab = abre.predict(X_test)</span><br><span class="line">mse = mean_squared_error(y_test, y_pred_ab)</span><br><span class="line">evs = explained_variance_score(y_test, y_pred_ab)</span><br><span class="line">print(&quot;\nAbaBoost决策树-均方误差: &quot;, mse)</span><br><span class="line">print(&quot;AbaBoost决策树-解释方差: &quot;, evs)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>决策树-均方误差:  12.74782456548819<br>决策树-解释方差:  0.8454595720920495<br>AbaBoost决策树-均方误差:  7.015648111222207<br>AbaBoost决策树-解释方差:  0.9147414844474588</p>
</blockquote>
<h1 id="计算特征的相对重要性-（如交通案例计算各出口贡献率）"><a href="#计算特征的相对重要性-（如交通案例计算各出口贡献率）" class="headerlink" title="计算特征的相对重要性 （如交通案例计算各出口贡献率）"></a>计算特征的相对重要性 （如交通案例计算各出口贡献率）</h1><p><strong>(<em>modle.feature__importances</em>)</strong></p>
<p>在这个案例中，我们用了13个特征，它们对模型都有贡献。但是，有一个重要的问题出现了：如何判断哪个特征更加重要？显然，所有的特征对结果的贡献是不一样的。如果需要忽略一些特征，就需要知道哪些特征不太重要。scikit-learn里面有这样的功能。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">def plot_feature_importances(feature_importances, title, feature_names):</span><br><span class="line"> # 将重要性值标准化</span><br><span class="line">    feature_importances = 100.0 * (feature_importances / max(feature_importances))</span><br><span class="line"></span><br><span class="line"> # 将得分从高到低排序</span><br><span class="line">    index_sorted = np.flipud(np.argsort(feature_importances))</span><br><span class="line"></span><br><span class="line"> # 让X坐标轴上的标签居中显示</span><br><span class="line">    pos = np.arange(index_sorted.shape[0]) + 0.5</span><br><span class="line"></span><br><span class="line"> # 画条形图</span><br><span class="line"> plt.figure()</span><br><span class="line"> plt.bar(pos, feature_importances[index_sorted], align=&apos;center&apos;)</span><br><span class="line"> plt.xticks(pos, feature_names[index_sorted])</span><br><span class="line"> plt.ylabel(&apos;Relative Importance&apos;)</span><br><span class="line"> plt.title(title)</span><br><span class="line"> plt.show()</span><br><span class="line"></span><br><span class="line"># 画出特征的相对重要性</span><br><span class="line">plot_feature_importances(dtre.feature_importances_, &apos;Decision Tree regressor&apos;, hous_data.feature_names)</span><br><span class="line">plot_feature_importances(abre.feature_importances_, &apos;AdaBoost regressor&apos;, hous_data.feature_names)</span><br></pre></td></tr></table></figure></p>
<p><img src="http://p4rlzrioq.bkt.clouddn.com/%E8%AE%A1%E7%AE%97%E7%89%B9%E5%BE%81%E7%9A%84%E7%9B%B8%E5%AF%B9%E9%87%8D%E8%A6%81%E6%80%A71.png" alt=""></p>
<p><img src="http://p4rlzrioq.bkt.clouddn.com/%E8%AE%A1%E7%AE%97%E7%89%B9%E5%BE%81%E7%9A%84%E7%9B%B8%E5%AF%B9%E9%87%8D%E8%A6%81%E6%80%A72.png" alt=""></p>
<p>上图可以看出不带AbaBoost的决策树回归器显示最重要的特征是RM，而带AbaBoost算法的决策回归器现实的最主要特征是LASTAT。现实生活中如果对这个数据集建立不同的回归器会发现最重要的特征就是LSTAT，这足以体现AbaBoost算法对决策树训练效果的改善。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">from pyecharts import Pie</span><br><span class="line"></span><br><span class="line">attr = f_name</span><br><span class="line">v1 = rf_regr.feature_importances_</span><br><span class="line">pie = Pie(&quot;影响房价的因素分析&quot;)</span><br><span class="line">pie.add(&quot;决策树回归器&quot;, hous_data.feature_names, dtre.feature_importances_, is_label_show=True, label_emphasis_textcolor=&apos;red&apos;,</span><br><span class="line">label_emphasis_textsize=14, is_random=True, legend_orient=&apos;vertical&apos;, legend_pos=&apos;1&apos;, legend_top=&apos;40&apos;,center=[35, 50],radius=[0, 50])</span><br><span class="line"></span><br><span class="line">pie.add(&quot;AbaBoost决策树&quot;, hous_data.feature_names, abre.feature_importances_,is_label_show=True, label_emphasis_textcolor=&apos;red&apos;,label_emphasis_textsize=14, is_random=True, legend_orient=&apos;vertical&apos;, legend_pos=&apos;1&apos;, legend_top=&apos;40&apos;,center=[75, 50],radius=[0, 50])</span><br><span class="line"></span><br><span class="line">pie</span><br></pre></td></tr></table></figure></p>
<p><img src="http://p4rlzrioq.bkt.clouddn.com/%E8%AE%A1%E7%AE%97%E7%89%B9%E5%BE%81%E7%9A%84%E7%9B%B8%E5%AF%B9%E9%87%8D%E8%A6%81%E6%80%A73.png" alt=""></p>
<h1 id="随机森林评估共享单车的需求分布"><a href="#随机森林评估共享单车的需求分布" class="headerlink" title="随机森林评估共享单车的需求分布"></a>随机森林评估共享单车的需求分布</h1><p><strong>采用随机森林回归器<code>(random forest regressor)</code>估计输出结果。</strong></p>
<p>随机森林死一个决策树合集，它基本上就是用一组由数据集的若干子集构建的决策树构成，再用决策树平均值改善整体学习效果</p>
<p>我们将使用bike_day.csv文件中的数据集，它可以在 <a href="https://archive.ics.uci.edu/ml/datasets/Bike+Sharing+Dataset" target="_blank" rel="noopener">https://archive.ics.uci.edu/ml/datasets/Bike+Sharing+Dataset</a> 获取。这份数据集一共16列，前两列是序列号与日期，分析的时候可以不用；最后三列数据是不同类型的输出结果；最后一列是第十四列与第十五列的和，因此建立模型时可以不考虑第十四列与第十五列。</p>
<p>参数<code>n_estimators</code>是指评估器<code>（estimator）</code>的数量，表示随机森林需要使用的决策树数量；<br>参数<code>max_depth</code> 是指每个决策树的最大深度；参数<code>min_samples_split</code>是指决策树分裂一个节点需要用到的最小数据样本量。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">import pandas as pd</span><br><span class="line">from sklearn.ensemble import RandomForestRegressor</span><br><span class="line">from housing import plot_feature_importances   #这个方法源码参考上例</span><br><span class="line"></span><br><span class="line">data = pd.read_csv(&apos;bike_day.csv&apos;,sep=&apos;,&apos;)</span><br><span class="line"></span><br><span class="line">X = data[data.columns[2:13]]</span><br><span class="line">y = data[data.columns[-1]]</span><br><span class="line">f_name = X.columns</span><br><span class="line"></span><br><span class="line">X, y = shuffle(X, y, random_state=7)</span><br><span class="line"></span><br><span class="line">num = int(0.9 * len(X))</span><br><span class="line">X_train, y_train = X[:num], y[:num]</span><br><span class="line">X_test, y_test = X[num:], y[num:]</span><br><span class="line"></span><br><span class="line">rf_regr = RandomForestRegressor(n_estimators=1000, max_depth=15, min_samples_split=12)</span><br><span class="line">rf_regr.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line">y_pred = rf_regr.predict(X_test)</span><br><span class="line"></span><br><span class="line">mse = mean_squared_error(y_test, y_pred)</span><br><span class="line">evs = explained_variance_score(y_test, y_pred)</span><br><span class="line"></span><br><span class="line">print(&quot;随机森林回归器效果：&quot;)</span><br><span class="line">print(&quot;均方误差：&quot;, round(mse, 2))</span><br><span class="line">print(&quot;解释方差分：&quot;, round(evs, 2))</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>随机森林回归器效果：<br>均方误差： 368026.24<br>解释方差分： 0.89</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">from pyecharts import Pie</span><br><span class="line"></span><br><span class="line">attr = f_name</span><br><span class="line">v1 = rf_regr.feature_importances_</span><br><span class="line">pie = Pie(&quot;共享单车因素分析&quot;)</span><br><span class="line">pie.add(&quot;因素&quot;, attr, v1, is_label_show=True, label_emphasis_textcolor=&apos;red&apos;,</span><br><span class="line">label_emphasis_textsize=14, is_random=True, legend_orient=&apos;vertical&apos;, legend_pos=&apos;1&apos;, legend_top=&apos;40&apos;)</span><br><span class="line">pie</span><br></pre></td></tr></table></figure>
<p><img src="http://p4rlzrioq.bkt.clouddn.com/%E5%85%B1%E4%BA%AB%E5%8D%95%E8%BD%A6.png" alt=""></p>
<p><strong>利用按小时的数据计算相关性</strong></p>
<p>这里要用到3～14列<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">len(X_train)</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>15641</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">hour_data = pd.read_csv(&apos;bike_hour.csv&apos;, sep=&apos;,&apos;)</span><br><span class="line">X = hour_data[hour_data.columns[2:14]]</span><br><span class="line">y = hour_data[hour_data.columns[-1]]</span><br><span class="line">X, y = shuffle(X, y, random_state=7)</span><br><span class="line"></span><br><span class="line">num = int(0.9*len(X))</span><br><span class="line">X_train, y_train = X[:num], y[:num]</span><br><span class="line">X_test, y_test = X[num:], y[num:]</span><br><span class="line">f_names = X.columns</span><br><span class="line"></span><br><span class="line">hrf_regr = RandomForestRegressor(n_estimators=1000, max_depth=15, min_samples_split=10)</span><br><span class="line">hrf_regr.fit(X_train, y_train)</span><br><span class="line">y_pred = hrf_regr.predict(X_test)</span><br><span class="line">mse = mean_squared_error(y_test, y_pred)</span><br><span class="line">evs = explained_variance_score(y_test, y_pred)</span><br><span class="line"></span><br><span class="line">print(&quot;均方误差：&quot;, mse)</span><br><span class="line">print(&quot;解释方差分：&quot;, evs)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>均方误差： 1884.1767363623571<br>解释方差分： 0.9414038595964176</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">attr = f_names</span><br><span class="line">v1 = hrf_regr.feature_importances_</span><br><span class="line">pie = Pie(&quot;共享单车因素分析&quot;)</span><br><span class="line">pie.add(&quot;因素&quot;, attr, v1, is_label_show=True, label_emphasis_textcolor=&apos;red&apos;,</span><br><span class="line">label_emphasis_textsize=14, is_random=True, </span><br><span class="line">legend_orient=&apos;vertical&apos;, legend_pos=&apos;1&apos;, legend_top=&apos;40&apos;)</span><br><span class="line">pie</span><br></pre></td></tr></table></figure>
<p><img src="http://p4rlzrioq.bkt.clouddn.com/%E5%85%B1%E4%BA%AB%E5%8D%95%E8%BD%A62.png" alt=""></p>
<p>由图可见，其中最重要的特征是一天中的不同时间点（hr），其次重要的是温度，这完全符合人们的直觉。</p>

      
    </div>
    
    
    

    

    <div>
      
        <div>
    
        <div style="text-align:center;color: #ccc;font-size:14px;">-------------本文结束<i class="fa fa-paw"></i>感谢您的阅读-------------</div>
    
</div>
      
    </div>

    
      <div>
        <div style="padding: 10px 0; margin: 20px auto; width: 90%; text-align: center;">
  <div>Donate comment here</div>
  <button id="rewardButton" disable="enable" onclick="var qr = document.getElementById('QR'); if (qr.style.display === 'none') {qr.style.display='block';} else {qr.style.display='none'}">
    <span>打赏</span>
  </button>
  <div id="QR" style="display: none;">

    
      <div id="wechat" style="display: inline-block">
        <img id="wechat_qr" src="/images/wechatpay.png" alt="FGY 微信支付"/>
        <p>微信支付</p>
      </div>
    

    
      <div id="alipay" style="display: inline-block">
        <img id="alipay_qr" src="/images/alipay.jpg" alt="FGY 支付宝"/>
        <p>支付宝</p>
      </div>
    

    

  </div>
</div>

      </div>
    

    
      <div>
        <ul class="post-copyright">
  <li class="post-copyright-author">
    <strong>本文作者：</strong>
    FGY
  </li>
  <li class="post-copyright-link">
    <strong>本文链接：</strong>
    <a href="http://frankblog.site/2018/06/05/sklearn之数据预处理和创建模型/" title="sklearn之数据预处理和创建模型">http://frankblog.site/2018/06/05/sklearn之数据预处理和创建模型/</a>
  </li>
  <li class="post-copyright-license">
    <strong>版权声明： </strong>
    本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/3.0/" rel="external nofollow" target="_blank">CC BY-NC-SA 3.0</a> 许可协议。转载请注明出处！
  </li>
</ul>

      </div>
    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/机器学习/" rel="tag"><i class="fa fa-tag"></i> 机器学习</a>
          
            <a href="/tags/sklearn/" rel="tag"><i class="fa fa-tag"></i> sklearn</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2018/06/04/机器学习之逻辑回归/" rel="next" title="机器学习之逻辑回归">
                <i class="fa fa-chevron-left"></i> 机器学习之逻辑回归
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2018/06/05/决策树之泰坦之灾/" rel="prev" title="决策树之泰坦之灾">
                决策树之泰坦之灾 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>
  <aside id="sidebar" class="sidebar">
    
      <div id="sidebar-dimmer"></div>
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="/images/风景.jpeg"
                alt="FGY" />
            
              <p class="site-author-name" itemprop="name">FGY</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">
            

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">17</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">9</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">24</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>

            

          </nav>


          
            <div class="feed-link motion-element">
              <a href="/atom.xml" rel="alternate">
                <i class="fa fa-rss"></i>
                RSS
              </a>
            </div>
          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/fgyeason" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i>GitHub</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="https://www.kaggle.com/fgy0303" target="_blank" title="Kaggle">
                      
                        <i class="fa fa-fw fa-database"></i>Kaggle</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="https://music.163.com/#/playlist?id=2130685222" target="_blank" title="云音乐">
                      
                        <i class="fa fa-fw fa-music"></i>云音乐</a>
                  </span>
                
            </div>
          

          
          

          

          
            <div class="links-of-blogroll motion-element links-of-blogroll-inline">
              <div class="links-of-blogroll-title">
                <i class="fa  fa-fw fa-link"></i>
                Links
              </div>
              <ul class="links-of-blogroll-list">
                
                  <li class="links-of-blogroll-item">
                    <a href="http://xgboost.apachecn.org/cn/latest/" title="XGBoost" target="_blank">XGBoost</a>
                  </li>
                
                  <li class="links-of-blogroll-item">
                    <a href="https://www.lfd.uci.edu/~gohlke/pythonlibs/#wordcloud" title="Py_whl" target="_blank">Py_whl</a>
                  </li>
                
                  <li class="links-of-blogroll-item">
                    <a href="https://www.coursera.org/" title="Coursera" target="_blank">Coursera</a>
                  </li>
                
                  <li class="links-of-blogroll-item">
                    <a href="https://stackoverflow.com/" title="StackoverFlow" target="_blank">StackoverFlow</a>
                  </li>
                
                  <li class="links-of-blogroll-item">
                    <a href="https://juejin.im" title="掘金" target="_blank">掘金</a>
                  </li>
                
                  <li class="links-of-blogroll-item">
                    <a href="https://uqer.io/data/browse/0/?page=1" title="量化" target="_blank">量化</a>
                  </li>
                
                  <li class="links-of-blogroll-item">
                    <a href="https://www.jiqizhixin.com/" title="机器之心" target="_blank">机器之心</a>
                  </li>
                
                  <li class="links-of-blogroll-item">
                    <a href="http://tool.chinaz.com/" title="站长工具" target="_blank">站长工具</a>
                  </li>
                
              </ul>
            </div>
          
          

          
        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#数据预处理"><span class="nav-number">1.</span> <span class="nav-text">数据预处理</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#均值移除-mean-removal"><span class="nav-number">1.1.</span> <span class="nav-text">均值移除 mean removal</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#范围缩放-min-max-scaling"><span class="nav-number">1.2.</span> <span class="nav-text">范围缩放 min max scaling</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#归一化-normalization"><span class="nav-number">1.3.</span> <span class="nav-text">归一化 normalization</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#二值化-binarization"><span class="nav-number">1.4.</span> <span class="nav-text">二值化 binarization</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#独热编码"><span class="nav-number">1.5.</span> <span class="nav-text">独热编码</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#标记编码方法"><span class="nav-number">1.6.</span> <span class="nav-text">标记编码方法</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#创建线性回归"><span class="nav-number">2.</span> <span class="nav-text">创建线性回归</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#计算回归准确性"><span class="nav-number">3.</span> <span class="nav-text">计算回归准确性</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#保存模型数据"><span class="nav-number">4.</span> <span class="nav-text">保存模型数据</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#创建岭回归"><span class="nav-number">5.</span> <span class="nav-text">创建岭回归</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#创建多项式回归器（重点）"><span class="nav-number">6.</span> <span class="nav-text">创建多项式回归器（重点）</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#AdaBoost算法估算房屋价格"><span class="nav-number">7.</span> <span class="nav-text">AdaBoost算法估算房屋价格</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#计算特征的相对重要性-（如交通案例计算各出口贡献率）"><span class="nav-number">8.</span> <span class="nav-text">计算特征的相对重要性 （如交通案例计算各出口贡献率）</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#随机森林评估共享单车的需求分布"><span class="nav-number">9.</span> <span class="nav-text">随机森林评估共享单车的需求分布</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

<iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width=330 height=450 src="//music.163.com/outchain/player?type=0&id=2130685222&auto=1&height=430"></iframe>

      

    </div>
  </aside>




        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js">
</script>

<div class="copyright">&copy; <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">FGY</span>

  
</div>



  <div class="powered-by">
  <i class="fa fa-user-md"></i><span id="busuanzi_container_site_uv">
    本站访客数: <span id="busuanzi_value_site_uv"></span>人
  </span>
  </div>
<span>|</span>
  <div class="powered-by">
  <i class="fa fa-user-md"></i><span id="busuanzi_container_site_uv">
    访问量: <span id="busuanzi_value_site_pv"></span>次
  </span>
  </div>


<!--  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Muse</a> v5.1.4</div>



-->
<!--
<div class="theme-info">
  <div class="powered-by"></div>
  <span class="post-count">博客全站共54.6k字</span>
</div>
-->




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    
      <div id="needsharebutton-float">
        <span class="btn">
          <i class="fa fa-share-alt" aria-hidden="true"></i>
        </span>
      </div>
    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  


  











  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  

  
  
    <script type="text/javascript" src="/lib/canvas-nest/canvas-nest.min.js"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  

  
  
  
  <link rel="stylesheet" href="/lib/needsharebutton/needsharebutton.css">

  
  
  <script src="/lib/needsharebutton/needsharebutton.js"></script>

  <script>
    
    
      flOptions = {};
      
          flOptions.iconStyle = "box";
      
          flOptions.boxForm = "horizontal";
      
          flOptions.position = "middleRight";
      
          flOptions.networks = "Weibo,Wechat,Douban,QQZone,Twitter,Facebook";
      
      new needShareButton('#needsharebutton-float', flOptions);
    
  </script>

  

  

  

  

<!-- -->
  
</body>
</html>

<!-- 页面点击小红心 -->
<script type="text/javascript" src="/js/src/love.js"></script>
